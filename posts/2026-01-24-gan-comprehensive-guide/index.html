<!doctype html><html lang=en dir=auto data-theme=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>生成对抗网络：从混沌中创造秩序的博弈论 | s-ai-unix's Blog</title><meta name=keywords content="GAN,深度学习,生成模型,神经网络,博弈论"><meta name=description content="深入探讨生成对抗网络（GAN）的数学原理、训练挑战与应用前景"><meta name=author content="s-ai-unix"><link rel=canonical href=https://s-ai-unix.github.io/posts/2026-01-24-gan-comprehensive-guide/><link crossorigin=anonymous href=/assets/css/stylesheet.0833aff7e1cf567ecfb9755701ee95a80535f671e2e1a0a770c9bc20a0a7b5bb.css integrity="sha256-CDOv9+HPVn7PuXVXAe6VqAU19nHi4aCncMm8IKCntbs=" rel="preload stylesheet" as=style><link rel=icon href=https://s-ai-unix.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://s-ai-unix.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://s-ai-unix.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://s-ai-unix.github.io/apple-touch-icon.png><link rel=mask-icon href=https://s-ai-unix.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://s-ai-unix.github.io/posts/2026-01-24-gan-comprehensive-guide/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51);color-scheme:dark}.list{background:var(--theme)}.toc{background:var(--entry)}}@media(prefers-color-scheme:light){.list::-webkit-scrollbar-thumb{border-color:var(--code-bg)}}</style></noscript><script>localStorage.getItem("pref-theme")==="dark"?document.querySelector("html").dataset.theme="dark":localStorage.getItem("pref-theme")==="light"?document.querySelector("html").dataset.theme="light":window.matchMedia("(prefers-color-scheme: dark)").matches?document.querySelector("html").dataset.theme="dark":document.querySelector("html").dataset.theme="light"</script><meta property="og:url" content="https://s-ai-unix.github.io/posts/2026-01-24-gan-comprehensive-guide/"><meta property="og:site_name" content="s-ai-unix's Blog"><meta property="og:title" content="生成对抗网络：从混沌中创造秩序的博弈论"><meta property="og:description" content="深入探讨生成对抗网络（GAN）的数学原理、训练挑战与应用前景"><meta property="og:locale" content="zh-cn"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2026-01-24T11:45:00+08:00"><meta property="article:modified_time" content="2026-01-24T11:45:00+08:00"><meta property="article:tag" content="GAN"><meta property="article:tag" content="深度学习"><meta property="article:tag" content="生成模型"><meta property="article:tag" content="神经网络"><meta property="article:tag" content="博弈论"><meta property="og:image" content="https://s-ai-unix.github.io/images/covers/gan-abstract.jpg"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://s-ai-unix.github.io/images/covers/gan-abstract.jpg"><meta name=twitter:title content="生成对抗网络：从混沌中创造秩序的博弈论"><meta name=twitter:description content="深入探讨生成对抗网络（GAN）的数学原理、训练挑战与应用前景"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://s-ai-unix.github.io/posts/"},{"@type":"ListItem","position":2,"name":"生成对抗网络：从混沌中创造秩序的博弈论","item":"https://s-ai-unix.github.io/posts/2026-01-24-gan-comprehensive-guide/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"生成对抗网络：从混沌中创造秩序的博弈论","name":"生成对抗网络：从混沌中创造秩序的博弈论","description":"深入探讨生成对抗网络（GAN）的数学原理、训练挑战与应用前景","keywords":["GAN","深度学习","生成模型","神经网络","博弈论"],"articleBody":"引言：从混沌中创造秩序 想象你是一位艺术鉴赏家,正在试图辨别一幅画作是大师真迹还是现代仿品。你仔细观察笔触、色彩、构图,试图找出破绽。与此同时,另一位艺术家正在努力学习大师的风格,试图创作出能骗过你的作品。这是一个永恒的博弈:一方越来越擅长伪造,另一方越来越擅长辨别。\n这正是生成对抗网络的核心思想。2014年,Ian Goodfellow 在一个学术研讨会上提出了这个想法,当时有人认为这是\"在酒吧里想出来的疯狂主意\"。然而,这个\"疯狂的主意\"彻底改变了生成式人工智能的格局。\n第一章：生成问题的本质 在深入 GAN 之前,让我们先理解什么是\"生成\"问题。假设我们有一个数据集,比如一堆手写数字图片。我们希望创建一个模型,能够生成\"看起来像\"这些手写数字的新图片。\n这个问题有两个核心挑战:\n数据分布建模: 我们需要学习数据的概率分布 $p_{data}(\\mathbf{x})$,其中 $\\mathbf{x}$ 表示一个样本。 从分布中采样: 一旦我们学到了分布,我们需要能够从中采样来生成新样本。 1.1 传统生成方法 在 GAN 出现之前,研究者已经尝试了多种方法:\n自编码器: 先将数据压缩到低维空间,然后试图从低维表示重建原始数据。但这种方法生成的样本往往模糊不清。\n玻尔兹曼机: 基于能量函数的方法,通过马尔可夫链蒙特卡洛采样。但训练极其困难,采样效率低。\n变分自编码器 (VAE): 通过变分推断近似后验分布。数学上优美,但生成的图像仍然不够真实。\n这些方法都有一个共同点:它们试图显式地建模数据分布 $p_{data}(\\mathbf{x})$。这就像试图精确描述\"什么样的数字图像看起来像真实的\",这本身就是一个极其困难的问题。\n1.2 GAN 的突破思想 GAN 的革命性在于:不需要显式建模数据分布。\n相反,GAN 将生成问题转化为一个对抗游戏:\n生成器 (Generator, $G$): 从随机噪声 $\\mathbf{z} \\sim p_z(\\mathbf{z})$ 出发,生成伪造样本 $\\tilde{\\mathbf{x}} = G(\\mathbf{z})$。目标:让判别器无法区分真假。\n判别器 (Discriminator, $D$): 接收一个样本 $\\mathbf{x}$,判断它是来自真实数据($\\mathbf{x} \\sim p_{data}$)还是生成器($\\tilde{\\mathbf{x}} = G(\\mathbf{z})$)。输出是概率 $D(\\mathbf{x}) \\in [0, 1]$。目标:准确区分真假。\n这是一个零和博弈:生成器试图最小化判别器的准确率,而判别器试图最大化准确率。当两者达到平衡时,生成器就\"学会\"了生成真实样本。\nflowchart LR subgraph 生成器_Generator Z[噪声 zz ~ p_z] G[生成器 G] Z --\u003e G G --\u003e Fake[伪造样本 x̃x̃ = Gz] end subgraph 判别器_Discriminator Real[真实样本 xx ~ p_data] FakeIn[伪造样本 x̃] D[判别器 D] Real --\u003e D FakeIn --\u003e D D --\u003e Prob[概率 Dx ∈ 0,1] end Fake -.-\u003e|输入| FakeIn style Z fill:#FF6B6B,stroke:#FF6B6B,stroke-width:3px,color:#fff style G fill:#4ECDC4,stroke:#4ECDC4,stroke-width:2px,color:#fff style Fake fill:#FFE66D,stroke:#FFE66D,stroke-width:2px,color:#333 style Real fill:#95E1D3,stroke:#95E1D3,stroke-width:3px,color:#333 style D fill:#A8E6CF,stroke:#A8E6CF,stroke-width:2px,color:#333 style Prob fill:#DDA0DD,stroke:#DDA0DD,stroke-width:3px,color:#fff style FakeIn fill:#FFE66D,stroke:#FFE66D,stroke-width:2px,color:#333 图 1：GAN 的架构示意图。生成器将噪声映射为图像，判别器区分真实和伪造样本\n第二章：数学框架与目标函数 2.1 极大极小博弈 让我们将这个想法形式化。定义:\n$\\mathbf{z} \\sim p_z(\\mathbf{z})$: 先验噪声分布(通常为高斯分布) $\\mathbf{x} \\sim p_{data}(\\mathbf{x})$: 真实数据分布 $G(\\mathbf{z}; \\theta_g)$: 生成器,参数为 $\\theta_g$ $D(\\mathbf{x}; \\theta_d)$: 判别器,参数为 $\\theta_d$ 判别器的目标是最大化对真实样本正确分类的概率,同时最小化对生成样本的错误分类概率:\n$$V(D, G) = \\mathbb{E}{\\mathbf{x} \\sim p{data}(\\mathbf{x})}[\\log D(\\mathbf{x})] + \\mathbb{E}_{\\mathbf{z} \\sim p_z(\\mathbf{z})}[\\log(1 - D(G(\\mathbf{z})))]$$\n其中:\n第一项:判别器对真实样本 $\\mathbf{x}$ 输出接近 $1$ 的概率 第二项:判别器对伪造样本 $G(\\mathbf{z})$ 输出接近 $0$ 的概率 生成器的目标是最小化这个价值函数(让判别器犯错):\n$$\\min_G \\max_D V(D, G)$$\n这就是著名的极大极小博弈。\n2.2 判别器的最优解 让我们先固定生成器 $G$,求解判别器的最优解。对于任何给定的输入 $\\mathbf{x}$,判别器输出 $D(\\mathbf{x})$。我们想要最大化对数似然:\n$$\\max_{D(\\mathbf{x})} \\left[ p_{data}(\\mathbf{x}) \\log D(\\mathbf{x}) + p_g(\\mathbf{x}) \\log(1 - D(\\mathbf{x})) \\right]$$\n其中 $p_g(\\mathbf{x})$ 是生成样本的分布。\n这是一个标量优化问题。对 $D(\\mathbf{x})$ 求导并令为零:\n$$\\frac{d}{dD(\\mathbf{x})} \\left[ p_{data}(\\mathbf{x}) \\log D(\\mathbf{x}) + p_g(\\mathbf{x}) \\log(1 - D(\\mathbf{x})) \\right] = 0$$\n$$\\frac{p_{data}(\\mathbf{x})}{D(\\mathbf{x})} - \\frac{p_g(\\mathbf{x})}{1 - D(\\mathbf{x})} = 0$$\n$$p_{data}(\\mathbf{x})(1 - D(\\mathbf{x})) = p_g(\\mathbf{x}) D(\\mathbf{x})$$\n$$p_{data}(\\mathbf{x}) - p_{data}(\\mathbf{x}) D(\\mathbf{x}) = p_g(\\mathbf{x}) D(\\mathbf{x})$$\n$$D^*(\\mathbf{x}) = \\frac{p_{data}(\\mathbf{x})}{p_{data}(\\mathbf{x}) + p_g(\\mathbf{x})}$$\n这是判别器的全局最优解。\n直观解释:判别器的输出应该等于\"这个样本来自真实数据而非生成数据的概率\"。如果 $p_{data}(\\mathbf{x})$ 很高而 $p_g(\\mathbf{x})$ 很低,那么 $D(\\mathbf{x}) \\approx 1$;反之则接近 $0$。\n2.3 生成器的目标函数 有了最优判别器,我们可以将其代回价值函数:\n$$V(G, D^*) = \\mathbb{E}{\\mathbf{x} \\sim p{data}}\\left[\\log \\frac{p_{data}(\\mathbf{x})}{p_{data}(\\mathbf{x}) + p_g(\\mathbf{x})}\\right] + \\mathbb{E}{\\mathbf{x} \\sim p_g}\\left[\\log \\frac{p_g(\\mathbf{x})}{p{data}(\\mathbf{x}) + p_g(\\mathbf{x})}\\right]$$\n这个表达式看起来复杂,但可以简化。注意到:\n$$\\int [p_{data}(\\mathbf{x}) \\log \\frac{p_{data}(\\mathbf{x})}{p_{data}(\\mathbf{x}) + p_g(\\mathbf{x})} + p_g(\\mathbf{x}) \\log \\frac{p_g(\\mathbf{x})}{p_{data}(\\mathbf{x}) + p_g(\\mathbf{x})}] d\\mathbf{x}$$\n这可以写成:\n$$\\mathbb{E}{\\mathbf{x} \\sim p{data}}\\left[-\\log 2 - \\log \\left(\\frac{p_{data}(\\mathbf{x}) + p_g(\\mathbf{x})}{2 p_{data}(\\mathbf{x})}\\right)\\right] + \\mathbb{E}{\\mathbf{x} \\sim p_g}\\left[-\\log 2 - \\log \\left(\\frac{p{data}(\\mathbf{x}) + p_g(\\mathbf{x})}{2 p_g(\\mathbf{x})}\\right)\\right]$$\n$$= -\\log 4 + \\text{KL}\\left(p_{data} \\parallel \\frac{p_{data} + p_g}{2}\\right) + \\text{KL}\\left(p_g \\parallel \\frac{p_{data} + p_g}{2}\\right)$$\n其中 $\\text{KL}$ 是 KL 散度。这个表达式恰好等于:\n$$-\\log 4 + 2 \\cdot \\text{JSD}(p_{data} \\parallel p_g)$$\n其中 JSD 是 Jensen-Shannon 散度。\n关键洞察:生成器的目标是最小化 JSD 散度。当 $p_g = p_{data}$ 时,JSD 散度为 $0$,价值函数达到最小值 $-\\log 4$。\n结论:GAN 的训练目标是让生成分布 $p_g$ 收敛到真实数据分布 $p_{data}$。\n2.4 实际训练过程 虽然理论分析很有趣,但实际训练时我们使用交替优化:\n固定 $G$,更新 $D$:\n采样真实数据: ${\\mathbf{x}^{(1)}, \\ldots, \\mathbf{x}^{(m)}} \\sim p_{data}$ 采样噪声: ${\\mathbf{z}^{(1)}, \\ldots, \\mathbf{z}^{(m)}} \\sim p_z$ 生成伪造样本: ${\\tilde{\\mathbf{x}}^{(1)}, \\ldots, \\tilde{\\mathbf{x}}^{(m)}}, \\tilde{\\mathbf{x}}^{(i)} = G(\\mathbf{z}^{(i)})$ 梯度上升: $$\\nabla_{\\theta_d} \\frac{1}{m} \\sum_{i=1}^{m} \\left[\\log D(\\mathbf{x}^{(i)}) + \\log(1 - D(\\tilde{\\mathbf{x}}^{(i)}))\\right]$$ 固定 $D$,更新 $G$:\n采样噪声: ${\\mathbf{z}^{(1)}, \\ldots, \\mathbf{z}^{(m)}} \\sim p_z$ 梯度下降: $$\\nabla_{\\theta_g} \\frac{1}{m} \\sum_{i=1}^{m} \\log(1 - D(G(\\mathbf{z}^{(i)})))$$ 实际改进:在实践中,生成器通常最大化 $\\log D(G(\\mathbf{z}))$ 而不是最小化 $\\log(1 - D(G(\\mathbf{z})))$,因为后者在训练初期梯度会消失。\n第三章：GAN 的架构与实现 3.1 神经网络基础 让我们先回顾多层感知机的基本结构。一个典型的神经网络:\n$$\\mathbf{h}^{(l)} = \\sigma(\\mathbf{W}^{(l)} \\mathbf{h}^{(l-1)} + \\mathbf{b}^{(l)})$$\n其中:\n$\\mathbf{W}^{(l)} \\in \\mathbb{R}^{n^{(l)} \\times n^{(l-1)}}$: 第 $l$ 层的权重矩阵 $\\mathbf{b}^{(l)} \\in \\mathbb{R}^{n^{(l)}}$: 第 $l$ 层的偏置向量 $\\sigma(\\cdot)$: 激活函数(如 ReLU, sigmoid, tanh) $\\mathbf{h}^{(0)} = \\mathbf{x}$: 输入 $\\mathbf{h}^{(L)}$: 输出 反向传播:训练神经网络的核心是反向传播算法。给定损失函数 $L$,我们使用链式法则计算梯度:\n$$\\frac{\\partial L}{\\partial \\mathbf{W}^{(l)}} = \\frac{\\partial L}{\\partial \\mathbf{h}^{(l)}} \\cdot \\frac{\\partial \\mathbf{h}^{(l)}}{\\partial \\mathbf{z}^{(l)}} \\cdot \\frac{\\partial \\mathbf{z}^{(l)}}{\\partial \\mathbf{W}^{(l)}}$$\n其中 $\\mathbf{z}^{(l)} = \\mathbf{W}^{(l)} \\mathbf{h}^{(l-1)} + \\mathbf{b}^{(l)}$。\n3.2 GAN 的具体实现 让我们看看 GAN 的具体实现。假设我们生成 $64 \\times 64$ 的 RGB 图像。\n生成器 $G$:\n# 输入: 噪声向量 z ∈ R^100 # 输出: 图像 x ∈ R^(64×64×3) # 第一层: 全连接层 + Reshape z → Dense(4×4×512) → Reshape(4, 4, 512) # 上采样层 (使用转置卷积或上采样 + 卷积) 4×4×512 → Conv2DTranspose(256, 5×5, stride=2) → 8×8×256 8×8×256 → BatchNorm → ReLU 8×8×256 → Conv2DTranspose(128, 5×5, stride=2) → 16×16×128 16×16×128 → BatchNorm → ReLU 16×16×128 → Conv2DTranspose(64, 5×5, stride=2) → 32×32×64 32×32×64 → BatchNorm → ReLU 32×32×64 → Conv2DTranspose(3, 5×5, stride=2, activation='tanh') → 64×64×3 判别器 $D$:\n# 输入: 图像 x ∈ R^(64×64×3) # 输出: 概率 D(x) ∈ [0, 1] 64×64×3 → Conv2D(64, 5×5, stride=2, leaky_relu) → 32×32×64 32×32×64 → Dropout(0.3) 32×32×64 → Conv2D(128, 5×5, stride=2, leaky_relu) → 16×16×128 16×16×128 → BatchNorm → Dropout(0.3) 16×16×128 → Conv2D(256, 5×5, stride=2, leaky_relu) → 8×8×256 8×8×256 → BatchNorm → Dropout(0.3) 8×8×256 → Flatten → Dense(1, activation='sigmoid') 关键设计决策:\n激活函数选择:\n判别器: 使用 LeakyReLU 而非 ReLU,避免\"死亡神经元\" 生成器: 使用 tanh 作为输出激活函数(输出范围 $[-1, 1]$) 批归一化 (Batch Normalization):\n稳定训练,防止梯度爆炸/消失 生成器的所有层都使用,判别器的部分层使用 转置卷积 vs 上采样:\n转置卷积可能导致棋盘格效应 现代 GAN 更多使用上采样 + 卷积 3.3 GAN 架构图 graph TB subgraph 生成器_G Z[噪声 zz ∈ R^100] --\u003e FC1[全连接层4×4×512] FC1 --\u003e US1[上采样层8×8×256] US1 --\u003e US2[上采样层16×16×128] US2 --\u003e US3[上采样层32×32×64] US3 --\u003e US4[上采样层64×64×3] US4 --\u003e X_hat[生成图像x̃ = Gz] end subgraph 判别器_D X[真实图像x ∈ R^64×64×3] X_hat_in[生成图像x̃ = Gz] X --\u003e C1[卷积层32×32×64] X_hat_in --\u003e C1 C1 --\u003e C2[卷积层16×16×128] C2 --\u003e C3[卷积层8×8×256] C3 --\u003e F[展平层] F --\u003e OUT[输出概率Dx ∈ 0 1] end style Z fill:#FF9500,stroke:#FF9500,stroke-width:3px,color:#ffffff style X fill:#34C759,stroke:#34C759,stroke-width:3px,color:#ffffff style X_hat fill:#FF9500,stroke:#FF9500,stroke-width:2px,color:#ffffff style X_hat_in fill:#FF9500,stroke:#FF9500,stroke-width:2px,color:#ffffff style FC1 fill:#5AC8FA,stroke:#5AC8FA,stroke-width:2px,color:#ffffff style US1 fill:#5AC8FA,stroke:#5AC8FA,stroke-width:1px,color:#ffffff style US2 fill:#5AC8FA,stroke:#5AC8FA,stroke-width:1px,color:#ffffff style US3 fill:#5AC8FA,stroke:#5AC8FA,stroke-width:1px,color:#ffffff style US4 fill:#5AC8FA,stroke:#5AC8FA,stroke-width:1px,color:#ffffff style C1 fill:#AF52DE,stroke:#AF52DE,stroke-width:2px,color:#ffffff style C2 fill:#AF52DE,stroke:#AF52DE,stroke-width:2px,color:#ffffff style C3 fill:#AF52DE,stroke:#AF52DE,stroke-width:2px,color:#ffffff style F fill:#AF52DE,stroke:#AF52DE,stroke-width:1px,color:#ffffff style OUT fill:#FF3B30,stroke:#FF3B30,stroke-width:3px,color:#ffffff 第四章：训练的挑战与解决方案 GAN 的理论虽然优美,但实际训练极其困难。让我们探讨主要挑战和解决方案。\n4.1 模式崩溃 问题描述:生成器可能学会只生成少数几种样本,无法覆盖数据分布的多样性。\n原因分析:假设判别器对某一类样本输出 $D(\\mathbf{x}) \\approx 0.5$,生成器发现欺骗判别器最简单的方法是只生成这一类样本。\n解决方案:\n小批量判别 (Mini-batch Discrimination):\n让判别器能够判断\"一个小批量的样本是否都来自同一分布\" 特征之间的相似度被纳入考虑 特征匹配 (Feature Matching):\n生成器不再试图欺骗判别器的输出,而是匹配判别器中间层的统计量 目标:让生成样本的激活统计量与真实样本相似 使用不同架构:\nWGAN-GP:使用 Wasserstein 距离 SNGAN:谱归一化 BigGAN:自注意力机制 4.2 收敛性问题 问题描述:GAN 的训练是两个网络的对抗,容易陷入不稳定状态。\n原因分析:\n纳什均衡的存在性和可达性 两个网络的训练速度不匹配 梯度在训练过程中震荡 解决方案:\n标签平滑 (Label Smoothing):\n不使用硬标签 ${0, 1}$,而是使用 ${0.1, 0.9}$ 防止判别器过度自信 梯度惩罚 (Gradient Penalty):\nWGAN-GP 引入梯度约束 目标:让判别器的梯度在真实和生成样本之间保持一致 学习率调度:\n使用不同的学习率 使用衰减学习率 4.3 评估困难 问题描述:GAN 的评估没有统一的标准。不像分类任务有准确率,生成任务的主观性很强。\n常用指标:\nInception Score (IS): $$IS(G) = \\exp\\left(\\mathbb{E}_{\\mathbf{x} \\sim p_g}[\\text{KL}(p(y|\\mathbf{x}) \\parallel p(y))]\\right)$$\n高 IS 意味着生成图像清晰(低熵)且多样化(高熵) Fréchet Inception Distance (FID): $$FID(p_r, p_g) = |\\mathbf{\\mu}_r - \\mathbf{\\mu}_g|^2 + \\text{Tr}(\\mathbf{\\Sigma}_r + \\mathbf{\\Sigma}_g - 2(\\mathbf{\\Sigma}_r \\mathbf{\\Sigma}_g)^{1/2})$$\n基于 Inception 特征的距离度量 越低越好 人类评估:\n图灵测试式的评估 主观但最有说服力 第五章：高级 GAN 架构 5.1 DCGAN:深度卷积生成对抗网络 DCGAN 是第一个稳定训练的 GAN 架构,奠定了后续发展的基础。\n关键改进:\n使用卷积层而非全连接层:\n判别器使用步长卷积(strided convolution)代替池化 生成器使用转置卷积或上采样 批归一化:\n在生成器和判别器中都使用 稳定训练,防止梯度问题 架构设计:\n去除全连接层 生成器除输出层外使用 ReLU 判别器所有层都使用 LeakyReLU 几何直观:卷积操作捕捉空间层次结构,从低级特征(边缘、纹理)到高级特征(形状、物体)。\n5.2 WGAN:Wasserstein GAN WGAN 的核心思想是使用 Wasserstein 距离代替 JS 散度。\nWasserstein 距离(地球移动距离):\n$$W(p_r, p_g) = \\inf_{\\gamma \\in \\Pi(p_r, p_g)} \\mathbb{E}_{(\\mathbf{x}, \\mathbf{y}) \\sim \\gamma}[|\\mathbf{x} - \\mathbf{y}|]$$\n其中 $\\Pi(p_r, p_g)$ 是所有联合分布的集合,满足边缘分布分别为 $p_r$ 和 $p_g$。\n直观解释:将分布 $p_r$ 的\"土堆\"移动到 $p_g$ 的\"坑洞\"所需的最小\"功\"。\n图 2：Wasserstein 距离的几何直观。我们需要将真实分布的质量移动到生成分布的位置，最小化所需的\"功\"\n关键优势:\n更好的梯度性质:即使分布没有重叠,Wasserstein 距离仍然提供有意义的梯度 与训练稳定性相关:判别器的损失可以用于衡量训练进度 WGAN-GP 的改进:\n使用梯度惩罚代替权重裁剪 目标:让判别器的梯度范数接近 $1$ 更稳定的训练 5.3 SNGAN:谱归一化 SNGAN 通过谱归一化(Spectral Normalization)稳定判别器的训练。\n谱归一化的定义:\n$$\\bar{\\mathbf{W}}_{SN} = \\frac{\\mathbf{W}}{\\sigma(\\mathbf{W})}$$\n其中 $\\sigma(\\mathbf{W})$ 是权重矩阵 $\\mathbf{W}$ 的谱范数(最大奇异值)。\n效果:\n限制判别器的 Lipschitz 常数 稳定训练,不需要批归一化 适用于各种架构 5.4 JS 散度 vs Wasserstein 距离 理解为什么 Wasserstein 距离比 JS 散度更好,我们需要看它们的性质。\n图 3：JS 散度与 Wasserstein 距离的对比。当两个分布没有重叠时，JS 散度饱和而 Wasserstein 距离继续提供有意义的梯度\nJS 散度的局限:\n当 $p_r$ 和 $p_g$ 没有重叠时,JS 散度为 $\\log 2$ 这意味着梯度消失,生成器无法学习 Wasserstein 距离的优势:\n即使分布没有重叠,仍然提供有意义的梯度 与分布的支撑集无关 更好的训练稳定性 5.5 StyleGAN:基于风格的生成 StyleGAN 引入了\"风格迁移\"的思想,将图像分解为风格和内容。\n核心思想:\n风格编码器:\n将噪声 $\\mathbf{z}$ 映射到风格向量 $\\mathbf{w}$ 风格向量控制图像的高级属性(年龄、姿态等) 自适应实例归一化: $$\\text{AdaIN}(\\mathbf{x}i, \\mathbf{y}) = \\mathbf{y}{s,i} \\frac{\\mathbf{x}_i - \\mu(\\mathbf{x}_i)}{\\sigma(\\mathbf{x}i)} + \\mathbf{y}{b,i}$$\n使用风格向量对特征进行归一化 $\\mathbf{y}_s$ 控制尺度,$\\mathbf{y}_b$ 控制偏移 潜在空间解耦:\n将风格空间与潜在空间分离 更好的属性可控性 效果:生成极高保真度的人脸图像,支持精细的属性控制。\n5.6 条件 GAN 条件 GAN 在生成器中引入条件信息。\n架构变化:\n$$G(\\mathbf{z}, \\mathbf{y}) \\to \\tilde{\\mathbf{x}}$$ $$D(\\mathbf{x}, \\mathbf{y}) \\to \\text{真/假}$$\n其中 $\\mathbf{y}$ 是条件信息(类别标签、文本描述等)。\n应用场景:\n文本到图像生成 类别条件生成 图像到图像翻译 第六章：实际应用 6.1 图像生成与编辑 应用举例:\n人脸生成:StyleGAN 可以生成逼真的人脸 超分辨率:SRGAN 将低分辨率图像提升到高分辨率 图像修复:Context Encoders 可以修复图像中的缺失部分 数学原理:GAN 学习数据分布的流形(manifold)。通过在潜空间中插值,可以实现平滑的图像变换。\n6.2 图像到图像翻译 Pix2Pix:\n使用条件 GAN 进行配对图像的翻译 应用:语义分割到图像、灰度到彩色、航拍到地图 CycleGAN:\n无配对数据的图像到图像翻译 引入循环一致性损失(cycle consistency loss) 应用:马到斑马、夏天到冬天、照片到画作 CycleGAN 的核心思想:\n对于两个域 $\\mathcal{X}$ 和 $\\mathcal{Y}$,定义两个生成器:\n$G: \\mathcal{X} \\to \\mathcal{Y}$ $F: \\mathcal{Y} \\to \\mathcal{X}$ 循环一致性损失:\n$$\\mathcal{L}{cyc} = \\mathbb{E}{\\mathbf{x} \\sim p_{\\mathcal{X}}}[|F(G(\\mathbf{x})) - \\mathbf{x}|1] + \\mathbb{E}{\\mathbf{y} \\sim p_{\\mathcal{Y}}}[|G(F(\\mathbf{y})) - \\mathbf{y}|_1]$$\n直观解释:将图像从 $\\mathcal{X}$ 转换到 $\\mathcal{Y}$,再转换回 $\\mathcal{X}$,应该得到原图。\n6.3 文本到图像生成 StackGAN:\n分阶段生成:先生成粗略草图,再精细化 使用文本编码器提取文本特征 AttnGAN:\n引入注意力机制,关注文本的不同部分 更精细的文本-图像对应 数学挑战:\n文本是离散的,图像是连续的 需要将文本编码为连续的潜在向量 6.4 数据增强 GAN 可以用于生成合成数据,增强训练集。\n优势:\n生成与真实数据相似的样本 适用于数据稀缺的场景 可以控制生成样本的属性 注意事项:\n生成质量必须足够高 避免过度依赖合成数据 需要验证合成数据的有效性 第七章：前沿方向与挑战 7.1 大规模 GAN BigGAN 等架构将 GAN 推向大规模图像生成。\n关键改进:\n使用大模型(数亿参数) 批量大小增大(数千) 自注意力机制 类别条件生成 挑战:\n计算资源需求极高 训练不稳定 模式崩溃仍然存在 7.2 3D 生成 GAN 正在扩展到 3D 领域。\n应用:\n3D 物体生成 点云生成 神经渲染 技术挑战:\n3D 数据表示(体素、点云、网格) 计算复杂度 评估标准 7.3 理论突破 GAN 的理论基础仍在发展。\n研究方向:\n收敛性证明:何时 GAN 一定收敛? 分布匹配:更好的距离度量 稳定性分析:训练稳定性的理论保证 数学挑战:\n非凸优化问题 博弈论与优化的交叉 高维空间中的分布性质 7.4 伦理考量 GAN 的强大能力也带来伦理问题。\n问题:\n深度伪造(Deepfake):可以生成虚假的视频和音频 隐私:从生成样本推断训练数据 偏见:继承训练数据的偏见 应对:\n检测技术:识别 GAN 生成的内容 合规使用:负责任地使用技术 公平性:确保生成模型的公平性 第八章：潜空间探索 GAN 的潜空间(latent space)是一个迷人的概念。理解潜空间有助于我们更好地控制和生成图像。\n8.1 潜空间的几何结构 生成器的输入空间 $\\mathcal{Z}$ 通常是高斯分布 $\\mathcal{N}(0, \\mathbf{I})$。生成器 $G$ 将这个空间映射到图像空间:\n$$G: \\mathcal{Z} \\to \\mathcal{X}$$\n关键洞察:\n$\\mathcal{Z}$ 中的每个点对应一个图像 $\\mathcal{Z}$ 中的路径对应图像的连续变换 $\\mathcal{Z}$ 中的线性方向对应图像属性的变化 8.2 潜空间插值 潜空间插值是 GAN 最重要的应用之一。给定两个噪声向量 $\\mathbf{z}_1$ 和 $\\mathbf{z}_2$,我们可以插值:\n$$\\mathbf{z}(\\alpha) = (1-\\alpha)\\mathbf{z}_1 + \\alpha\\mathbf{z}_2, \\quad \\alpha \\in [0, 1]$$\n生成图像序列:\n$$G(\\mathbf{z}(\\alpha))$$\n图 4：潜空间插值的可视化。通过在两个噪声向量之间线性插值，我们可以获得从一种图像到另一种图像的平滑过渡\n数学解释:\n$\\alpha = 0$: 第一张图像 $G(\\mathbf{z}_1)$ $\\alpha = 1$: 第二张图像 $G(\\mathbf{z}_2)$ $\\alpha \\in (0, 1)$: 中间状态的图像 8.3 属性控制 通过在潜空间中移动,我们可以控制图像的特定属性:\n$$\\mathbf{z}’ = \\mathbf{z} + \\alpha \\mathbf{v}_{\\text{attribute}}$$\n其中 $\\mathbf{v}_{\\text{attribute}}$ 是对应某个属性的向量方向。\n常见属性:\n年龄:年轻 $\\leftrightarrow$ 年老 朝向:左 $\\leftrightarrow$ 右 发型:长发 $\\leftrightarrow$ 短发 表情:微笑 $\\leftrightarrow$ 严肃 挑战:\n如何找到属性向量? 如何保证属性互不干扰? 如何实现精确控制? 第九章：训练实践与技巧 9.1 训练损失曲线 GAN 的训练损失曲线有独特的模式。\n图 5：典型的 GAN 训练损失曲线。判别器和生成器的损失会相互振荡，最终趋于平衡\n观察:\n判别器损失:先下降,然后稳定在某个值附近 生成器损失:通常较高,然后缓慢下降 震荡:两个网络对抗导致损失振荡 正常 vs 异常:\n正常:损失合理波动,生成质量逐步提升 异常:损失持续上升或趋于零,生成质量退化 9.2 实用技巧 判别器更新频率:\n通常更新 $k$ 次判别器,再更新 $1$ 次生成器 推荐 $k \\in [3, 5]$ 学习率选择:\n生成器和判别器可以使用不同学习率 推荐: $10^{-4}$ 到 $10^{-3}$ 使用 Adam 优化器, $\\beta_1 = 0.5$ (而非 $0.9$) 噪声分布:\n推荐:标准高斯分布 $\\mathcal{N}(0, \\mathbf{I})$ 维度:通常 $100$ 到 $512$ 归一化:\n输入图像归一化到 $[-1, 1]$ 使用 tanh 作为生成器输出层激活函数 9.3 调试策略 先训练判别器:\n暂时固定生成器,训练判别器 确保判别器能准确区分真实和伪造样本 检查梯度:\n使用梯度裁剪或梯度惩罚 避免梯度爆炸或消失 监控生成质量:\n定期保存生成样本 观察质量变化趋势 调整超参数:\n学习率、批大小、网络架构 使用网格搜索或贝叶斯优化 结语:博弈与合作的平衡 生成对抗网络的美妙之处在于它将生成问题转化为一个博弈论问题。生成器和判别器在对抗中相互促进,最终达到纳什均衡。\n从数学角度看,GAN 最小化生成分布与真实分布之间的距离。从工程角度看,GAN 是两个神经网络的对抗训练。从艺术角度看,GAN 是创造与鉴别的永恒博弈。\n但 GAN 的故事远未结束。新的架构、新的理论、新的应用层出不穷。从 DCGAN 到 StyleGAN,从 WGAN 到 BigGAN,每个进展都推动着生成式 AI 的边界。\n在这个混沌的世界中,GAN 提供了一种从噪声中创造秩序的方法。就像那位艺术鉴赏家和伪造艺术家的博弈,最终的赢家不是某一方,而是整个系统——一个能够创造逼真世界的系统。\n参考文献 Goodfellow, I., et al. (2014). “Generative Adversarial Nets.” NeurIPS. Radford, A., et al. (2015). “Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks.” ICLR. Arjovsky, M., et al. (2017). “Wasserstein GAN.” ICML. Karras, T., et al. (2018). “Progressive Growing of GANs for Improved Quality, Stability, and Variation.” ICLR. Miyato, T., et al. (2018). “Spectral Normalization for Generative Adversarial Networks.” ICLR. Zhu, J.-Y., et al. (2017). “Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks.” ICCV. Karras, T., et al. (2019). “A Style-Based Generator Architecture for GANs.” CVPR. Brock, A., et al. (2018). “Large Scale GAN Training for High Fidelity Natural Image Synthesis.” ICLR. ","wordCount":"1458","inLanguage":"en","image":"https://s-ai-unix.github.io/images/covers/gan-abstract.jpg","datePublished":"2026-01-24T11:45:00+08:00","dateModified":"2026-01-24T11:45:00+08:00","author":{"@type":"Person","name":"s-ai-unix"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://s-ai-unix.github.io/posts/2026-01-24-gan-comprehensive-guide/"},"publisher":{"@type":"Organization","name":"s-ai-unix's Blog","logo":{"@type":"ImageObject","url":"https://s-ai-unix.github.io/favicon.ico"}}}</script><link rel=stylesheet href=https://s-ai-unix.github.io/css/classical-quote.css></head><body id=top><header class=header><nav class=nav><div class=logo><a href=https://s-ai-unix.github.io/ accesskey=h title="s-ai-unix's Blog (Alt + H)">s-ai-unix's Blog</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://s-ai-unix.github.io/ title="🏠 首页"><span>🏠 首页</span></a></li><li><a href=https://s-ai-unix.github.io/posts/ title="📚 文章"><span>📚 文章</span></a></li><li><a href=https://s-ai-unix.github.io/archives/ title="📁 归档"><span>📁 归档</span></a></li><li><a href=https://s-ai-unix.github.io/tags/ title="🏷️ 标签"><span>🏷️ 标签</span></a></li><li><a href=https://s-ai-unix.github.io/search/ title="🔍 搜索 (Alt + /)" accesskey=/><span>🔍 搜索</span></a></li><li><a href=https://s-ai-unix.github.io/about/ title="👤 关于"><span>👤 关于</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://s-ai-unix.github.io/>Home</a>&nbsp;»&nbsp;<a href=https://s-ai-unix.github.io/posts/>Posts</a></div><h1 class="post-title entry-hint-parent">生成对抗网络：从混沌中创造秩序的博弈论</h1><div class=post-description>深入探讨生成对抗网络（GAN）的数学原理、训练挑战与应用前景</div><div class=post-meta><span title='2026-01-24 11:45:00 +0800 CST'>January 24, 2026</span>&nbsp;·&nbsp;<span>7 min</span>&nbsp;·&nbsp;<span>1458 words</span>&nbsp;·&nbsp;<span>s-ai-unix</span></div></header><figure class=entry-cover><a href=https://s-ai-unix.github.io/images/covers/gan-abstract.jpg target=_blank rel="noopener noreferrer"><img loading=eager src=https://s-ai-unix.github.io/images/covers/gan-abstract.jpg alt=生成对抗网络的抽象艺术表现></a><figcaption>生成器与判别器的永恒博弈</figcaption></figure><div class=toc><details open><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#%e5%bc%95%e8%a8%80%e4%bb%8e%e6%b7%b7%e6%b2%8c%e4%b8%ad%e5%88%9b%e9%80%a0%e7%a7%a9%e5%ba%8f aria-label=引言：从混沌中创造秩序>引言：从混沌中创造秩序</a><ul><li><a href=#%e7%ac%ac%e4%b8%80%e7%ab%a0%e7%94%9f%e6%88%90%e9%97%ae%e9%a2%98%e7%9a%84%e6%9c%ac%e8%b4%a8 aria-label=第一章：生成问题的本质>第一章：生成问题的本质</a><ul><li><a href=#11-%e4%bc%a0%e7%bb%9f%e7%94%9f%e6%88%90%e6%96%b9%e6%b3%95 aria-label="1.1 传统生成方法">1.1 传统生成方法</a></li><li><a href=#12-gan-%e7%9a%84%e7%aa%81%e7%a0%b4%e6%80%9d%e6%83%b3 aria-label="1.2 GAN 的突破思想">1.2 GAN 的突破思想</a></li></ul></li><li><a href=#%e7%ac%ac%e4%ba%8c%e7%ab%a0%e6%95%b0%e5%ad%a6%e6%a1%86%e6%9e%b6%e4%b8%8e%e7%9b%ae%e6%a0%87%e5%87%bd%e6%95%b0 aria-label=第二章：数学框架与目标函数>第二章：数学框架与目标函数</a><ul><li><a href=#21-%e6%9e%81%e5%a4%a7%e6%9e%81%e5%b0%8f%e5%8d%9a%e5%bc%88 aria-label="2.1 极大极小博弈">2.1 极大极小博弈</a></li><li><a href=#22-%e5%88%a4%e5%88%ab%e5%99%a8%e7%9a%84%e6%9c%80%e4%bc%98%e8%a7%a3 aria-label="2.2 判别器的最优解">2.2 判别器的最优解</a></li><li><a href=#23-%e7%94%9f%e6%88%90%e5%99%a8%e7%9a%84%e7%9b%ae%e6%a0%87%e5%87%bd%e6%95%b0 aria-label="2.3 生成器的目标函数">2.3 生成器的目标函数</a></li><li><a href=#24-%e5%ae%9e%e9%99%85%e8%ae%ad%e7%bb%83%e8%bf%87%e7%a8%8b aria-label="2.4 实际训练过程">2.4 实际训练过程</a></li></ul></li><li><a href=#%e7%ac%ac%e4%b8%89%e7%ab%a0gan-%e7%9a%84%e6%9e%b6%e6%9e%84%e4%b8%8e%e5%ae%9e%e7%8e%b0 aria-label="第三章：GAN 的架构与实现">第三章：GAN 的架构与实现</a><ul><li><a href=#31-%e7%a5%9e%e7%bb%8f%e7%bd%91%e7%bb%9c%e5%9f%ba%e7%a1%80 aria-label="3.1 神经网络基础">3.1 神经网络基础</a></li><li><a href=#32-gan-%e7%9a%84%e5%85%b7%e4%bd%93%e5%ae%9e%e7%8e%b0 aria-label="3.2 GAN 的具体实现">3.2 GAN 的具体实现</a></li><li><a href=#33-gan-%e6%9e%b6%e6%9e%84%e5%9b%be aria-label="3.3 GAN 架构图">3.3 GAN 架构图</a></li></ul></li><li><a href=#%e7%ac%ac%e5%9b%9b%e7%ab%a0%e8%ae%ad%e7%bb%83%e7%9a%84%e6%8c%91%e6%88%98%e4%b8%8e%e8%a7%a3%e5%86%b3%e6%96%b9%e6%a1%88 aria-label=第四章：训练的挑战与解决方案>第四章：训练的挑战与解决方案</a><ul><li><a href=#41-%e6%a8%a1%e5%bc%8f%e5%b4%a9%e6%ba%83 aria-label="4.1 模式崩溃">4.1 模式崩溃</a></li><li><a href=#42-%e6%94%b6%e6%95%9b%e6%80%a7%e9%97%ae%e9%a2%98 aria-label="4.2 收敛性问题">4.2 收敛性问题</a></li><li><a href=#43-%e8%af%84%e4%bc%b0%e5%9b%b0%e9%9a%be aria-label="4.3 评估困难">4.3 评估困难</a></li></ul></li><li><a href=#%e7%ac%ac%e4%ba%94%e7%ab%a0%e9%ab%98%e7%ba%a7-gan-%e6%9e%b6%e6%9e%84 aria-label="第五章：高级 GAN 架构">第五章：高级 GAN 架构</a><ul><li><a href=#51-dcgan%e6%b7%b1%e5%ba%a6%e5%8d%b7%e7%a7%af%e7%94%9f%e6%88%90%e5%af%b9%e6%8a%97%e7%bd%91%e7%bb%9c aria-label="5.1 DCGAN:深度卷积生成对抗网络">5.1 DCGAN:深度卷积生成对抗网络</a></li><li><a href=#52-wganwasserstein-gan aria-label="5.2 WGAN:Wasserstein GAN">5.2 WGAN:Wasserstein GAN</a></li><li><a href=#53-sngan%e8%b0%b1%e5%bd%92%e4%b8%80%e5%8c%96 aria-label="5.3 SNGAN:谱归一化">5.3 SNGAN:谱归一化</a></li><li><a href=#54-js-%e6%95%a3%e5%ba%a6-vs-wasserstein-%e8%b7%9d%e7%a6%bb aria-label="5.4 JS 散度 vs Wasserstein 距离">5.4 JS 散度 vs Wasserstein 距离</a></li><li><a href=#55-stylegan%e5%9f%ba%e4%ba%8e%e9%a3%8e%e6%a0%bc%e7%9a%84%e7%94%9f%e6%88%90 aria-label="5.5 StyleGAN:基于风格的生成">5.5 StyleGAN:基于风格的生成</a></li><li><a href=#56-%e6%9d%a1%e4%bb%b6-gan aria-label="5.6 条件 GAN">5.6 条件 GAN</a></li></ul></li><li><a href=#%e7%ac%ac%e5%85%ad%e7%ab%a0%e5%ae%9e%e9%99%85%e5%ba%94%e7%94%a8 aria-label=第六章：实际应用>第六章：实际应用</a><ul><li><a href=#61-%e5%9b%be%e5%83%8f%e7%94%9f%e6%88%90%e4%b8%8e%e7%bc%96%e8%be%91 aria-label="6.1 图像生成与编辑">6.1 图像生成与编辑</a></li><li><a href=#62-%e5%9b%be%e5%83%8f%e5%88%b0%e5%9b%be%e5%83%8f%e7%bf%bb%e8%af%91 aria-label="6.2 图像到图像翻译">6.2 图像到图像翻译</a></li><li><a href=#63-%e6%96%87%e6%9c%ac%e5%88%b0%e5%9b%be%e5%83%8f%e7%94%9f%e6%88%90 aria-label="6.3 文本到图像生成">6.3 文本到图像生成</a></li><li><a href=#64-%e6%95%b0%e6%8d%ae%e5%a2%9e%e5%bc%ba aria-label="6.4 数据增强">6.4 数据增强</a></li></ul></li><li><a href=#%e7%ac%ac%e4%b8%83%e7%ab%a0%e5%89%8d%e6%b2%bf%e6%96%b9%e5%90%91%e4%b8%8e%e6%8c%91%e6%88%98 aria-label=第七章：前沿方向与挑战>第七章：前沿方向与挑战</a><ul><li><a href=#71-%e5%a4%a7%e8%a7%84%e6%a8%a1-gan aria-label="7.1 大规模 GAN">7.1 大规模 GAN</a></li><li><a href=#72-3d-%e7%94%9f%e6%88%90 aria-label="7.2 3D 生成">7.2 3D 生成</a></li><li><a href=#73-%e7%90%86%e8%ae%ba%e7%aa%81%e7%a0%b4 aria-label="7.3 理论突破">7.3 理论突破</a></li><li><a href=#74-%e4%bc%a6%e7%90%86%e8%80%83%e9%87%8f aria-label="7.4 伦理考量">7.4 伦理考量</a></li></ul></li><li><a href=#%e7%ac%ac%e5%85%ab%e7%ab%a0%e6%bd%9c%e7%a9%ba%e9%97%b4%e6%8e%a2%e7%b4%a2 aria-label=第八章：潜空间探索>第八章：潜空间探索</a><ul><li><a href=#81-%e6%bd%9c%e7%a9%ba%e9%97%b4%e7%9a%84%e5%87%a0%e4%bd%95%e7%bb%93%e6%9e%84 aria-label="8.1 潜空间的几何结构">8.1 潜空间的几何结构</a></li><li><a href=#82-%e6%bd%9c%e7%a9%ba%e9%97%b4%e6%8f%92%e5%80%bc aria-label="8.2 潜空间插值">8.2 潜空间插值</a></li><li><a href=#83-%e5%b1%9e%e6%80%a7%e6%8e%a7%e5%88%b6 aria-label="8.3 属性控制">8.3 属性控制</a></li></ul></li><li><a href=#%e7%ac%ac%e4%b9%9d%e7%ab%a0%e8%ae%ad%e7%bb%83%e5%ae%9e%e8%b7%b5%e4%b8%8e%e6%8a%80%e5%b7%a7 aria-label=第九章：训练实践与技巧>第九章：训练实践与技巧</a><ul><li><a href=#91-%e8%ae%ad%e7%bb%83%e6%8d%9f%e5%a4%b1%e6%9b%b2%e7%ba%bf aria-label="9.1 训练损失曲线">9.1 训练损失曲线</a></li><li><a href=#92-%e5%ae%9e%e7%94%a8%e6%8a%80%e5%b7%a7 aria-label="9.2 实用技巧">9.2 实用技巧</a></li><li><a href=#93-%e8%b0%83%e8%af%95%e7%ad%96%e7%95%a5 aria-label="9.3 调试策略">9.3 调试策略</a></li></ul></li><li><a href=#%e7%bb%93%e8%af%ad%e5%8d%9a%e5%bc%88%e4%b8%8e%e5%90%88%e4%bd%9c%e7%9a%84%e5%b9%b3%e8%a1%a1 aria-label=结语:博弈与合作的平衡>结语:博弈与合作的平衡</a></li><li><a href=#%e5%8f%82%e8%80%83%e6%96%87%e7%8c%ae aria-label=参考文献>参考文献</a></li></ul></li></ul></div></details></div><div class=post-content><h1 id=引言从混沌中创造秩序>引言：从混沌中创造秩序<a hidden class=anchor aria-hidden=true href=#引言从混沌中创造秩序>#</a></h1><p>想象你是一位艺术鉴赏家,正在试图辨别一幅画作是大师真迹还是现代仿品。你仔细观察笔触、色彩、构图,试图找出破绽。与此同时,另一位艺术家正在努力学习大师的风格,试图创作出能骗过你的作品。这是一个永恒的博弈:一方越来越擅长伪造,另一方越来越擅长辨别。</p><p>这正是生成对抗网络的核心思想。2014年,Ian Goodfellow 在一个学术研讨会上提出了这个想法,当时有人认为这是"在酒吧里想出来的疯狂主意"。然而,这个"疯狂的主意"彻底改变了生成式人工智能的格局。</p><h2 id=第一章生成问题的本质>第一章：生成问题的本质<a hidden class=anchor aria-hidden=true href=#第一章生成问题的本质>#</a></h2><p>在深入 GAN 之前,让我们先理解什么是"生成"问题。假设我们有一个数据集,比如一堆手写数字图片。我们希望创建一个模型,能够生成"看起来像"这些手写数字的新图片。</p><p>这个问题有两个核心挑战:</p><ol><li><strong>数据分布建模</strong>: 我们需要学习数据的概率分布 $p_{data}(\mathbf{x})$,其中 $\mathbf{x}$ 表示一个样本。</li><li><strong>从分布中采样</strong>: 一旦我们学到了分布,我们需要能够从中采样来生成新样本。</li></ol><h3 id=11-传统生成方法>1.1 传统生成方法<a hidden class=anchor aria-hidden=true href=#11-传统生成方法>#</a></h3><p>在 GAN 出现之前,研究者已经尝试了多种方法:</p><p><strong>自编码器</strong>: 先将数据压缩到低维空间,然后试图从低维表示重建原始数据。但这种方法生成的样本往往模糊不清。</p><p><strong>玻尔兹曼机</strong>: 基于能量函数的方法,通过马尔可夫链蒙特卡洛采样。但训练极其困难,采样效率低。</p><p><strong>变分自编码器 (VAE)</strong>: 通过变分推断近似后验分布。数学上优美,但生成的图像仍然不够真实。</p><p>这些方法都有一个共同点:它们试图显式地建模数据分布 $p_{data}(\mathbf{x})$。这就像试图精确描述"什么样的数字图像看起来像真实的",这本身就是一个极其困难的问题。</p><h3 id=12-gan-的突破思想>1.2 GAN 的突破思想<a hidden class=anchor aria-hidden=true href=#12-gan-的突破思想>#</a></h3><p>GAN 的革命性在于:<strong>不需要显式建模数据分布</strong>。</p><p>相反,GAN 将生成问题转化为一个<strong>对抗游戏</strong>:</p><ul><li><p><strong>生成器 (Generator, $G$)</strong>: 从随机噪声 $\mathbf{z} \sim p_z(\mathbf{z})$ 出发,生成伪造样本 $\tilde{\mathbf{x}} = G(\mathbf{z})$。目标:让判别器无法区分真假。</p></li><li><p><strong>判别器 (Discriminator, $D$)</strong>: 接收一个样本 $\mathbf{x}$,判断它是来自真实数据($\mathbf{x} \sim p_{data}$)还是生成器($\tilde{\mathbf{x}} = G(\mathbf{z})$)。输出是概率 $D(\mathbf{x}) \in [0, 1]$。目标:准确区分真假。</p></li></ul><p>这是一个<strong>零和博弈</strong>:生成器试图最小化判别器的准确率,而判别器试图最大化准确率。当两者达到平衡时,生成器就"学会"了生成真实样本。</p><div class=mermaid-wrapper style="background:#fff;padding:2rem 1rem;margin:2rem 0;border-radius:8px;box-shadow:0 2px 12px rgba(0,0,0,8%)"><div class=mermaid>flowchart LR
subgraph 生成器_Generator
Z[噪声 z<br>z ~ p_z]
G[生成器 G]
Z --> G
G --> Fake[伪造样本 x̃<br>x̃ = Gz]
end
subgraph 判别器_Discriminator
Real[真实样本 x<br>x ~ p_data]
FakeIn[伪造样本 x̃]
D[判别器 D]
Real --> D
FakeIn --> D
D --> Prob[概率 Dx ∈ 0,1]
end
Fake -.->|输入| FakeIn
style Z fill:#FF6B6B,stroke:#FF6B6B,stroke-width:3px,color:#fff
style G fill:#4ECDC4,stroke:#4ECDC4,stroke-width:2px,color:#fff
style Fake fill:#FFE66D,stroke:#FFE66D,stroke-width:2px,color:#333
style Real fill:#95E1D3,stroke:#95E1D3,stroke-width:3px,color:#333
style D fill:#A8E6CF,stroke:#A8E6CF,stroke-width:2px,color:#333
style Prob fill:#DDA0DD,stroke:#DDA0DD,stroke-width:3px,color:#fff
style FakeIn fill:#FFE66D,stroke:#FFE66D,stroke-width:2px,color:#333</div></div><p><strong>图 1</strong>：GAN 的架构示意图。生成器将噪声映射为图像，判别器区分真实和伪造样本</p><h2 id=第二章数学框架与目标函数>第二章：数学框架与目标函数<a hidden class=anchor aria-hidden=true href=#第二章数学框架与目标函数>#</a></h2><h3 id=21-极大极小博弈>2.1 极大极小博弈<a hidden class=anchor aria-hidden=true href=#21-极大极小博弈>#</a></h3><p>让我们将这个想法形式化。定义:</p><ul><li>$\mathbf{z} \sim p_z(\mathbf{z})$: 先验噪声分布(通常为高斯分布)</li><li>$\mathbf{x} \sim p_{data}(\mathbf{x})$: 真实数据分布</li><li>$G(\mathbf{z}; \theta_g)$: 生成器,参数为 $\theta_g$</li><li>$D(\mathbf{x}; \theta_d)$: 判别器,参数为 $\theta_d$</li></ul><p>判别器的目标是最大化对真实样本正确分类的概率,同时最小化对生成样本的错误分类概率:</p><p>$$V(D, G) = \mathbb{E}<em>{\mathbf{x} \sim p</em>{data}(\mathbf{x})}[\log D(\mathbf{x})] + \mathbb{E}_{\mathbf{z} \sim p_z(\mathbf{z})}[\log(1 - D(G(\mathbf{z})))]$$</p><p>其中:</p><ul><li>第一项:判别器对真实样本 $\mathbf{x}$ 输出接近 $1$ 的概率</li><li>第二项:判别器对伪造样本 $G(\mathbf{z})$ 输出接近 $0$ 的概率</li></ul><p>生成器的目标是<strong>最小化</strong>这个价值函数(让判别器犯错):</p><p>$$\min_G \max_D V(D, G)$$</p><p>这就是著名的<strong>极大极小博弈</strong>。</p><h3 id=22-判别器的最优解>2.2 判别器的最优解<a hidden class=anchor aria-hidden=true href=#22-判别器的最优解>#</a></h3><p>让我们先固定生成器 $G$,求解判别器的最优解。对于任何给定的输入 $\mathbf{x}$,判别器输出 $D(\mathbf{x})$。我们想要最大化对数似然:</p><p>$$\max_{D(\mathbf{x})} \left[ p_{data}(\mathbf{x}) \log D(\mathbf{x}) + p_g(\mathbf{x}) \log(1 - D(\mathbf{x})) \right]$$</p><p>其中 $p_g(\mathbf{x})$ 是生成样本的分布。</p><p>这是一个标量优化问题。对 $D(\mathbf{x})$ 求导并令为零:</p><p>$$\frac{d}{dD(\mathbf{x})} \left[ p_{data}(\mathbf{x}) \log D(\mathbf{x}) + p_g(\mathbf{x}) \log(1 - D(\mathbf{x})) \right] = 0$$</p><p>$$\frac{p_{data}(\mathbf{x})}{D(\mathbf{x})} - \frac{p_g(\mathbf{x})}{1 - D(\mathbf{x})} = 0$$</p><p>$$p_{data}(\mathbf{x})(1 - D(\mathbf{x})) = p_g(\mathbf{x}) D(\mathbf{x})$$</p><p>$$p_{data}(\mathbf{x}) - p_{data}(\mathbf{x}) D(\mathbf{x}) = p_g(\mathbf{x}) D(\mathbf{x})$$</p><p>$$D^*(\mathbf{x}) = \frac{p_{data}(\mathbf{x})}{p_{data}(\mathbf{x}) + p_g(\mathbf{x})}$$</p><p>这是判别器的<strong>全局最优解</strong>。</p><p><strong>直观解释</strong>:判别器的输出应该等于"这个样本来自真实数据而非生成数据的概率"。如果 $p_{data}(\mathbf{x})$ 很高而 $p_g(\mathbf{x})$ 很低,那么 $D(\mathbf{x}) \approx 1$;反之则接近 $0$。</p><h3 id=23-生成器的目标函数>2.3 生成器的目标函数<a hidden class=anchor aria-hidden=true href=#23-生成器的目标函数>#</a></h3><p>有了最优判别器,我们可以将其代回价值函数:</p><p>$$V(G, D^*) = \mathbb{E}<em>{\mathbf{x} \sim p</em>{data}}\left[\log \frac{p_{data}(\mathbf{x})}{p_{data}(\mathbf{x}) + p_g(\mathbf{x})}\right] + \mathbb{E}<em>{\mathbf{x} \sim p_g}\left[\log \frac{p_g(\mathbf{x})}{p</em>{data}(\mathbf{x}) + p_g(\mathbf{x})}\right]$$</p><p>这个表达式看起来复杂,但可以简化。注意到:</p><p>$$\int [p_{data}(\mathbf{x}) \log \frac{p_{data}(\mathbf{x})}{p_{data}(\mathbf{x}) + p_g(\mathbf{x})} + p_g(\mathbf{x}) \log \frac{p_g(\mathbf{x})}{p_{data}(\mathbf{x}) + p_g(\mathbf{x})}] d\mathbf{x}$$</p><p>这可以写成:</p><p>$$\mathbb{E}<em>{\mathbf{x} \sim p</em>{data}}\left[-\log 2 - \log \left(\frac{p_{data}(\mathbf{x}) + p_g(\mathbf{x})}{2 p_{data}(\mathbf{x})}\right)\right] + \mathbb{E}<em>{\mathbf{x} \sim p_g}\left[-\log 2 - \log \left(\frac{p</em>{data}(\mathbf{x}) + p_g(\mathbf{x})}{2 p_g(\mathbf{x})}\right)\right]$$</p><p>$$= -\log 4 + \text{KL}\left(p_{data} \parallel \frac{p_{data} + p_g}{2}\right) + \text{KL}\left(p_g \parallel \frac{p_{data} + p_g}{2}\right)$$</p><p>其中 $\text{KL}$ 是 KL 散度。这个表达式恰好等于:</p><p>$$-\log 4 + 2 \cdot \text{JSD}(p_{data} \parallel p_g)$$</p><p>其中 JSD 是 Jensen-Shannon 散度。</p><p><strong>关键洞察</strong>:生成器的目标是最小化 JSD 散度。当 $p_g = p_{data}$ 时,JSD 散度为 $0$,价值函数达到最小值 $-\log 4$。</p><p><strong>结论</strong>:GAN 的训练目标是让生成分布 $p_g$ 收敛到真实数据分布 $p_{data}$。</p><h3 id=24-实际训练过程>2.4 实际训练过程<a hidden class=anchor aria-hidden=true href=#24-实际训练过程>#</a></h3><p>虽然理论分析很有趣,但实际训练时我们使用交替优化:</p><ol><li><p><strong>固定 $G$,更新 $D$</strong>:</p><ul><li>采样真实数据: ${\mathbf{x}^{(1)}, \ldots, \mathbf{x}^{(m)}} \sim p_{data}$</li><li>采样噪声: ${\mathbf{z}^{(1)}, \ldots, \mathbf{z}^{(m)}} \sim p_z$</li><li>生成伪造样本: ${\tilde{\mathbf{x}}^{(1)}, \ldots, \tilde{\mathbf{x}}^{(m)}}, \tilde{\mathbf{x}}^{(i)} = G(\mathbf{z}^{(i)})$</li><li>梯度上升:
$$\nabla_{\theta_d} \frac{1}{m} \sum_{i=1}^{m} \left[\log D(\mathbf{x}^{(i)}) + \log(1 - D(\tilde{\mathbf{x}}^{(i)}))\right]$$</li></ul></li><li><p><strong>固定 $D$,更新 $G$</strong>:</p><ul><li>采样噪声: ${\mathbf{z}^{(1)}, \ldots, \mathbf{z}^{(m)}} \sim p_z$</li><li>梯度下降:
$$\nabla_{\theta_g} \frac{1}{m} \sum_{i=1}^{m} \log(1 - D(G(\mathbf{z}^{(i)})))$$</li></ul></li></ol><p><strong>实际改进</strong>:在实践中,生成器通常最大化 $\log D(G(\mathbf{z}))$ 而不是最小化 $\log(1 - D(G(\mathbf{z})))$,因为后者在训练初期梯度会消失。</p><h2 id=第三章gan-的架构与实现>第三章：GAN 的架构与实现<a hidden class=anchor aria-hidden=true href=#第三章gan-的架构与实现>#</a></h2><h3 id=31-神经网络基础>3.1 神经网络基础<a hidden class=anchor aria-hidden=true href=#31-神经网络基础>#</a></h3><p>让我们先回顾多层感知机的基本结构。一个典型的神经网络:</p><p>$$\mathbf{h}^{(l)} = \sigma(\mathbf{W}^{(l)} \mathbf{h}^{(l-1)} + \mathbf{b}^{(l)})$$</p><p>其中:</p><ul><li>$\mathbf{W}^{(l)} \in \mathbb{R}^{n^{(l)} \times n^{(l-1)}}$: 第 $l$ 层的权重矩阵</li><li>$\mathbf{b}^{(l)} \in \mathbb{R}^{n^{(l)}}$: 第 $l$ 层的偏置向量</li><li>$\sigma(\cdot)$: 激活函数(如 ReLU, sigmoid, tanh)</li><li>$\mathbf{h}^{(0)} = \mathbf{x}$: 输入</li><li>$\mathbf{h}^{(L)}$: 输出</li></ul><p><strong>反向传播</strong>:训练神经网络的核心是反向传播算法。给定损失函数 $L$,我们使用链式法则计算梯度:</p><p>$$\frac{\partial L}{\partial \mathbf{W}^{(l)}} = \frac{\partial L}{\partial \mathbf{h}^{(l)}} \cdot \frac{\partial \mathbf{h}^{(l)}}{\partial \mathbf{z}^{(l)}} \cdot \frac{\partial \mathbf{z}^{(l)}}{\partial \mathbf{W}^{(l)}}$$</p><p>其中 $\mathbf{z}^{(l)} = \mathbf{W}^{(l)} \mathbf{h}^{(l-1)} + \mathbf{b}^{(l)}$。</p><h3 id=32-gan-的具体实现>3.2 GAN 的具体实现<a hidden class=anchor aria-hidden=true href=#32-gan-的具体实现>#</a></h3><p>让我们看看 GAN 的具体实现。假设我们生成 $64 \times 64$ 的 RGB 图像。</p><p><strong>生成器 $G$</strong>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># 输入: 噪声向量 z ∈ R^100</span>
</span></span><span class=line><span class=cl><span class=c1># 输出: 图像 x ∈ R^(64×64×3)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 第一层: 全连接层 + Reshape</span>
</span></span><span class=line><span class=cl><span class=n>z</span> <span class=err>→</span> <span class=n>Dense</span><span class=p>(</span><span class=mi>4</span><span class=err>×</span><span class=mi>4</span><span class=err>×</span><span class=mi>512</span><span class=p>)</span> <span class=err>→</span> <span class=n>Reshape</span><span class=p>(</span><span class=mi>4</span><span class=p>,</span> <span class=mi>4</span><span class=p>,</span> <span class=mi>512</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 上采样层 (使用转置卷积或上采样 + 卷积)</span>
</span></span><span class=line><span class=cl><span class=mi>4</span><span class=err>×</span><span class=mi>4</span><span class=err>×</span><span class=mi>512</span> <span class=err>→</span> <span class=n>Conv2DTranspose</span><span class=p>(</span><span class=mi>256</span><span class=p>,</span> <span class=mi>5</span><span class=err>×</span><span class=mi>5</span><span class=p>,</span> <span class=n>stride</span><span class=o>=</span><span class=mi>2</span><span class=p>)</span> <span class=err>→</span> <span class=mi>8</span><span class=err>×</span><span class=mi>8</span><span class=err>×</span><span class=mi>256</span>
</span></span><span class=line><span class=cl><span class=mi>8</span><span class=err>×</span><span class=mi>8</span><span class=err>×</span><span class=mi>256</span> <span class=err>→</span> <span class=n>BatchNorm</span> <span class=err>→</span> <span class=n>ReLU</span>
</span></span><span class=line><span class=cl><span class=mi>8</span><span class=err>×</span><span class=mi>8</span><span class=err>×</span><span class=mi>256</span> <span class=err>→</span> <span class=n>Conv2DTranspose</span><span class=p>(</span><span class=mi>128</span><span class=p>,</span> <span class=mi>5</span><span class=err>×</span><span class=mi>5</span><span class=p>,</span> <span class=n>stride</span><span class=o>=</span><span class=mi>2</span><span class=p>)</span> <span class=err>→</span> <span class=mi>16</span><span class=err>×</span><span class=mi>16</span><span class=err>×</span><span class=mi>128</span>
</span></span><span class=line><span class=cl><span class=mi>16</span><span class=err>×</span><span class=mi>16</span><span class=err>×</span><span class=mi>128</span> <span class=err>→</span> <span class=n>BatchNorm</span> <span class=err>→</span> <span class=n>ReLU</span>
</span></span><span class=line><span class=cl><span class=mi>16</span><span class=err>×</span><span class=mi>16</span><span class=err>×</span><span class=mi>128</span> <span class=err>→</span> <span class=n>Conv2DTranspose</span><span class=p>(</span><span class=mi>64</span><span class=p>,</span> <span class=mi>5</span><span class=err>×</span><span class=mi>5</span><span class=p>,</span> <span class=n>stride</span><span class=o>=</span><span class=mi>2</span><span class=p>)</span> <span class=err>→</span> <span class=mi>32</span><span class=err>×</span><span class=mi>32</span><span class=err>×</span><span class=mi>64</span>
</span></span><span class=line><span class=cl><span class=mi>32</span><span class=err>×</span><span class=mi>32</span><span class=err>×</span><span class=mi>64</span> <span class=err>→</span> <span class=n>BatchNorm</span> <span class=err>→</span> <span class=n>ReLU</span>
</span></span><span class=line><span class=cl><span class=mi>32</span><span class=err>×</span><span class=mi>32</span><span class=err>×</span><span class=mi>64</span> <span class=err>→</span> <span class=n>Conv2DTranspose</span><span class=p>(</span><span class=mi>3</span><span class=p>,</span> <span class=mi>5</span><span class=err>×</span><span class=mi>5</span><span class=p>,</span> <span class=n>stride</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span> <span class=n>activation</span><span class=o>=</span><span class=s1>&#39;tanh&#39;</span><span class=p>)</span> <span class=err>→</span> <span class=mi>64</span><span class=err>×</span><span class=mi>64</span><span class=err>×</span><span class=mi>3</span>
</span></span></code></pre></div><p><strong>判别器 $D$</strong>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># 输入: 图像 x ∈ R^(64×64×3)</span>
</span></span><span class=line><span class=cl><span class=c1># 输出: 概率 D(x) ∈ [0, 1]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=mi>64</span><span class=err>×</span><span class=mi>64</span><span class=err>×</span><span class=mi>3</span> <span class=err>→</span> <span class=n>Conv2D</span><span class=p>(</span><span class=mi>64</span><span class=p>,</span> <span class=mi>5</span><span class=err>×</span><span class=mi>5</span><span class=p>,</span> <span class=n>stride</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span> <span class=n>leaky_relu</span><span class=p>)</span> <span class=err>→</span> <span class=mi>32</span><span class=err>×</span><span class=mi>32</span><span class=err>×</span><span class=mi>64</span>
</span></span><span class=line><span class=cl><span class=mi>32</span><span class=err>×</span><span class=mi>32</span><span class=err>×</span><span class=mi>64</span> <span class=err>→</span> <span class=n>Dropout</span><span class=p>(</span><span class=mf>0.3</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=mi>32</span><span class=err>×</span><span class=mi>32</span><span class=err>×</span><span class=mi>64</span> <span class=err>→</span> <span class=n>Conv2D</span><span class=p>(</span><span class=mi>128</span><span class=p>,</span> <span class=mi>5</span><span class=err>×</span><span class=mi>5</span><span class=p>,</span> <span class=n>stride</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span> <span class=n>leaky_relu</span><span class=p>)</span> <span class=err>→</span> <span class=mi>16</span><span class=err>×</span><span class=mi>16</span><span class=err>×</span><span class=mi>128</span>
</span></span><span class=line><span class=cl><span class=mi>16</span><span class=err>×</span><span class=mi>16</span><span class=err>×</span><span class=mi>128</span> <span class=err>→</span> <span class=n>BatchNorm</span> <span class=err>→</span> <span class=n>Dropout</span><span class=p>(</span><span class=mf>0.3</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=mi>16</span><span class=err>×</span><span class=mi>16</span><span class=err>×</span><span class=mi>128</span> <span class=err>→</span> <span class=n>Conv2D</span><span class=p>(</span><span class=mi>256</span><span class=p>,</span> <span class=mi>5</span><span class=err>×</span><span class=mi>5</span><span class=p>,</span> <span class=n>stride</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span> <span class=n>leaky_relu</span><span class=p>)</span> <span class=err>→</span> <span class=mi>8</span><span class=err>×</span><span class=mi>8</span><span class=err>×</span><span class=mi>256</span>
</span></span><span class=line><span class=cl><span class=mi>8</span><span class=err>×</span><span class=mi>8</span><span class=err>×</span><span class=mi>256</span> <span class=err>→</span> <span class=n>BatchNorm</span> <span class=err>→</span> <span class=n>Dropout</span><span class=p>(</span><span class=mf>0.3</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=mi>8</span><span class=err>×</span><span class=mi>8</span><span class=err>×</span><span class=mi>256</span> <span class=err>→</span> <span class=n>Flatten</span> <span class=err>→</span> <span class=n>Dense</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=n>activation</span><span class=o>=</span><span class=s1>&#39;sigmoid&#39;</span><span class=p>)</span>
</span></span></code></pre></div><p><strong>关键设计决策</strong>:</p><ol><li><p><strong>激活函数选择</strong>:</p><ul><li>判别器: 使用 LeakyReLU 而非 ReLU,避免"死亡神经元"</li><li>生成器: 使用 tanh 作为输出激活函数(输出范围 $[-1, 1]$)</li></ul></li><li><p><strong>批归一化 (Batch Normalization)</strong>:</p><ul><li>稳定训练,防止梯度爆炸/消失</li><li>生成器的所有层都使用,判别器的部分层使用</li></ul></li><li><p><strong>转置卷积 vs 上采样</strong>:</p><ul><li>转置卷积可能导致棋盘格效应</li><li>现代 GAN 更多使用上采样 + 卷积</li></ul></li></ol><h3 id=33-gan-架构图>3.3 GAN 架构图<a hidden class=anchor aria-hidden=true href=#33-gan-架构图>#</a></h3><div class=mermaid-wrapper style="background:#fff;padding:2rem 1rem;margin:2rem 0;border-radius:8px;box-shadow:0 2px 12px rgba(0,0,0,8%)"><div class=mermaid>graph TB
subgraph 生成器_G
Z[噪声 z<br>z ∈ R^100] --> FC1[全连接层<br>4×4×512]
FC1 --> US1[上采样层<br>8×8×256]
US1 --> US2[上采样层<br>16×16×128]
US2 --> US3[上采样层<br>32×32×64]
US3 --> US4[上采样层<br>64×64×3]
US4 --> X_hat[生成图像<br>x̃ = Gz]
end
subgraph 判别器_D
X[真实图像<br>x ∈ R^64×64×3]
X_hat_in[生成图像<br>x̃ = Gz]
X --> C1[卷积层<br>32×32×64]
X_hat_in --> C1
C1 --> C2[卷积层<br>16×16×128]
C2 --> C3[卷积层<br>8×8×256]
C3 --> F[展平层]
F --> OUT[输出概率<br>Dx ∈ 0 1]
end
style Z fill:#FF9500,stroke:#FF9500,stroke-width:3px,color:#ffffff
style X fill:#34C759,stroke:#34C759,stroke-width:3px,color:#ffffff
style X_hat fill:#FF9500,stroke:#FF9500,stroke-width:2px,color:#ffffff
style X_hat_in fill:#FF9500,stroke:#FF9500,stroke-width:2px,color:#ffffff
style FC1 fill:#5AC8FA,stroke:#5AC8FA,stroke-width:2px,color:#ffffff
style US1 fill:#5AC8FA,stroke:#5AC8FA,stroke-width:1px,color:#ffffff
style US2 fill:#5AC8FA,stroke:#5AC8FA,stroke-width:1px,color:#ffffff
style US3 fill:#5AC8FA,stroke:#5AC8FA,stroke-width:1px,color:#ffffff
style US4 fill:#5AC8FA,stroke:#5AC8FA,stroke-width:1px,color:#ffffff
style C1 fill:#AF52DE,stroke:#AF52DE,stroke-width:2px,color:#ffffff
style C2 fill:#AF52DE,stroke:#AF52DE,stroke-width:2px,color:#ffffff
style C3 fill:#AF52DE,stroke:#AF52DE,stroke-width:2px,color:#ffffff
style F fill:#AF52DE,stroke:#AF52DE,stroke-width:1px,color:#ffffff
style OUT fill:#FF3B30,stroke:#FF3B30,stroke-width:3px,color:#ffffff</div></div><h2 id=第四章训练的挑战与解决方案>第四章：训练的挑战与解决方案<a hidden class=anchor aria-hidden=true href=#第四章训练的挑战与解决方案>#</a></h2><p>GAN 的理论虽然优美,但实际训练极其困难。让我们探讨主要挑战和解决方案。</p><h3 id=41-模式崩溃>4.1 模式崩溃<a hidden class=anchor aria-hidden=true href=#41-模式崩溃>#</a></h3><p><strong>问题描述</strong>:生成器可能学会只生成少数几种样本,无法覆盖数据分布的多样性。</p><p><strong>原因分析</strong>:假设判别器对某一类样本输出 $D(\mathbf{x}) \approx 0.5$,生成器发现欺骗判别器最简单的方法是只生成这一类样本。</p><p><strong>解决方案</strong>:</p><ol><li><p><strong>小批量判别 (Mini-batch Discrimination)</strong>:</p><ul><li>让判别器能够判断"一个小批量的样本是否都来自同一分布"</li><li>特征之间的相似度被纳入考虑</li></ul></li><li><p><strong>特征匹配 (Feature Matching)</strong>:</p><ul><li>生成器不再试图欺骗判别器的输出,而是匹配判别器中间层的统计量</li><li>目标:让生成样本的激活统计量与真实样本相似</li></ul></li><li><p><strong>使用不同架构</strong>:</p><ul><li>WGAN-GP:使用 Wasserstein 距离</li><li>SNGAN:谱归一化</li><li>BigGAN:自注意力机制</li></ul></li></ol><h3 id=42-收敛性问题>4.2 收敛性问题<a hidden class=anchor aria-hidden=true href=#42-收敛性问题>#</a></h3><p><strong>问题描述</strong>:GAN 的训练是两个网络的对抗,容易陷入不稳定状态。</p><p><strong>原因分析</strong>:</p><ul><li>纳什均衡的存在性和可达性</li><li>两个网络的训练速度不匹配</li><li>梯度在训练过程中震荡</li></ul><p><strong>解决方案</strong>:</p><ol><li><p><strong>标签平滑 (Label Smoothing)</strong>:</p><ul><li>不使用硬标签 ${0, 1}$,而是使用 ${0.1, 0.9}$</li><li>防止判别器过度自信</li></ul></li><li><p><strong>梯度惩罚 (Gradient Penalty)</strong>:</p><ul><li>WGAN-GP 引入梯度约束</li><li>目标:让判别器的梯度在真实和生成样本之间保持一致</li></ul></li><li><p><strong>学习率调度</strong>:</p><ul><li>使用不同的学习率</li><li>使用衰减学习率</li></ul></li></ol><h3 id=43-评估困难>4.3 评估困难<a hidden class=anchor aria-hidden=true href=#43-评估困难>#</a></h3><p><strong>问题描述</strong>:GAN 的评估没有统一的标准。不像分类任务有准确率,生成任务的主观性很强。</p><p><strong>常用指标</strong>:</p><ol><li><p><strong>Inception Score (IS)</strong>:
$$IS(G) = \exp\left(\mathbb{E}_{\mathbf{x} \sim p_g}[\text{KL}(p(y|\mathbf{x}) \parallel p(y))]\right)$$</p><ul><li>高 IS 意味着生成图像清晰(低熵)且多样化(高熵)</li></ul></li><li><p><strong>Fréchet Inception Distance (FID)</strong>:
$$FID(p_r, p_g) = |\mathbf{\mu}_r - \mathbf{\mu}_g|^2 + \text{Tr}(\mathbf{\Sigma}_r + \mathbf{\Sigma}_g - 2(\mathbf{\Sigma}_r \mathbf{\Sigma}_g)^{1/2})$$</p><ul><li>基于 Inception 特征的距离度量</li><li>越低越好</li></ul></li><li><p><strong>人类评估</strong>:</p><ul><li>图灵测试式的评估</li><li>主观但最有说服力</li></ul></li></ol><h2 id=第五章高级-gan-架构>第五章：高级 GAN 架构<a hidden class=anchor aria-hidden=true href=#第五章高级-gan-架构>#</a></h2><h3 id=51-dcgan深度卷积生成对抗网络>5.1 DCGAN:深度卷积生成对抗网络<a hidden class=anchor aria-hidden=true href=#51-dcgan深度卷积生成对抗网络>#</a></h3><p>DCGAN 是第一个稳定训练的 GAN 架构,奠定了后续发展的基础。</p><p><strong>关键改进</strong>:</p><ol><li><p><strong>使用卷积层而非全连接层</strong>:</p><ul><li>判别器使用步长卷积(strided convolution)代替池化</li><li>生成器使用转置卷积或上采样</li></ul></li><li><p><strong>批归一化</strong>:</p><ul><li>在生成器和判别器中都使用</li><li>稳定训练,防止梯度问题</li></ul></li><li><p><strong>架构设计</strong>:</p><ul><li>去除全连接层</li><li>生成器除输出层外使用 ReLU</li><li>判别器所有层都使用 LeakyReLU</li></ul></li></ol><p><strong>几何直观</strong>:卷积操作捕捉空间层次结构,从低级特征(边缘、纹理)到高级特征(形状、物体)。</p><h3 id=52-wganwasserstein-gan>5.2 WGAN:Wasserstein GAN<a hidden class=anchor aria-hidden=true href=#52-wganwasserstein-gan>#</a></h3><p>WGAN 的核心思想是使用 Wasserstein 距离代替 JS 散度。</p><p><strong>Wasserstein 距离(地球移动距离)</strong>:</p><p>$$W(p_r, p_g) = \inf_{\gamma \in \Pi(p_r, p_g)} \mathbb{E}_{(\mathbf{x}, \mathbf{y}) \sim \gamma}[|\mathbf{x} - \mathbf{y}|]$$</p><p>其中 $\Pi(p_r, p_g)$ 是所有联合分布的集合,满足边缘分布分别为 $p_r$ 和 $p_g$。</p><p><strong>直观解释</strong>:将分布 $p_r$ 的"土堆"移动到 $p_g$ 的"坑洞"所需的最小"功"。</p><p><img alt="Wasserstein 距离的直观理解" loading=lazy src=/images/math/wasserstein-distance.png></p><p><strong>图 2</strong>：Wasserstein 距离的几何直观。我们需要将真实分布的质量移动到生成分布的位置，最小化所需的"功"</p><p><strong>关键优势</strong>:</p><ol><li><strong>更好的梯度性质</strong>:即使分布没有重叠,Wasserstein 距离仍然提供有意义的梯度</li><li><strong>与训练稳定性相关</strong>:判别器的损失可以用于衡量训练进度</li></ol><p><strong>WGAN-GP 的改进</strong>:</p><ul><li>使用梯度惩罚代替权重裁剪</li><li>目标:让判别器的梯度范数接近 $1$</li><li>更稳定的训练</li></ul><h3 id=53-sngan谱归一化>5.3 SNGAN:谱归一化<a hidden class=anchor aria-hidden=true href=#53-sngan谱归一化>#</a></h3><p>SNGAN 通过谱归一化(Spectral Normalization)稳定判别器的训练。</p><p><strong>谱归一化的定义</strong>:</p><p>$$\bar{\mathbf{W}}_{SN} = \frac{\mathbf{W}}{\sigma(\mathbf{W})}$$</p><p>其中 $\sigma(\mathbf{W})$ 是权重矩阵 $\mathbf{W}$ 的谱范数(最大奇异值)。</p><p><strong>效果</strong>:</p><ul><li>限制判别器的 Lipschitz 常数</li><li>稳定训练,不需要批归一化</li><li>适用于各种架构</li></ul><h3 id=54-js-散度-vs-wasserstein-距离>5.4 JS 散度 vs Wasserstein 距离<a hidden class=anchor aria-hidden=true href=#54-js-散度-vs-wasserstein-距离>#</a></h3><p>理解为什么 Wasserstein 距离比 JS 散度更好,我们需要看它们的性质。</p><p><img alt="JS 散度 vs Wasserstein 距离" loading=lazy src=/images/math/js-vs-wasserstein.png></p><p><strong>图 3</strong>：JS 散度与 Wasserstein 距离的对比。当两个分布没有重叠时，JS 散度饱和而 Wasserstein 距离继续提供有意义的梯度</p><p><strong>JS 散度的局限</strong>:</p><ul><li>当 $p_r$ 和 $p_g$ 没有重叠时,JS 散度为 $\log 2$</li><li>这意味着梯度消失,生成器无法学习</li></ul><p><strong>Wasserstein 距离的优势</strong>:</p><ul><li>即使分布没有重叠,仍然提供有意义的梯度</li><li>与分布的支撑集无关</li><li>更好的训练稳定性</li></ul><h3 id=55-stylegan基于风格的生成>5.5 StyleGAN:基于风格的生成<a hidden class=anchor aria-hidden=true href=#55-stylegan基于风格的生成>#</a></h3><p>StyleGAN 引入了"风格迁移"的思想,将图像分解为风格和内容。</p><p><strong>核心思想</strong>:</p><ol><li><p><strong>风格编码器</strong>:</p><ul><li>将噪声 $\mathbf{z}$ 映射到风格向量 $\mathbf{w}$</li><li>风格向量控制图像的高级属性(年龄、姿态等)</li></ul></li><li><p><strong>自适应实例归一化</strong>:
$$\text{AdaIN}(\mathbf{x}<em>i, \mathbf{y}) = \mathbf{y}</em>{s,i} \frac{\mathbf{x}_i - \mu(\mathbf{x}_i)}{\sigma(\mathbf{x}<em>i)} + \mathbf{y}</em>{b,i}$$</p><ul><li>使用风格向量对特征进行归一化</li><li>$\mathbf{y}_s$ 控制尺度,$\mathbf{y}_b$ 控制偏移</li></ul></li><li><p><strong>潜在空间解耦</strong>:</p><ul><li>将风格空间与潜在空间分离</li><li>更好的属性可控性</li></ul></li></ol><p><strong>效果</strong>:生成极高保真度的人脸图像,支持精细的属性控制。</p><h3 id=56-条件-gan>5.6 条件 GAN<a hidden class=anchor aria-hidden=true href=#56-条件-gan>#</a></h3><p>条件 GAN 在生成器中引入条件信息。</p><p><strong>架构变化</strong>:</p><p>$$G(\mathbf{z}, \mathbf{y}) \to \tilde{\mathbf{x}}$$
$$D(\mathbf{x}, \mathbf{y}) \to \text{真/假}$$</p><p>其中 $\mathbf{y}$ 是条件信息(类别标签、文本描述等)。</p><p><strong>应用场景</strong>:</p><ul><li>文本到图像生成</li><li>类别条件生成</li><li>图像到图像翻译</li></ul><h2 id=第六章实际应用>第六章：实际应用<a hidden class=anchor aria-hidden=true href=#第六章实际应用>#</a></h2><h3 id=61-图像生成与编辑>6.1 图像生成与编辑<a hidden class=anchor aria-hidden=true href=#61-图像生成与编辑>#</a></h3><p><strong>应用举例</strong>:</p><ul><li>人脸生成:StyleGAN 可以生成逼真的人脸</li><li>超分辨率:SRGAN 将低分辨率图像提升到高分辨率</li><li>图像修复:Context Encoders 可以修复图像中的缺失部分</li></ul><p><strong>数学原理</strong>:GAN 学习数据分布的流形(manifold)。通过在潜空间中插值,可以实现平滑的图像变换。</p><h3 id=62-图像到图像翻译>6.2 图像到图像翻译<a hidden class=anchor aria-hidden=true href=#62-图像到图像翻译>#</a></h3><p><strong>Pix2Pix</strong>:</p><ul><li>使用条件 GAN 进行配对图像的翻译</li><li>应用:语义分割到图像、灰度到彩色、航拍到地图</li></ul><p><strong>CycleGAN</strong>:</p><ul><li>无配对数据的图像到图像翻译</li><li>引入循环一致性损失(cycle consistency loss)</li><li>应用:马到斑马、夏天到冬天、照片到画作</li></ul><p><strong>CycleGAN 的核心思想</strong>:</p><p>对于两个域 $\mathcal{X}$ 和 $\mathcal{Y}$,定义两个生成器:</p><ul><li>$G: \mathcal{X} \to \mathcal{Y}$</li><li>$F: \mathcal{Y} \to \mathcal{X}$</li></ul><p>循环一致性损失:</p><p>$$\mathcal{L}<em>{cyc} = \mathbb{E}</em>{\mathbf{x} \sim p_{\mathcal{X}}}[|F(G(\mathbf{x})) - \mathbf{x}|<em>1] + \mathbb{E}</em>{\mathbf{y} \sim p_{\mathcal{Y}}}[|G(F(\mathbf{y})) - \mathbf{y}|_1]$$</p><p><strong>直观解释</strong>:将图像从 $\mathcal{X}$ 转换到 $\mathcal{Y}$,再转换回 $\mathcal{X}$,应该得到原图。</p><h3 id=63-文本到图像生成>6.3 文本到图像生成<a hidden class=anchor aria-hidden=true href=#63-文本到图像生成>#</a></h3><p><strong>StackGAN</strong>:</p><ul><li>分阶段生成:先生成粗略草图,再精细化</li><li>使用文本编码器提取文本特征</li></ul><p><strong>AttnGAN</strong>:</p><ul><li>引入注意力机制,关注文本的不同部分</li><li>更精细的文本-图像对应</li></ul><p><strong>数学挑战</strong>:</p><ul><li>文本是离散的,图像是连续的</li><li>需要将文本编码为连续的潜在向量</li></ul><h3 id=64-数据增强>6.4 数据增强<a hidden class=anchor aria-hidden=true href=#64-数据增强>#</a></h3><p>GAN 可以用于生成合成数据,增强训练集。</p><p><strong>优势</strong>:</p><ul><li>生成与真实数据相似的样本</li><li>适用于数据稀缺的场景</li><li>可以控制生成样本的属性</li></ul><p><strong>注意事项</strong>:</p><ul><li>生成质量必须足够高</li><li>避免过度依赖合成数据</li><li>需要验证合成数据的有效性</li></ul><h2 id=第七章前沿方向与挑战>第七章：前沿方向与挑战<a hidden class=anchor aria-hidden=true href=#第七章前沿方向与挑战>#</a></h2><h3 id=71-大规模-gan>7.1 大规模 GAN<a hidden class=anchor aria-hidden=true href=#71-大规模-gan>#</a></h3><p>BigGAN 等架构将 GAN 推向大规模图像生成。</p><p><strong>关键改进</strong>:</p><ul><li>使用大模型(数亿参数)</li><li>批量大小增大(数千)</li><li>自注意力机制</li><li>类别条件生成</li></ul><p><strong>挑战</strong>:</p><ul><li>计算资源需求极高</li><li>训练不稳定</li><li>模式崩溃仍然存在</li></ul><h3 id=72-3d-生成>7.2 3D 生成<a hidden class=anchor aria-hidden=true href=#72-3d-生成>#</a></h3><p>GAN 正在扩展到 3D 领域。</p><p><strong>应用</strong>:</p><ul><li>3D 物体生成</li><li>点云生成</li><li>神经渲染</li></ul><p><strong>技术挑战</strong>:</p><ul><li>3D 数据表示(体素、点云、网格)</li><li>计算复杂度</li><li>评估标准</li></ul><h3 id=73-理论突破>7.3 理论突破<a hidden class=anchor aria-hidden=true href=#73-理论突破>#</a></h3><p>GAN 的理论基础仍在发展。</p><p><strong>研究方向</strong>:</p><ul><li>收敛性证明:何时 GAN 一定收敛?</li><li>分布匹配:更好的距离度量</li><li>稳定性分析:训练稳定性的理论保证</li></ul><p><strong>数学挑战</strong>:</p><ul><li>非凸优化问题</li><li>博弈论与优化的交叉</li><li>高维空间中的分布性质</li></ul><h3 id=74-伦理考量>7.4 伦理考量<a hidden class=anchor aria-hidden=true href=#74-伦理考量>#</a></h3><p>GAN 的强大能力也带来伦理问题。</p><p><strong>问题</strong>:</p><ul><li>深度伪造(Deepfake):可以生成虚假的视频和音频</li><li>隐私:从生成样本推断训练数据</li><li>偏见:继承训练数据的偏见</li></ul><p><strong>应对</strong>:</p><ul><li>检测技术:识别 GAN 生成的内容</li><li>合规使用:负责任地使用技术</li><li>公平性:确保生成模型的公平性</li></ul><h2 id=第八章潜空间探索>第八章：潜空间探索<a hidden class=anchor aria-hidden=true href=#第八章潜空间探索>#</a></h2><p>GAN 的潜空间(latent space)是一个迷人的概念。理解潜空间有助于我们更好地控制和生成图像。</p><h3 id=81-潜空间的几何结构>8.1 潜空间的几何结构<a hidden class=anchor aria-hidden=true href=#81-潜空间的几何结构>#</a></h3><p>生成器的输入空间 $\mathcal{Z}$ 通常是高斯分布 $\mathcal{N}(0, \mathbf{I})$。生成器 $G$ 将这个空间映射到图像空间:</p><p>$$G: \mathcal{Z} \to \mathcal{X}$$</p><p><strong>关键洞察</strong>:</p><ul><li>$\mathcal{Z}$ 中的每个点对应一个图像</li><li>$\mathcal{Z}$ 中的路径对应图像的连续变换</li><li>$\mathcal{Z}$ 中的线性方向对应图像属性的变化</li></ul><h3 id=82-潜空间插值>8.2 潜空间插值<a hidden class=anchor aria-hidden=true href=#82-潜空间插值>#</a></h3><p>潜空间插值是 GAN 最重要的应用之一。给定两个噪声向量 $\mathbf{z}_1$ 和 $\mathbf{z}_2$,我们可以插值:</p><p>$$\mathbf{z}(\alpha) = (1-\alpha)\mathbf{z}_1 + \alpha\mathbf{z}_2, \quad \alpha \in [0, 1]$$</p><p>生成图像序列:</p><p>$$G(\mathbf{z}(\alpha))$$</p><p><img alt=潜空间插值 loading=lazy src=/images/math/latent-interpolation.png></p><p><strong>图 4</strong>：潜空间插值的可视化。通过在两个噪声向量之间线性插值，我们可以获得从一种图像到另一种图像的平滑过渡</p><p><strong>数学解释</strong>:</p><ul><li>$\alpha = 0$: 第一张图像 $G(\mathbf{z}_1)$</li><li>$\alpha = 1$: 第二张图像 $G(\mathbf{z}_2)$</li><li>$\alpha \in (0, 1)$: 中间状态的图像</li></ul><h3 id=83-属性控制>8.3 属性控制<a hidden class=anchor aria-hidden=true href=#83-属性控制>#</a></h3><p>通过在潜空间中移动,我们可以控制图像的特定属性:</p><p>$$\mathbf{z}&rsquo; = \mathbf{z} + \alpha \mathbf{v}_{\text{attribute}}$$</p><p>其中 $\mathbf{v}_{\text{attribute}}$ 是对应某个属性的向量方向。</p><p><strong>常见属性</strong>:</p><ul><li>年龄:年轻 $\leftrightarrow$ 年老</li><li>朝向:左 $\leftrightarrow$ 右</li><li>发型:长发 $\leftrightarrow$ 短发</li><li>表情:微笑 $\leftrightarrow$ 严肃</li></ul><p><strong>挑战</strong>:</p><ul><li>如何找到属性向量?</li><li>如何保证属性互不干扰?</li><li>如何实现精确控制?</li></ul><h2 id=第九章训练实践与技巧>第九章：训练实践与技巧<a hidden class=anchor aria-hidden=true href=#第九章训练实践与技巧>#</a></h2><h3 id=91-训练损失曲线>9.1 训练损失曲线<a hidden class=anchor aria-hidden=true href=#91-训练损失曲线>#</a></h3><p>GAN 的训练损失曲线有独特的模式。</p><p><img alt="GAN 训练损失曲线" loading=lazy src=/images/math/gan-training-loss.png></p><p><strong>图 5</strong>：典型的 GAN 训练损失曲线。判别器和生成器的损失会相互振荡，最终趋于平衡</p><p><strong>观察</strong>:</p><ul><li>判别器损失:先下降,然后稳定在某个值附近</li><li>生成器损失:通常较高,然后缓慢下降</li><li>震荡:两个网络对抗导致损失振荡</li></ul><p><strong>正常 vs 异常</strong>:</p><ul><li>正常:损失合理波动,生成质量逐步提升</li><li>异常:损失持续上升或趋于零,生成质量退化</li></ul><h3 id=92-实用技巧>9.2 实用技巧<a hidden class=anchor aria-hidden=true href=#92-实用技巧>#</a></h3><ol><li><p><strong>判别器更新频率</strong>:</p><ul><li>通常更新 $k$ 次判别器,再更新 $1$ 次生成器</li><li>推荐 $k \in [3, 5]$</li></ul></li><li><p><strong>学习率选择</strong>:</p><ul><li>生成器和判别器可以使用不同学习率</li><li>推荐: $10^{-4}$ 到 $10^{-3}$</li><li>使用 Adam 优化器, $\beta_1 = 0.5$ (而非 $0.9$)</li></ul></li><li><p><strong>噪声分布</strong>:</p><ul><li>推荐:标准高斯分布 $\mathcal{N}(0, \mathbf{I})$</li><li>维度:通常 $100$ 到 $512$</li></ul></li><li><p><strong>归一化</strong>:</p><ul><li>输入图像归一化到 $[-1, 1]$</li><li>使用 tanh 作为生成器输出层激活函数</li></ul></li></ol><h3 id=93-调试策略>9.3 调试策略<a hidden class=anchor aria-hidden=true href=#93-调试策略>#</a></h3><ol><li><p><strong>先训练判别器</strong>:</p><ul><li>暂时固定生成器,训练判别器</li><li>确保判别器能准确区分真实和伪造样本</li></ul></li><li><p><strong>检查梯度</strong>:</p><ul><li>使用梯度裁剪或梯度惩罚</li><li>避免梯度爆炸或消失</li></ul></li><li><p><strong>监控生成质量</strong>:</p><ul><li>定期保存生成样本</li><li>观察质量变化趋势</li></ul></li><li><p><strong>调整超参数</strong>:</p><ul><li>学习率、批大小、网络架构</li><li>使用网格搜索或贝叶斯优化</li></ul></li></ol><h2 id=结语博弈与合作的平衡>结语:博弈与合作的平衡<a hidden class=anchor aria-hidden=true href=#结语博弈与合作的平衡>#</a></h2><p>生成对抗网络的美妙之处在于它将生成问题转化为一个博弈论问题。生成器和判别器在对抗中相互促进,最终达到纳什均衡。</p><p>从数学角度看,GAN 最小化生成分布与真实分布之间的距离。从工程角度看,GAN 是两个神经网络的对抗训练。从艺术角度看,GAN 是创造与鉴别的永恒博弈。</p><p>但 GAN 的故事远未结束。新的架构、新的理论、新的应用层出不穷。从 DCGAN 到 StyleGAN,从 WGAN 到 BigGAN,每个进展都推动着生成式 AI 的边界。</p><p>在这个混沌的世界中,GAN 提供了一种从噪声中创造秩序的方法。就像那位艺术鉴赏家和伪造艺术家的博弈,最终的赢家不是某一方,而是整个系统——一个能够创造逼真世界的系统。</p><hr><h2 id=参考文献>参考文献<a hidden class=anchor aria-hidden=true href=#参考文献>#</a></h2><ol><li>Goodfellow, I., et al. (2014). &ldquo;Generative Adversarial Nets.&rdquo; NeurIPS.</li><li>Radford, A., et al. (2015). &ldquo;Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks.&rdquo; ICLR.</li><li>Arjovsky, M., et al. (2017). &ldquo;Wasserstein GAN.&rdquo; ICML.</li><li>Karras, T., et al. (2018). &ldquo;Progressive Growing of GANs for Improved Quality, Stability, and Variation.&rdquo; ICLR.</li><li>Miyato, T., et al. (2018). &ldquo;Spectral Normalization for Generative Adversarial Networks.&rdquo; ICLR.</li><li>Zhu, J.-Y., et al. (2017). &ldquo;Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks.&rdquo; ICCV.</li><li>Karras, T., et al. (2019). &ldquo;A Style-Based Generator Architecture for GANs.&rdquo; CVPR.</li><li>Brock, A., et al. (2018). &ldquo;Large Scale GAN Training for High Fidelity Natural Image Synthesis.&rdquo; ICLR.</li></ol></div><footer class=post-footer><ul class=post-tags><li><a href=https://s-ai-unix.github.io/tags/gan/>GAN</a></li><li><a href=https://s-ai-unix.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/>深度学习</a></li><li><a href=https://s-ai-unix.github.io/tags/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/>生成模型</a></li><li><a href=https://s-ai-unix.github.io/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/>神经网络</a></li><li><a href=https://s-ai-unix.github.io/tags/%E5%8D%9A%E5%BC%88%E8%AE%BA/>博弈论</a></li></ul><nav class=paginav><a class=prev href=https://s-ai-unix.github.io/posts/2026-01-24-pca-comprehensive-guide/><span class=title>« Prev</span><br><span>PCA 主成分分析：从数据降维的优雅艺术</span>
</a><a class=next href=https://s-ai-unix.github.io/posts/2026-01-24-probability-distributions-guide/><span class=title>Next »</span><br><span>概率统计中的常见分布：从二项分布到正态分布的深层之旅</span></a></nav><ul class=share-buttons><li><a target=_blank rel="noopener noreferrer" aria-label="share 生成对抗网络：从混沌中创造秩序的博弈论 on x" href="https://x.com/intent/tweet/?text=%e7%94%9f%e6%88%90%e5%af%b9%e6%8a%97%e7%bd%91%e7%bb%9c%ef%bc%9a%e4%bb%8e%e6%b7%b7%e6%b2%8c%e4%b8%ad%e5%88%9b%e9%80%a0%e7%a7%a9%e5%ba%8f%e7%9a%84%e5%8d%9a%e5%bc%88%e8%ae%ba&amp;url=https%3a%2f%2fs-ai-unix.github.io%2fposts%2f2026-01-24-gan-comprehensive-guide%2f&amp;hashtags=GAN%2c%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0%2c%e7%94%9f%e6%88%90%e6%a8%a1%e5%9e%8b%2c%e7%a5%9e%e7%bb%8f%e7%bd%91%e7%bb%9c%2c%e5%8d%9a%e5%bc%88%e8%ae%ba"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446C483.971.0 512 28.03 512 62.554zM269.951 190.75 182.567 75.216H56L207.216 272.95 63.9 436.783h61.366L235.9 310.383l96.667 126.4H456L298.367 228.367l134-153.151H371.033zM127.633 110h36.468l219.38 290.065H349.5z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share 生成对抗网络：从混沌中创造秩序的博弈论 on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fs-ai-unix.github.io%2fposts%2f2026-01-24-gan-comprehensive-guide%2f&amp;title=%e7%94%9f%e6%88%90%e5%af%b9%e6%8a%97%e7%bd%91%e7%bb%9c%ef%bc%9a%e4%bb%8e%e6%b7%b7%e6%b2%8c%e4%b8%ad%e5%88%9b%e9%80%a0%e7%a7%a9%e5%ba%8f%e7%9a%84%e5%8d%9a%e5%bc%88%e8%ae%ba&amp;summary=%e7%94%9f%e6%88%90%e5%af%b9%e6%8a%97%e7%bd%91%e7%bb%9c%ef%bc%9a%e4%bb%8e%e6%b7%b7%e6%b2%8c%e4%b8%ad%e5%88%9b%e9%80%a0%e7%a7%a9%e5%ba%8f%e7%9a%84%e5%8d%9a%e5%bc%88%e8%ae%ba&amp;source=https%3a%2f%2fs-ai-unix.github.io%2fposts%2f2026-01-24-gan-comprehensive-guide%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share 生成对抗网络：从混沌中创造秩序的博弈论 on reddit" href="https://reddit.com/submit?url=https%3a%2f%2fs-ai-unix.github.io%2fposts%2f2026-01-24-gan-comprehensive-guide%2f&title=%e7%94%9f%e6%88%90%e5%af%b9%e6%8a%97%e7%bd%91%e7%bb%9c%ef%bc%9a%e4%bb%8e%e6%b7%b7%e6%b2%8c%e4%b8%ad%e5%88%9b%e9%80%a0%e7%a7%a9%e5%ba%8f%e7%9a%84%e5%8d%9a%e5%bc%88%e8%ae%ba"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share 生成对抗网络：从混沌中创造秩序的博弈论 on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fs-ai-unix.github.io%2fposts%2f2026-01-24-gan-comprehensive-guide%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a></li></ul></footer><script src=https://giscus.app/client.js data-repo=s-ai-unix/blog data-repo-id=R_kgDOQ3Njaw data-category=General data-category-id=DIC_kwDOQ3Nja84C0yve data-mapping=pathname data-strict=0 data-reactions-enabled=1 data-emit-metadata=0 data-input-position=bottom data-theme=preferred_color_scheme data-lang=zh-CN data-loading=lazy crossorigin=anonymous async></script></article></main><footer class=footer><span>&copy; 2026 <a href=https://s-ai-unix.github.io/>s-ai-unix's Blog</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
<a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script>(function(){"use strict";function e(){var e=document.querySelectorAll("p, li, td, div, span, h1, h2, h3, h4, h5, h6, ol, ul");e.forEach(function(e){if(e.classList.contains("classical-quote-container")||e.classList.contains("quote-text")||e.closest(".classical-quote-container"))return;var t,n=e.innerHTML,s=!1;for(n.indexOf("<em>")!==-1&&(t=n.replace(/\$([^$]*?)<em>([^<]+?)<\/em>([^$]*?)\$/g,function(e,t,n,s){return/^[\d.,]+$/.test((t+n+s).replace(/[.,]/g,""))?e:"$"+t+"_"+n+s+"$"}),t=t.replace(/\$\$([^$]*?)<em>([^<]+?)<\/em>([^$]*?)\$\$/g,function(e,t,n,s){return"$$"+t+"_"+n+s+"$$"}),t!==n&&(n=t,s=!0)),n.indexOf("</em>")!==-1&&(t=n.replace(/\$([^$]*?)<\/em>([^$]*?)\$/g,function(e,t,n){return"$"+t+"_{"+n+"$"}),t=t.replace(/\$\$([^$]*?)<\/em>([^$]*?)\$\$/g,function(e,t,n){return"$$"+t+"_{"+n+"$$"}),t!==n&&(n=t,s=!0)),n.indexOf("<em>$")!==-1&&(t=n.replace(/<em>\$/g,"$"),t!==n&&(n=t,s=!0)),n.indexOf("</em>$")!==-1&&(t=n.replace(/<\/em>\$/g,"$"),t!==n&&(n=t,s=!0));n.indexOf("<em>")!==-1&&n.indexOf("</em>")!==-1;){if(t=n.replace(/\$([^$]*?)<em>([^<]+?)<\/em>([^$]*?)\$/g,function(e,t,n,s){return/^[\d.,]+$/.test((t+n+s).replace(/[.,]/g,""))?e:"$"+t+"_"+n+s+"$"}),t=t.replace(/\$\$([^$]*?)<em>([^<]+?)<\/em>([^$]*?)\$\$/g,function(e,t,n,s){return"$$"+t+"_"+n+s+"$$"}),t===n)break;n=t,s=!0}n.indexOf("_{")!==-1&&(t=n.replace(/_{/g,"_{"),t!==n&&(n=t,s=!0)),n.indexOf("}_")!==-1&&(t=n.replace(/}_/g,"}"),t!==n&&(n=t,s=!0)),n.includes("</em>{")&&(t=n.replace(/\\mathbf\{(W|x|y|z)\}<\/em>\{\\mathrm\{([a-z]+)\}\}/g,"\\mathbf{$1}_{\\mathrm{$2}}"),t=t.replace(/([LHf])<\/em>\{\\mathrm\{([a-z]+)\}\}/g,"$1_{\\mathrm{$2}}"),t=t.replace(/\\nabla ([LHf])<\/em>\{\\mathrm\{([a-z]+)\}\}/g,`\\nabla $1_{\\mathrm{$2}}`),t=t.replace(/([A-Z])<\/em>\{\\mathrm\{([a-z]+)\}\}/g,"$1_{\\mathrm{$2}}"),t!==n&&(n=t,s=!0)),n.includes("<em>{\\mathrm{")&&(t=n.replace(/\\mathbf\{(W|x|y|z)\}<em>\{\\mathrm\{([a-z]+)\}\}/g,"\\mathbf{$1}_{\\mathrm{$2}}"),t=t.replace(/([LHf])<em>\{\\mathrm\{([a-z]+)\}\}/g,"$1_{\\mathrm{$2}}"),t=t.replace(/\\nabla ([LHf])<em>\{\\mathrm\{([a-z]+)\}\}/g,`\\nabla $1_{\\mathrm{$2}}`),t=t.replace(/([A-Z])<em>\{\\mathrm\{([a-z]+)\}\}/g,"$1_{\\mathrm{$2}}"),t!==n&&(n=t,s=!0)),(n.includes("</em>")||n.includes("<em>"))&&(t=n.replace(/(\$[^$]*?)<em>([^$]*?)<\/em>/g,"$1_{$2}"),t=t.replace(/(\$\$[^$]*?)<em>([^$]*?)<\/em>/g,"$1_{$2}"),t=t.replace(/(\$[^$]*?)<em>/g,"$1"),t=t.replace(/<em>([^$]*?\$)/g,"$1"),t=t.replace(/(\$[^$]*?)<\/em>/g,"$1"),t=t.replace(/<\/em>([^$]*?\$)/g,"$1"),t!==n&&(n=t,s=!0)),n.indexOf("\\\\")!==-1&&(t=n.replace(/(\$\{1,2\})([^$]*?)(\$\{1,2\})/g,function(e,t,n,s){for(;n.indexOf("\\\\")!==-1;)n=n.replace(/\\\\/g,"\\");return t+n+s}),t!==n&&(n=t,s=!0)),s&&(e.innerHTML=n)})}window.MathJax={tex:{inlineMath:[["$","$"]],displayMath:[["$$","$$"]],processEscapes:!0,processEnvironments:!0,tags:"ams",packages:{"[+]":["noerrors","noundefined","boldsymbol"]},macros:{oiint:"\\mathop{∯}",oiiint:"\\mathop{∰}"}},options:{skipHtmlTags:["script","noscript","style","textarea","pre","code"]},startup:{pageReady:function(){return e(),MathJax.startup.defaultPageReady().then(function(){console.log("MathJax formulas rendered successfully")})}}}})()</script><script src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script><link rel=stylesheet href=/css/mermaid-custom.css><script src=/js/mermaid-converter.js></script><script type=module>
  import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs';

  
  setTimeout(() => {
    mermaid.initialize({
      startOnLoad: true,
      theme: 'base',
      themeVariables: {
        primaryColor: '#e3f2fd',
        primaryTextColor: '#1565c0',
        primaryBorderColor: '#2196f3',
        lineColor: '#42a5f5',
        secondaryColor: '#f3e5f5',
        tertiaryColor: '#fff9c4',
        background: '#ffffff',
        mainBkg: '#ffffff',
        nodeBorder: '#2196f3',
        clusterBkg: '#ffffff',
        clusterBorder: '#e0e0e0',
        titleColor: '#1565c0',
        edgeLabelBackground: '#fafafa',
      },
      securityLevel: 'loose',
    });
  }, 100);
</script><script src=/js/toc.js></script><script>let menu=document.getElementById("menu");if(menu){const e=localStorage.getItem("menu-scroll-position");e&&(menu.scrollLeft=parseInt(e,10)),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}}document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{const e=document.querySelector("html");e.dataset.theme==="dark"?(e.dataset.theme="light",localStorage.setItem("pref-theme","light")):(e.dataset.theme="dark",localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script><script>(function(){"use strict";function e(){var e=document.querySelectorAll("p, li, td, div, span, h1, h2, h3, h4, h5, h6, ol, ul");e.forEach(function(e){if(e.classList.contains("classical-quote-container")||e.classList.contains("quote-text")||e.closest(".classical-quote-container"))return;var t,n=e.innerHTML,s=!1;for(n.indexOf("<em>")!==-1&&(t=n.replace(/\$([^$]*?)<em>([^<]+?)<\/em>([^$]*?)\$/g,function(e,t,n,s){return/^[\d.,]+$/.test((t+n+s).replace(/[.,]/g,""))?e:"$"+t+"_"+n+s+"$"}),t=t.replace(/\$\$([^$]*?)<em>([^<]+?)<\/em>([^$]*?)\$\$/g,function(e,t,n,s){return"$$"+t+"_"+n+s+"$$"}),t!==n&&(n=t,s=!0)),n.indexOf("</em>")!==-1&&(t=n.replace(/\$([^$]*?)<\/em>([^$]*?)\$/g,function(e,t,n){return"$"+t+"_{"+n+"$"}),t=t.replace(/\$\$([^$]*?)<\/em>([^$]*?)\$\$/g,function(e,t,n){return"$$"+t+"_{"+n+"$$"}),t!==n&&(n=t,s=!0)),n.indexOf("<em>$")!==-1&&(t=n.replace(/<em>\$/g,"$"),t!==n&&(n=t,s=!0)),n.indexOf("</em>$")!==-1&&(t=n.replace(/<\/em>\$/g,"$"),t!==n&&(n=t,s=!0));n.indexOf("<em>")!==-1&&n.indexOf("</em>")!==-1;){if(t=n.replace(/\$([^$]*?)<em>([^<]+?)<\/em>([^$]*?)\$/g,function(e,t,n,s){return/^[\d.,]+$/.test((t+n+s).replace(/[.,]/g,""))?e:"$"+t+"_"+n+s+"$"}),t=t.replace(/\$\$([^$]*?)<em>([^<]+?)<\/em>([^$]*?)\$\$/g,function(e,t,n,s){return"$$"+t+"_"+n+s+"$$"}),t===n)break;n=t,s=!0}n.indexOf("_{")!==-1&&(t=n.replace(/_{/g,"_{"),t!==n&&(n=t,s=!0)),n.indexOf("}_")!==-1&&(t=n.replace(/}_/g,"}"),t!==n&&(n=t,s=!0)),n.includes("</em>{")&&(t=n.replace(/\\mathbf\{(W|x|y|z)\}<\/em>\{\\mathrm\{([a-z]+)\}\}/g,"\\mathbf{$1}_{\\mathrm{$2}}"),t=t.replace(/([LHf])<\/em>\{\\mathrm\{([a-z]+)\}\}/g,"$1_{\\mathrm{$2}}"),t=t.replace(/\\nabla ([LHf])<\/em>\{\\mathrm\{([a-z]+)\}\}/g,`\\nabla $1_{\\mathrm{$2}}`),t=t.replace(/([A-Z])<\/em>\{\\mathrm\{([a-z]+)\}\}/g,"$1_{\\mathrm{$2}}"),t!==n&&(n=t,s=!0)),n.includes("<em>{\\mathrm{")&&(t=n.replace(/\\mathbf\{(W|x|y|z)\}<em>\{\\mathrm\{([a-z]+)\}\}/g,"\\mathbf{$1}_{\\mathrm{$2}}"),t=t.replace(/([LHf])<em>\{\\mathrm\{([a-z]+)\}\}/g,"$1_{\\mathrm{$2}}"),t=t.replace(/\\nabla ([LHf])<em>\{\\mathrm\{([a-z]+)\}\}/g,`\\nabla $1_{\\mathrm{$2}}`),t=t.replace(/([A-Z])<em>\{\\mathrm\{([a-z]+)\}\}/g,"$1_{\\mathrm{$2}}"),t!==n&&(n=t,s=!0)),(n.includes("</em>")||n.includes("<em>"))&&(t=n.replace(/(\$[^$]*?)<em>([^$]*?)<\/em>/g,"$1_{$2}"),t=t.replace(/(\$\$[^$]*?)<em>([^$]*?)<\/em>/g,"$1_{$2}"),t=t.replace(/(\$[^$]*?)<em>/g,"$1"),t=t.replace(/<em>([^$]*?\$)/g,"$1"),t=t.replace(/(\$[^$]*?)<\/em>/g,"$1"),t=t.replace(/<\/em>([^$]*?\$)/g,"$1"),t!==n&&(n=t,s=!0)),n.indexOf("\\\\")!==-1&&(t=n.replace(/(\$\{1,2\})([^$]*?)(\$\{1,2\})/g,function(e,t,n,s){for(;n.indexOf("\\\\")!==-1;)n=n.replace(/\\\\/g,"\\");return t+n+s}),t!==n&&(n=t,s=!0)),s&&(e.innerHTML=n)})}window.MathJax={tex:{inlineMath:[["$","$"]],displayMath:[["$$","$$"]],processEscapes:!0,processEnvironments:!0,tags:"ams",packages:{"[+]":["noerrors","noundefined","boldsymbol"]},macros:{oiint:"\\mathop{∯}",oiiint:"\\mathop{∰}"}},options:{skipHtmlTags:["script","noscript","style","textarea","pre","code"]},startup:{pageReady:function(){return e(),MathJax.startup.defaultPageReady().then(function(){console.log("MathJax formulas rendered successfully")})}}}})()</script><script src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script><link rel=stylesheet href=/css/mermaid-custom.css><script src=/js/mermaid-converter.js></script><script type=module>
  import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs';

  
  setTimeout(() => {
    mermaid.initialize({
      startOnLoad: true,
      theme: 'base',
      themeVariables: {
        primaryColor: '#e3f2fd',
        primaryTextColor: '#1565c0',
        primaryBorderColor: '#2196f3',
        lineColor: '#42a5f5',
        secondaryColor: '#f3e5f5',
        tertiaryColor: '#fff9c4',
        background: '#ffffff',
        mainBkg: '#ffffff',
        nodeBorder: '#2196f3',
        clusterBkg: '#ffffff',
        clusterBorder: '#e0e0e0',
        titleColor: '#1565c0',
        edgeLabelBackground: '#fafafa',
      },
      securityLevel: 'loose',
    });
  }, 100);
</script><script src=/js/toc.js></script></body></html>
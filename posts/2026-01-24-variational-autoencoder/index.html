<!doctype html><html lang=en dir=auto data-theme=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>变分自编码器：从概率建模到深度生成的优雅桥梁 | s-ai-unix's Blog</title><meta name=keywords content="机器学习,深度学习,综述,神经网络"><meta name=description content="深入解析变分自编码器（VAE）的数学原理与推导，从变分推断到 ELBO 优化，从重参数化到生成应用，完整呈现 VAE 的理论框架与实践价值"><meta name=author content="s-ai-unix"><link rel=canonical href=https://s-ai-unix.github.io/posts/2026-01-24-variational-autoencoder/><link crossorigin=anonymous href=/assets/css/stylesheet.0833aff7e1cf567ecfb9755701ee95a80535f671e2e1a0a770c9bc20a0a7b5bb.css integrity="sha256-CDOv9+HPVn7PuXVXAe6VqAU19nHi4aCncMm8IKCntbs=" rel="preload stylesheet" as=style><link rel=icon href=https://s-ai-unix.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://s-ai-unix.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://s-ai-unix.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://s-ai-unix.github.io/apple-touch-icon.png><link rel=mask-icon href=https://s-ai-unix.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://s-ai-unix.github.io/posts/2026-01-24-variational-autoencoder/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51);color-scheme:dark}.list{background:var(--theme)}.toc{background:var(--entry)}}@media(prefers-color-scheme:light){.list::-webkit-scrollbar-thumb{border-color:var(--code-bg)}}</style></noscript><script>localStorage.getItem("pref-theme")==="dark"?document.querySelector("html").dataset.theme="dark":localStorage.getItem("pref-theme")==="light"?document.querySelector("html").dataset.theme="light":window.matchMedia("(prefers-color-scheme: dark)").matches?document.querySelector("html").dataset.theme="dark":document.querySelector("html").dataset.theme="light"</script><meta property="og:url" content="https://s-ai-unix.github.io/posts/2026-01-24-variational-autoencoder/"><meta property="og:site_name" content="s-ai-unix's Blog"><meta property="og:title" content="变分自编码器：从概率建模到深度生成的优雅桥梁"><meta property="og:description" content="深入解析变分自编码器（VAE）的数学原理与推导，从变分推断到 ELBO 优化，从重参数化到生成应用，完整呈现 VAE 的理论框架与实践价值"><meta property="og:locale" content="zh-cn"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2026-01-24T18:30:00+08:00"><meta property="article:modified_time" content="2026-01-24T18:30:00+08:00"><meta property="article:tag" content="机器学习"><meta property="article:tag" content="深度学习"><meta property="article:tag" content="综述"><meta property="article:tag" content="神经网络"><meta property="og:image" content="https://s-ai-unix.github.io/images/covers/vae-network.jpg"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://s-ai-unix.github.io/images/covers/vae-network.jpg"><meta name=twitter:title content="变分自编码器：从概率建模到深度生成的优雅桥梁"><meta name=twitter:description content="深入解析变分自编码器（VAE）的数学原理与推导，从变分推断到 ELBO 优化，从重参数化到生成应用，完整呈现 VAE 的理论框架与实践价值"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://s-ai-unix.github.io/posts/"},{"@type":"ListItem","position":2,"name":"变分自编码器：从概率建模到深度生成的优雅桥梁","item":"https://s-ai-unix.github.io/posts/2026-01-24-variational-autoencoder/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"变分自编码器：从概率建模到深度生成的优雅桥梁","name":"变分自编码器：从概率建模到深度生成的优雅桥梁","description":"深入解析变分自编码器（VAE）的数学原理与推导，从变分推断到 ELBO 优化，从重参数化到生成应用，完整呈现 VAE 的理论框架与实践价值","keywords":["机器学习","深度学习","综述","神经网络"],"articleBody":"引言：概率与生成的交响曲 想象你在创作一幅肖像画。你观察模特的面容，记住她的眼睛形状、嘴角弧度、颧骨位置——这些是你观察到的具体特征。但当你拿起画笔时，你不仅仅是在复制这些特征，而是在大脑中提取出某种\"风格特征\"：一种抽象的、压缩的表示。然后，基于这个压缩表示，你重新生成一幅作品。\n这就是自编码器（Autoencoder）的基本思想：将高维数据压缩到低维潜在空间，然后再从潜在空间重建原始数据。但传统的自编码器有一个致命缺陷：它学习的潜在空间是确定性的，这意味着我们无法从潜在空间中生成新的样本——我们只能重建已有的数据。\n2013 年，Kingma 和 Welling 提出了变分自编码器（Variational Autoencoder，VAE），它将变分推断的思想引入深度学习，通过将潜在变量建模为概率分布，使得我们能够：\n学习数据生成模型 从潜在空间采样生成新的、从未见过的样本 控制生成过程（通过操控潜在变量） 这不仅仅是一个算法，更是概率图模型与深度学习的完美结合。让我们一同踏上这段从变分推断到深度生成的优雅之旅。\n第一章：自编码器基础 1.1 自编码器的直观理解 自编码器是一个神经网络，由两部分组成：\n编码器（Encoder）：$z = f_{\\text{enc}}(x)$，将输入 $x$ 映射到潜在表示 $z$ 解码器（Decoder）：$\\hat{x} = f_{\\text{dec}}(z)$，从潜在表示重建输入 训练目标是让重建误差最小化：\n$$\\mathcal{L}_{\\text{AE}} = | x - \\hat{x} |^2$$\n1.2 标准自编码器的局限性 标准自编码器的编码器学习的是一个确定性映射：对于每个输入 $x$，潜在变量 $z$ 是一个固定的向量。这带来两个问题：\n无法生成新样本：因为我们不知道潜在空间的概率分布，无法采样新的 $z$ 来生成 $\\hat{x}$ 潜在空间不连续：即使输入 $x_1$ 和 $x_2$ 很相似，它们的潜在表示 $z_1$ 和 $z_2$ 可能相距很远 这些局限性推动我们思考：如果将潜在变量建模为概率分布，情况会怎样？\n第二章：变分推断的核心思想 2.1 生成模型的框架 假设我们有一组观测数据 $\\mathbf{x} = {x^{(1)}, x^{(2)}, \\ldots, x^{(N)}}$，我们想要学习一个生成模型，其过程如下：\n从某个先验分布 $p(z)$ 中采样潜在变量 $z$ 通过概率分布 $p(x|z)$ 生成观测数据 $x$ 这背后的概率图模型可以表示为：\n$$z \\rightarrow x$$\n联合概率分布为： $$p(x, z) = p(x|z) p(z)$$\n2.2 困难所在：后验推断不可解 如果我们想要进行生成，关键在于计算后验分布 $p(z|x)$：\n$$p(z|x) = \\frac{p(x|z) p(z)}{p(x)}$$\n其中边缘似然（证据）$p(x)$ 通过积分得到：\n$$p(x) = \\int p(x|z) p(z) , dz$$\n问题：当 $z$ 是高维变量时，这个积分是不可解的（intractable）。这意味着我们无法精确计算后验分布 $p(z|x)$。\n2.3 变分推断的解决方案 变分推断的核心思想是：用可处理的近似分布 $q_{\\phi}(z|x)$ 来逼近真实的后验 $p(z|x)$。这里的 $q_{\\phi}(z|x)$ 是一个参数为 $\\phi$ 的分布族，我们通过优化 $\\phi$ 使其尽可能接近真实后验。\n如何衡量两个分布的接近程度？我们使用KL 散度（Kullback-Leibler Divergence）：\n$$D_{\\text{KL}}(q_{\\phi}(z|x) | p(z|x)) = \\mathbb{E}{z \\sim q} \\left[ \\log \\frac{q{\\phi}(z|x)}{p(z|x)} \\right]$$\nKL 散度有两个重要性质：\n$D_{\\text{KL}}(q | p) \\geq 0$，等号成立当且仅当 $q = p$ KL 散度不是对称的，$D_{\\text{KL}}(q | p) \\neq D_{\\text{KL}}(p | q)$ 2.4 推导 ELBO（Evidence Lower Bound） 现在我们开始变分推断最关键的推导。我们的目标是让 $q_{\\phi}(z|x)$ 逼近 $p(z|x)$，即最小化 $D_{\\text{KL}}(q_{\\phi}(z|x) | p(z|x))$。\n第一步：展开 KL 散度\n$$\\begin{align} D_{\\text{KL}}(q_{\\phi}(z|x) | p(z|x)) \u0026= \\mathbb{E}{z \\sim q} \\left[ \\log \\frac{q{\\phi}(z|x)}{p(z|x)} \\right] \\ \u0026= \\mathbb{E}{z \\sim q} \\left[ \\log \\frac{q{\\phi}(z|x) p(x)}{p(x, z)} \\right] \\ \u0026= \\mathbb{E}{z \\sim q} \\left[ \\log q{\\phi}(z|x) + \\log p(x) - \\log p(x, z) \\right] \\ \u0026= \\log p(x) + \\mathbb{E}{z \\sim q} [\\log q{\\phi}(z|x) - \\log p(x|z) - \\log p(z)] \\end{align}$$\n这里的关键步骤是：\n使用贝叶斯公式：$p(z|x) = \\frac{p(x,z)}{p(x)}$ 将 $\\log p(x)$ 从期望中提取出来（因为 $x$ 是固定的） 分离出 $\\log p(x|z)$ 和 $\\log p(z)$ 第二步：重新整理\n$$\\log p(x) = D_{\\text{KL}}(q_{\\phi}(z|x) | p(z|x)) - \\mathbb{E}{z \\sim q} [\\log q{\\phi}(z|x)] + \\mathbb{E}{z \\sim q} [\\log p(x|z)] + \\mathbb{E}{z \\sim q} [\\log p(z)]$$\n第三步：定义 ELBO\n将右边的期望项合并，我们定义证据下界（Evidence Lower Bound，ELBO）：\n$$\\text{ELBO} = \\mathbb{E}{z \\sim q} [\\log p(x|z) + \\log p(z) - \\log q{\\phi}(z|x)]$$\n于是我们有：\n$$\\log p(x) = D_{\\text{KL}}(q_{\\phi}(z|x) | p(z|x)) + \\text{ELBO}$$\n第四步：理解这个等式\n这个等式是 VAE 的核心。它的物理直觉是：\n$\\log p(x)$ 是常数（它由数据决定，与 $q_{\\phi}$ 无关） $D_{\\text{KL}}(q_{\\phi}(z|x) | p(z|x)) \\geq 0$ 因此，最大化 ELBO 等价于最小化 KL 散度 换句话说，通过优化 ELBO，我们实际上是在让近似后验 $q_{\\phi}(z|x)$ 接近真实后验 $p(z|x)$。\n第三章：VAE 的数学推导 3.1 VAE 的概率模型设定 在 VAE 中，我们做出以下概率假设：\n先验分布：潜在变量 $z$ 服从标准正态分布 $$p(z) = \\mathcal{N}(z; 0, I)$$\n似然（解码器）：给定 $z$，$x$ 的条件分布为正态分布 $$p_{\\theta}(x|z) = \\mathcal{N}(x; \\mu_{\\theta}(z), \\sigma_{\\theta}^2(z) I)$$\n其中 $\\mu_{\\theta}(z)$ 和 $\\sigma_{\\theta}(z)$ 是神经网络输出的均值和方差。\n近似后验（编码器）：给定 $x$，$z$ 的条件分布为正态分布 $$q_{\\phi}(z|x) = \\mathcal{N}(z; \\mu_{\\phi}(x), \\text{diag}(\\sigma_{\\phi}^2(x)))$$\n其中 $\\mu_{\\phi}(x)$ 和 $\\sigma_{\\phi}(x)$ 是编码器网络的输出。\n3.2 ELBO 的具体形式 对于高斯分布，ELBO 可以展开为两项：\n$$\\begin{align} \\text{ELBO} \u0026= \\mathbb{E}{z \\sim q} [\\log p(x|z) + \\log p(z) - \\log q{\\phi}(z|x)] \\ \u0026= \\mathbb{E}{z \\sim q} [\\log p(x|z)] - \\mathbb{E}{z \\sim q} \\left[ \\log \\frac{q_{\\phi}(z|x)}{p(z)} \\right] \\ \u0026= \\underbrace{\\mathbb{E}{z \\sim q} [\\log p(x|z)]}{\\text{重建误差项}} - \\underbrace{D_{\\text{KL}}(q_{\\phi}(z|x) | p(z))}_{\\text{正则化项}} \\end{align}$$\n展开详解：\n第一项 $\\mathbb{E}_{z \\sim q} [\\log p(x|z)]$ 是重建误差项，衡量解码器重建 $x$ 的能力 第二项 $D_{\\text{KL}}(q_{\\phi}(z|x) | p(z))$ 是正则化项，约束编码器输出的分布接近先验分布 $p(z)$ 这体现了 VAE 的核心思想：在重建质量和潜在空间正则化之间寻找平衡 第一项：重建误差项\n$$\\mathbb{E}{z \\sim q} [\\log p(x|z)] = \\mathbb{E}{z \\sim q} \\left[ -\\frac{1}{2\\sigma^2} | x - \\mu_{\\theta}(z) |^2 - \\frac{d}{2} \\log(2\\pi\\sigma^2) \\right]$$\n如果我们假设 $\\sigma^2$ 是常数，优化这一项等价于最小化重建误差 $| x - \\hat{x} |^2$。\n第二项：KL 散度项\n对于两个高斯分布：\n$q_{\\phi}(z|x) = \\mathcal{N}(z; \\mu_{\\phi}, \\text{diag}(\\sigma_{\\phi}^2))$ $p(z) = \\mathcal{N}(z; 0, I)$ KL 散度有解析解：\n$$D_{\\text{KL}}(\\mathcal{N}(\\mu, \\Sigma) | \\mathcal{N}(0, I)) = \\frac{1}{2} \\left[ \\text{tr}(\\Sigma) + \\mu^T \\mu - d - \\log \\det(\\Sigma) \\right]$$\n对于对角协方差矩阵，简化为：\n$$D_{\\text{KL}} = \\frac{1}{2} \\sum_{j=1}^{d} \\left[ \\sigma_{\\phi,j}^2 + \\mu_{\\phi,j}^2 - 1 - \\log \\sigma_{\\phi,j}^2 \\right]$$\n这个解析解说明：\nKL 散度与均值 $\\mu$ 和方差 $\\sigma^2$ 呈二次关系 当 $\\mu=0$ 且 $\\sigma=1$ 时，KL 散度为 0（两个分布相同） 方差 $\\sigma^2$ 越大，KL 散度越大（分布越分散） 这个 3D 图展示了 KL 散度如何随均值 $\\mu$ 和标准差 $\\sigma$ 变化。红色标记点 (0,1) 是标准位置，此时 KL 散度为 0。您可以看到 KL 散度在远离这个点时如何增加。\n这个图展示了 1D 情况下的 KL 散度计算，其中蓝色曲线是先验分布 $p(z) = \\mathcal{N}(0,1)$，红色虚线是近似后验 $q(z|x) = \\mathcal{N}(\\mu, \\sigma^2)$。通过调整参数，您可以直观地理解 KL 散度的计算过程。\n3.3 完整的 VAE 损失函数 VAE 的损失函数是 ELBO 的负数（最小化损失 = 最大化 ELBO）：\n$$\\mathcal{L}{\\text{VAE}}(\\theta, \\phi; x) = -\\text{ELBO} = \\mathbb{E}{z \\sim q} [-\\log p_{\\theta}(x|z)] + D_{\\text{KL}}(q_{\\phi}(z|x) | p(z))$$\n在实现中，我们通常使用单个样本估计期望：\n$$\\mathcal{L}{\\text{VAE}}(\\theta, \\phi; x) \\approx -\\log p{\\theta}(x|z^{(l)}) + D_{\\text{KL}}(q_{\\phi}(z|x) | p(z))$$\n其中 $z^{(l)}$ 是从 $q_{\\phi}(z|x)$ 采样得到的单个样本。\n第四章：重参数化技巧（Reparameterization Trick） 4.1 采样阻碍了梯度反向传播 现在我们面临一个关键问题：如何训练编码器 $q_{\\phi}(z|x)$？\n在损失函数中，$z$ 是从 $q_{\\phi}(z|x)$ 采样的。这意味着：\n$$z \\sim \\mathcal{N}(\\mu_{\\phi}(x), \\sigma_{\\phi}^2(x))$$\n采样是一个随机操作，梯度无法通过采样过程反向传播。这就像我们试图对\"掷骰子\"求梯度——这是不可微的。\n4.2 重参数化的天才之处 重参数化技巧的核心思想是：将随机性从参数中分离出来。\n对于高斯分布采样：\n$$z = \\mu + \\sigma \\odot \\epsilon$$\n其中 $\\epsilon \\sim \\mathcal{N}(0, I)$ 是从标准正态分布采样的噪声，$\\odot$ 表示逐元素乘法。\n关键洞察：\n$\\mu$ 和 $\\sigma$ 是神经网络的可学习参数 $\\epsilon$ 是随机噪声，但与 $\\mu$ 和 $\\sigma$ 无关 采样只对 $\\epsilon$ 进行，不涉及 $\\mu$ 和 $\\sigma$ 因此，梯度可以通过 $\\mu$ 和 $\\sigma$ 反向传播！\n这个流程图展示了重参数化技巧的效果。通过将随机性分离为独立的噪声 $\\epsilon$，我们可以对确定性参数 $\\mu$ 和 $\\sigma$ 进行梯度优化。蓝色表示编码器阶段，橙色表示重参数化采样，绿色表示解码器阶段。\n4.3 梯度流向的可视化 在重参数化后，计算图的梯度流向为：\n$$\\begin{align} \\frac{\\partial \\mathcal{L}}{\\partial \\mu} \u0026= \\frac{\\partial \\mathcal{L}}{\\partial z} \\cdot \\frac{\\partial z}{\\partial \\mu} = \\frac{\\partial \\mathcal{L}}{\\partial z} \\ \\frac{\\partial \\mathcal{L}}{\\partial \\sigma} \u0026= \\frac{\\partial \\mathcal{L}}{\\partial z} \\cdot \\frac{\\partial z}{\\partial \\sigma} = \\frac{\\partial \\mathcal{L}}{\\partial z} \\odot \\epsilon \\end{align}$$\n因为 $\\epsilon$ 是独立于 $\\mu$ 和 $\\sigma$ 的随机变量，梯度可以顺利传播。\n4.4 网络架构 结合重参数化技巧，VAE 的完整架构如下：\n编码器：$x \\rightarrow \\mu_{\\phi}(x), \\log \\sigma_{\\phi}^2(x)$ 采样：$z = \\mu_{\\phi}(x) + \\sigma_{\\phi}(x) \\odot \\epsilon$ 解码器：$z \\rightarrow \\hat{x} = \\mu_{\\theta}(z)$ 在实现中，我们通常输出 $\\log \\sigma_{\\phi}^2$ 而非 $\\sigma_{\\phi}^2$，以确保方差始终为正。\n这个 3D 图展示了 ELBO 的两个组成部分：\n紫色表面：KL 散度 $D_{\\text{KL}}(q||p)$，随 $\\mu$ 和 $\\sigma$ 增加而增加 蓝色点：标记了标准位置 $(\\mu=0, \\sigma=1)$，此时 KL 散度为 0 ELBO 是 $\\log p(x) - D_{\\text{KL}}$，最大化 ELBO 等价于最小化 KL 散度，同时保持足够的重建能力。\n第五章：VAE 的网络结构 这个交互式流程图展示了 VAE 的完整网络架构。您可以通过点击节点查看详细信息，通过拖动来重新布局。图表展示了：\n编码器：将输入 $x$ 映射到潜在空间的均值 $\\mu_\\phi(x)$ 和对数方差 $\\log \\sigma_\\phi^2(x)$ 重参数化采样：使用噪声 $\\epsilon$ 采样得到 $z$ 解码器：从潜在变量 $z$ 重建输入 $\\hat{x}$ 损失计算：计算重建误差和 KL 散度的总和 各部分的颜色编码：\n蓝色：输入节点 橙色：重参数化采样（关键创新） 绿色：重建输出 红色：总损失函数 第六章：具体应用 6.1 图像生成 VAE 最直观的应用是图像生成。训练完成后，我们可以：\n从先验 $p(z) = \\mathcal{N}(0, I)$ 采样 $z$ 通过解码器 $p_{\\theta}(x|z)$ 生成图像 例如，在 MNIST 数据集上训练的 VAE 可以生成各种手写数字；在人脸数据集上训练的 VAE 可以生成不同姿态、表情的人脸。\n6.2 潜在空间的可视化与探索 VAE 的潜在空间具有良好的结构。我们可以：\n插值：在两个潜在向量 $z_1$ 和 $z_2$ 之间进行线性插值，观察生成的图像如何平滑过渡 操控：找到控制特定属性的潜在维度（如旋转、光照），通过修改这个维度来控制生成图像 这个交互式图展示了在潜在空间中从点 $z_1$ 到 $z_2$ 的线性插值路径。您可以拖动控制点来改变插值路径，观察不同路径下的生成效果。这种平滑插值是 VAE 生成质量的重要指标。\n6.3 异常检测 VAE 的重建误差可以用于异常检测：\n训练数据：正常样本，VAE 能很好地重建 测试数据：如果样本偏离训练分布，VAE 重建误差会很大 这常用于：\n工业缺陷检测 医疗影像异常识别 网络入侵检测 6.4 半监督学习 当只有部分数据有标签时，VAE 可以结合标签信息：\n有标签数据：使用分类损失 无标签数据：使用 VAE 重建损失 潜在变量同时包含内容和标签信息 6.5 文本生成 虽然 VAE 在文本生成中面临一些挑战（离散输入的梯度问题），但通过一些变体（如 Categorical-VAE），仍可用于：\n文本风格转换 句子生成 机器翻译 第七章：VAE 的变体与扩展 7.1 条件 VAE（Conditional VAE，CVAE） 标准 VAE 生成时完全随机，而 CVAE 允许我们控制生成过程：\n$$p(z|x, y) = \\mathcal{N}(z; \\mu_{\\phi}(x, y), \\text{diag}(\\sigma_{\\phi}^2(x, y)))$$\n其中 $y$ 是条件变量（如类别标签、文本描述）。这允许我们：\n生成特定类别的图像（如\"生成数字 5\"） 根据文本描述生成图像 7.2 β-VAE：解耦潜在变量 标准 VAE 的 KL 散度项权重固定为 1，而 β-VAE 引入超参数 $\\beta$：\n$$\\mathcal{L}{\\beta\\text{-VAE}} = \\mathbb{E}{z \\sim q} [-\\log p_{\\theta}(x|z)] + \\beta \\cdot D_{\\text{KL}}(q_{\\phi}(z|x) | p(z))$$\n$\\beta \u003e 1$：更强的正则化，潜在变量更解耦（每个维度对应一个语义因子） $\\beta \u003c 1$：更好的重建质量，但潜在空间可能纠缠 这个交互式图展示了不同 $\\beta$ 值对重建误差和 KL 散度的影响。紫色曲线显示不同的 $\\beta$ 值对应的权衡点。绿色菱形标记了标准 VAE（$\\beta=1$）。通过调整 $\\beta$：\n$\\beta \u003e 1$：更强的正则化，潜在变量更解耦 $\\beta \u003c 1$：更好的重建质量，但潜在空间可能纠缠 7.3 VAE-GAN 混合模型 VAE 生成的图像有时会模糊（因为损失函数是对数似然的变分下界，而非真实似然）。GAN 生成的图像清晰但难以训练。结合两者：\nVAE 部分：编码器-解码器结构，提供可解释的潜在空间 GAN 部分：判别器判断图像真伪，提供对抗损失 混合损失：\n$$\\mathcal{L} = \\mathcal{L}{\\text{VAE}} + \\lambda \\mathcal{L}{\\text{GAN}}$$\n7.4 VQ-VAE：离散潜在空间 VQ-VAE（Vector Quantized-VAE）将连续潜在空间离散化：\n学习一个码本（codebook）$E = {e_1, e_2, \\ldots, e_K}$ 对每个潜在向量 $z_e$，找到最近的码字 $e_k$：$z_q = e_k$ 使用 $z_q$ 进行重建 这带来两个优势：\n潜在表示更紧凑 可以与自回归模型（如 PixelCNN、Transformer）结合 第八章：VAE 与其他生成模型的对比 8.1 VAE vs GAN 特性 VAE GAN 训练稳定性 稳定 不稳定（模式崩溃） 生成质量 较模糊 清晰锐利 潜在空间 良好的结构 难以解释 可控性 高 低 训练目标 明确（最大化 ELBO） 博弈对抗 8.2 VAE vs Flow-based Models Normalizing Flows：可精确计算 $p(x)$，通过可逆变换建模复杂分布 优势：精确的似然估计 劣势：计算成本高，难以处理高维数据 VAE 提供了一个近似但高效的框架。\n8.3 VAE vs Diffusion Models Diffusion Models：通过逐步添加噪声然后反转过程生成样本 优势：生成质量极高（SOTA） 劣势：生成速度慢（需要多次扩散步骤） 有趣的是，Diffusion Models 可以看作是 VAE 的极限情况（潜在空间无限维，扩散过程无限步）。\n这个交互式图展示了典型的 VAE 训练曲线。您可以看到：\n蓝色曲线：重建误差随训练逐渐下降 红色曲线：KL 散度逐渐增加，最终达到平衡 这反映了 VAE 在重建质量和潜在空间正则化之间的动态平衡 通过滑块可以调整不同的学习率和网络结构参数，观察训练曲线的变化。\n第九章：数学深入：为什么 VAE 有效 9.1 信息论视角 ELBO 的两项有深刻的信息论含义：\n$$\\text{ELBO} = \\mathbb{E}{z \\sim q} [\\log p(x|z)] - D{\\text{KL}}(q_{\\phi}(z|x) | p(z))$$\n重建项：最大化 $I(x; z)$（互信息），即 $z$ 对 $x$ 的信息量 KL 项：约束 $H(z)$（$z$ 的熵），防止 $q$ 偏离先验太远 这实际上是在做率失真权衡（Rate-Distortion Tradeoff）：\n增加 $z$ 的维度（更多信息）→ 更好的重建 减小 $z$ 的维度（压缩）→ 更高的 KL 散度惩罚 9.2 几何视角：潜在流形学习 数据通常位于高维空间中的低维流形上。VAE 试图：\n将流形\"压平\"到潜在空间（编码器） 通过先验 $p(z)$ 约束潜在空间的结构 KL 散度项确保不同数据点的潜在表示不会\"聚集\"在一起，而是覆盖整个潜在空间。\n9.3 VAE 与 EM 算法的关系 VAE 的训练可以看作是 EM 算法的随机梯度版本：\nE 步：近似后验 $q_{\\phi}(z|x)$ M 步：优化生成模型 $p_{\\theta}(x|z)$ 与传统 EM 不同，VAE 通过神经网络参数化 $q_{\\phi}$ 和 $p_{\\theta}$，并使用随机梯度下降进行端到端训练。\n结语：概率与确定性的优雅舞蹈 变分自编码器是深度学习中一个真正的杰作。它不仅仅是一个算法，更是一种思维方式——一种在概率不确定性与深度学习的表达能力之间找到完美平衡的方式。\n回顾这段旅程，我们看到了：\n从确定性到概率：将自编码器的确定性映射推广为概率分布 从精确到近似：接受后验推断的困难，采用变分近似 从不可微到可微：通过重参数化技巧，让梯度能够通过采样传播 从重建到生成：不仅学会重建，更学会创造 VAE 的优雅之处在于：\n理论基础扎实：建立在变分推断、信息论、概率图模型等成熟理论之上 实践价值丰富：应用于图像生成、异常检测、半监督学习等多个领域 可解释性强：潜在空间有明确的概率解释，易于分析和控制 扩展性强：衍生出 CVAE、β-VAE、VQ-VAE 等众多变体 在深度学习的浪潮中，VAE 始终保持着独特的地位。它不是最\"炫酷\"的算法，却是最\"经典\"的算法之一；它不是生成质量最高的模型，却是最有理论保障的模型之一。\n当我们站在 VAE 的基础上继续探索——无论是扩散模型、流模型，还是其他未知的生成范式——我们会发现，VAE 教给我们的关于概率建模和变分优化的智慧，始终是前行的指路明灯。\n参考文献：\nKingma, D. P., \u0026 Welling, M. (2013). Auto-encoding variational bayes. arXiv preprint arXiv:1312.6114. Doersch, C. (2016). Tutorial on variational autoencoders. arXiv preprint arXiv:1606.05908. Higgins, I., et al. (2017). beta-VAE: Learning basic visual concepts with a constrained variational framework. ICLR. Oord, A. van den, et al. (2017). Neural discrete representation learning. NeurIPS. Goodfellow, I., et al. (2016). Deep Learning. MIT Press. Chapter 20: Deep Generative Models. ","wordCount":"1174","inLanguage":"en","image":"https://s-ai-unix.github.io/images/covers/vae-network.jpg","datePublished":"2026-01-24T18:30:00+08:00","dateModified":"2026-01-24T18:30:00+08:00","author":{"@type":"Person","name":"s-ai-unix"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://s-ai-unix.github.io/posts/2026-01-24-variational-autoencoder/"},"publisher":{"@type":"Organization","name":"s-ai-unix's Blog","logo":{"@type":"ImageObject","url":"https://s-ai-unix.github.io/favicon.ico"}}}</script><link rel=stylesheet href=https://s-ai-unix.github.io/css/classical-quote.css></head><body id=top><header class=header><nav class=nav><div class=logo><a href=https://s-ai-unix.github.io/ accesskey=h title="s-ai-unix's Blog (Alt + H)">s-ai-unix's Blog</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://s-ai-unix.github.io/ title="🏠 首页"><span>🏠 首页</span></a></li><li><a href=https://s-ai-unix.github.io/posts/ title="📚 文章"><span>📚 文章</span></a></li><li><a href=https://s-ai-unix.github.io/archives/ title="📁 归档"><span>📁 归档</span></a></li><li><a href=https://s-ai-unix.github.io/tags/ title="🏷️ 标签"><span>🏷️ 标签</span></a></li><li><a href=https://s-ai-unix.github.io/search/ title="🔍 搜索 (Alt + /)" accesskey=/><span>🔍 搜索</span></a></li><li><a href=https://s-ai-unix.github.io/about/ title="👤 关于"><span>👤 关于</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://s-ai-unix.github.io/>Home</a>&nbsp;»&nbsp;<a href=https://s-ai-unix.github.io/posts/>Posts</a></div><h1 class="post-title entry-hint-parent">变分自编码器：从概率建模到深度生成的优雅桥梁</h1><div class=post-description>深入解析变分自编码器（VAE）的数学原理与推导，从变分推断到 ELBO 优化，从重参数化到生成应用，完整呈现 VAE 的理论框架与实践价值</div><div class=post-meta><span title='2026-01-24 18:30:00 +0800 CST'>January 24, 2026</span>&nbsp;·&nbsp;<span>6 min</span>&nbsp;·&nbsp;<span>1174 words</span>&nbsp;·&nbsp;<span>s-ai-unix</span></div></header><figure class=entry-cover><a href=https://s-ai-unix.github.io/images/covers/vae-network.jpg target=_blank rel="noopener noreferrer"><img loading=eager src=https://s-ai-unix.github.io/images/covers/vae-network.jpg alt=变分自编码器网络结构示意图></a><figcaption>VAE 编码器-解码器架构</figcaption></figure><div class=toc><details open><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#%e5%bc%95%e8%a8%80%e6%a6%82%e7%8e%87%e4%b8%8e%e7%94%9f%e6%88%90%e7%9a%84%e4%ba%a4%e5%93%8d%e6%9b%b2 aria-label=引言：概率与生成的交响曲>引言：概率与生成的交响曲</a></li><li><a href=#%e7%ac%ac%e4%b8%80%e7%ab%a0%e8%87%aa%e7%bc%96%e7%a0%81%e5%99%a8%e5%9f%ba%e7%a1%80 aria-label=第一章：自编码器基础>第一章：自编码器基础</a><ul><li><a href=#11-%e8%87%aa%e7%bc%96%e7%a0%81%e5%99%a8%e7%9a%84%e7%9b%b4%e8%a7%82%e7%90%86%e8%a7%a3 aria-label="1.1 自编码器的直观理解">1.1 自编码器的直观理解</a></li><li><a href=#12-%e6%a0%87%e5%87%86%e8%87%aa%e7%bc%96%e7%a0%81%e5%99%a8%e7%9a%84%e5%b1%80%e9%99%90%e6%80%a7 aria-label="1.2 标准自编码器的局限性">1.2 标准自编码器的局限性</a></li></ul></li><li><a href=#%e7%ac%ac%e4%ba%8c%e7%ab%a0%e5%8f%98%e5%88%86%e6%8e%a8%e6%96%ad%e7%9a%84%e6%a0%b8%e5%bf%83%e6%80%9d%e6%83%b3 aria-label=第二章：变分推断的核心思想>第二章：变分推断的核心思想</a><ul><li><a href=#21-%e7%94%9f%e6%88%90%e6%a8%a1%e5%9e%8b%e7%9a%84%e6%a1%86%e6%9e%b6 aria-label="2.1 生成模型的框架">2.1 生成模型的框架</a></li><li><a href=#22-%e5%9b%b0%e9%9a%be%e6%89%80%e5%9c%a8%e5%90%8e%e9%aa%8c%e6%8e%a8%e6%96%ad%e4%b8%8d%e5%8f%af%e8%a7%a3 aria-label="2.2 困难所在：后验推断不可解">2.2 困难所在：后验推断不可解</a></li><li><a href=#23-%e5%8f%98%e5%88%86%e6%8e%a8%e6%96%ad%e7%9a%84%e8%a7%a3%e5%86%b3%e6%96%b9%e6%a1%88 aria-label="2.3 变分推断的解决方案">2.3 变分推断的解决方案</a></li><li><a href=#24-%e6%8e%a8%e5%af%bc-elboevidence-lower-bound aria-label="2.4 推导 ELBO（Evidence Lower Bound）">2.4 推导 ELBO（Evidence Lower Bound）</a></li></ul></li><li><a href=#%e7%ac%ac%e4%b8%89%e7%ab%a0vae-%e7%9a%84%e6%95%b0%e5%ad%a6%e6%8e%a8%e5%af%bc aria-label="第三章：VAE 的数学推导">第三章：VAE 的数学推导</a><ul><li><a href=#31-vae-%e7%9a%84%e6%a6%82%e7%8e%87%e6%a8%a1%e5%9e%8b%e8%ae%be%e5%ae%9a aria-label="3.1 VAE 的概率模型设定">3.1 VAE 的概率模型设定</a></li><li><a href=#32-elbo-%e7%9a%84%e5%85%b7%e4%bd%93%e5%bd%a2%e5%bc%8f aria-label="3.2 ELBO 的具体形式">3.2 ELBO 的具体形式</a></li><li><a href=#33-%e5%ae%8c%e6%95%b4%e7%9a%84-vae-%e6%8d%9f%e5%a4%b1%e5%87%bd%e6%95%b0 aria-label="3.3 完整的 VAE 损失函数">3.3 完整的 VAE 损失函数</a></li></ul></li><li><a href=#%e7%ac%ac%e5%9b%9b%e7%ab%a0%e9%87%8d%e5%8f%82%e6%95%b0%e5%8c%96%e6%8a%80%e5%b7%a7reparameterization-trick aria-label="第四章：重参数化技巧（Reparameterization Trick）">第四章：重参数化技巧（Reparameterization Trick）</a><ul><li><a href=#41-%e9%87%87%e6%a0%b7%e9%98%bb%e7%a2%8d%e4%ba%86%e6%a2%af%e5%ba%a6%e5%8f%8d%e5%90%91%e4%bc%a0%e6%92%ad aria-label="4.1 采样阻碍了梯度反向传播">4.1 采样阻碍了梯度反向传播</a></li><li><a href=#42-%e9%87%8d%e5%8f%82%e6%95%b0%e5%8c%96%e7%9a%84%e5%a4%a9%e6%89%8d%e4%b9%8b%e5%a4%84 aria-label="4.2 重参数化的天才之处">4.2 重参数化的天才之处</a></li><li><a href=#43-%e6%a2%af%e5%ba%a6%e6%b5%81%e5%90%91%e7%9a%84%e5%8f%af%e8%a7%86%e5%8c%96 aria-label="4.3 梯度流向的可视化">4.3 梯度流向的可视化</a></li><li><a href=#44-%e7%bd%91%e7%bb%9c%e6%9e%b6%e6%9e%84 aria-label="4.4 网络架构">4.4 网络架构</a></li></ul></li><li><a href=#%e7%ac%ac%e4%ba%94%e7%ab%a0vae-%e7%9a%84%e7%bd%91%e7%bb%9c%e7%bb%93%e6%9e%84 aria-label="第五章：VAE 的网络结构">第五章：VAE 的网络结构</a></li><li><a href=#%e7%ac%ac%e5%85%ad%e7%ab%a0%e5%85%b7%e4%bd%93%e5%ba%94%e7%94%a8 aria-label=第六章：具体应用>第六章：具体应用</a><ul><li><a href=#61-%e5%9b%be%e5%83%8f%e7%94%9f%e6%88%90 aria-label="6.1 图像生成">6.1 图像生成</a></li><li><a href=#62-%e6%bd%9c%e5%9c%a8%e7%a9%ba%e9%97%b4%e7%9a%84%e5%8f%af%e8%a7%86%e5%8c%96%e4%b8%8e%e6%8e%a2%e7%b4%a2 aria-label="6.2 潜在空间的可视化与探索">6.2 潜在空间的可视化与探索</a></li><li><a href=#63-%e5%bc%82%e5%b8%b8%e6%a3%80%e6%b5%8b aria-label="6.3 异常检测">6.3 异常检测</a></li><li><a href=#64-%e5%8d%8a%e7%9b%91%e7%9d%a3%e5%ad%a6%e4%b9%a0 aria-label="6.4 半监督学习">6.4 半监督学习</a></li><li><a href=#65-%e6%96%87%e6%9c%ac%e7%94%9f%e6%88%90 aria-label="6.5 文本生成">6.5 文本生成</a></li></ul></li><li><a href=#%e7%ac%ac%e4%b8%83%e7%ab%a0vae-%e7%9a%84%e5%8f%98%e4%bd%93%e4%b8%8e%e6%89%a9%e5%b1%95 aria-label="第七章：VAE 的变体与扩展">第七章：VAE 的变体与扩展</a><ul><li><a href=#71-%e6%9d%a1%e4%bb%b6-vaeconditional-vaecvae aria-label="7.1 条件 VAE（Conditional VAE，CVAE）">7.1 条件 VAE（Conditional VAE，CVAE）</a></li><li><a href=#72-%ce%b2-vae%e8%a7%a3%e8%80%a6%e6%bd%9c%e5%9c%a8%e5%8f%98%e9%87%8f aria-label="7.2 β-VAE：解耦潜在变量">7.2 β-VAE：解耦潜在变量</a></li><li><a href=#73-vae-gan-%e6%b7%b7%e5%90%88%e6%a8%a1%e5%9e%8b aria-label="7.3 VAE-GAN 混合模型">7.3 VAE-GAN 混合模型</a></li><li><a href=#74-vq-vae%e7%a6%bb%e6%95%a3%e6%bd%9c%e5%9c%a8%e7%a9%ba%e9%97%b4 aria-label="7.4 VQ-VAE：离散潜在空间">7.4 VQ-VAE：离散潜在空间</a></li></ul></li><li><a href=#%e7%ac%ac%e5%85%ab%e7%ab%a0vae-%e4%b8%8e%e5%85%b6%e4%bb%96%e7%94%9f%e6%88%90%e6%a8%a1%e5%9e%8b%e7%9a%84%e5%af%b9%e6%af%94 aria-label="第八章：VAE 与其他生成模型的对比">第八章：VAE 与其他生成模型的对比</a><ul><li><a href=#81-vae-vs-gan aria-label="8.1 VAE vs GAN">8.1 VAE vs GAN</a></li><li><a href=#82-vae-vs-flow-based-models aria-label="8.2 VAE vs Flow-based Models">8.2 VAE vs Flow-based Models</a></li><li><a href=#83-vae-vs-diffusion-models aria-label="8.3 VAE vs Diffusion Models">8.3 VAE vs Diffusion Models</a></li></ul></li><li><a href=#%e7%ac%ac%e4%b9%9d%e7%ab%a0%e6%95%b0%e5%ad%a6%e6%b7%b1%e5%85%a5%e4%b8%ba%e4%bb%80%e4%b9%88-vae-%e6%9c%89%e6%95%88 aria-label="第九章：数学深入：为什么 VAE 有效">第九章：数学深入：为什么 VAE 有效</a><ul><li><a href=#91-%e4%bf%a1%e6%81%af%e8%ae%ba%e8%a7%86%e8%a7%92 aria-label="9.1 信息论视角">9.1 信息论视角</a></li><li><a href=#92-%e5%87%a0%e4%bd%95%e8%a7%86%e8%a7%92%e6%bd%9c%e5%9c%a8%e6%b5%81%e5%bd%a2%e5%ad%a6%e4%b9%a0 aria-label="9.2 几何视角：潜在流形学习">9.2 几何视角：潜在流形学习</a></li><li><a href=#93-vae-%e4%b8%8e-em-%e7%ae%97%e6%b3%95%e7%9a%84%e5%85%b3%e7%b3%bb aria-label="9.3 VAE 与 EM 算法的关系">9.3 VAE 与 EM 算法的关系</a></li></ul></li><li><a href=#%e7%bb%93%e8%af%ad%e6%a6%82%e7%8e%87%e4%b8%8e%e7%a1%ae%e5%ae%9a%e6%80%a7%e7%9a%84%e4%bc%98%e9%9b%85%e8%88%9e%e8%b9%88 aria-label=结语：概率与确定性的优雅舞蹈>结语：概率与确定性的优雅舞蹈</a></li></ul></div></details></div><div class=post-content><h2 id=引言概率与生成的交响曲>引言：概率与生成的交响曲<a hidden class=anchor aria-hidden=true href=#引言概率与生成的交响曲>#</a></h2><p>想象你在创作一幅肖像画。你观察模特的面容，记住她的眼睛形状、嘴角弧度、颧骨位置——这些是你观察到的具体特征。但当你拿起画笔时，你不仅仅是在复制这些特征，而是在大脑中提取出某种"风格特征"：一种抽象的、压缩的表示。然后，基于这个压缩表示，你重新生成一幅作品。</p><p>这就是<strong>自编码器（Autoencoder）<strong>的基本思想：将高维数据压缩到低维潜在空间，然后再从潜在空间重建原始数据。但传统的自编码器有一个致命缺陷：它学习的潜在空间是</strong>确定性</strong>的，这意味着我们无法从潜在空间中生成新的样本——我们只能重建已有的数据。</p><p>2013 年，Kingma 和 Welling 提出了<strong>变分自编码器（Variational Autoencoder，VAE）</strong>，它将变分推断的思想引入深度学习，通过将潜在变量建模为概率分布，使得我们能够：</p><ol><li>学习数据生成模型</li><li>从潜在空间采样生成新的、从未见过的样本</li><li>控制生成过程（通过操控潜在变量）</li></ol><p>这不仅仅是一个算法，更是<strong>概率图模型</strong>与<strong>深度学习</strong>的完美结合。让我们一同踏上这段从变分推断到深度生成的优雅之旅。</p><h2 id=第一章自编码器基础>第一章：自编码器基础<a hidden class=anchor aria-hidden=true href=#第一章自编码器基础>#</a></h2><h3 id=11-自编码器的直观理解>1.1 自编码器的直观理解<a hidden class=anchor aria-hidden=true href=#11-自编码器的直观理解>#</a></h3><p>自编码器是一个神经网络，由两部分组成：</p><ul><li><strong>编码器（Encoder）</strong>：$z = f_{\text{enc}}(x)$，将输入 $x$ 映射到潜在表示 $z$</li><li><strong>解码器（Decoder）</strong>：$\hat{x} = f_{\text{dec}}(z)$，从潜在表示重建输入</li></ul><p>训练目标是让重建误差最小化：</p><p>$$\mathcal{L}_{\text{AE}} = | x - \hat{x} |^2$$</p><h3 id=12-标准自编码器的局限性>1.2 标准自编码器的局限性<a hidden class=anchor aria-hidden=true href=#12-标准自编码器的局限性>#</a></h3><p>标准自编码器的编码器学习的是一个<strong>确定性映射</strong>：对于每个输入 $x$，潜在变量 $z$ 是一个固定的向量。这带来两个问题：</p><ol><li><strong>无法生成新样本</strong>：因为我们不知道潜在空间的概率分布，无法采样新的 $z$ 来生成 $\hat{x}$</li><li><strong>潜在空间不连续</strong>：即使输入 $x_1$ 和 $x_2$ 很相似，它们的潜在表示 $z_1$ 和 $z_2$ 可能相距很远</li></ol><p>这些局限性推动我们思考：如果将潜在变量建模为<strong>概率分布</strong>，情况会怎样？</p><h2 id=第二章变分推断的核心思想>第二章：变分推断的核心思想<a hidden class=anchor aria-hidden=true href=#第二章变分推断的核心思想>#</a></h2><h3 id=21-生成模型的框架>2.1 生成模型的框架<a hidden class=anchor aria-hidden=true href=#21-生成模型的框架>#</a></h3><p>假设我们有一组观测数据 $\mathbf{x} = {x^{(1)}, x^{(2)}, \ldots, x^{(N)}}$，我们想要学习一个<strong>生成模型</strong>，其过程如下：</p><ol><li>从某个先验分布 $p(z)$ 中采样潜在变量 $z$</li><li>通过概率分布 $p(x|z)$ 生成观测数据 $x$</li></ol><p>这背后的<strong>概率图模型</strong>可以表示为：</p><p>$$z \rightarrow x$$</p><p>联合概率分布为：
$$p(x, z) = p(x|z) p(z)$$</p><h3 id=22-困难所在后验推断不可解>2.2 困难所在：后验推断不可解<a hidden class=anchor aria-hidden=true href=#22-困难所在后验推断不可解>#</a></h3><p>如果我们想要进行生成，关键在于计算<strong>后验分布</strong> $p(z|x)$：</p><p>$$p(z|x) = \frac{p(x|z) p(z)}{p(x)}$$</p><p>其中边缘似然（证据）$p(x)$ 通过积分得到：</p><p>$$p(x) = \int p(x|z) p(z) , dz$$</p><p><strong>问题</strong>：当 $z$ 是高维变量时，这个积分是<strong>不可解</strong>的（intractable）。这意味着我们无法精确计算后验分布 $p(z|x)$。</p><h3 id=23-变分推断的解决方案>2.3 变分推断的解决方案<a hidden class=anchor aria-hidden=true href=#23-变分推断的解决方案>#</a></h3><p>变分推断的核心思想是：用<strong>可处理的近似分布</strong> $q_{\phi}(z|x)$ 来逼近真实的后验 $p(z|x)$。这里的 $q_{\phi}(z|x)$ 是一个参数为 $\phi$ 的分布族，我们通过优化 $\phi$ 使其尽可能接近真实后验。</p><p>如何衡量两个分布的接近程度？我们使用<strong>KL 散度（Kullback-Leibler Divergence）</strong>：</p><p>$$D_{\text{KL}}(q_{\phi}(z|x) | p(z|x)) = \mathbb{E}<em>{z \sim q} \left[ \log \frac{q</em>{\phi}(z|x)}{p(z|x)} \right]$$</p><p>KL 散度有两个重要性质：</p><ol><li>$D_{\text{KL}}(q | p) \geq 0$，等号成立当且仅当 $q = p$</li><li>KL 散度不是对称的，$D_{\text{KL}}(q | p) \neq D_{\text{KL}}(p | q)$</li></ol><h3 id=24-推导-elboevidence-lower-bound>2.4 推导 ELBO（Evidence Lower Bound）<a hidden class=anchor aria-hidden=true href=#24-推导-elboevidence-lower-bound>#</a></h3><p>现在我们开始变分推断最关键的推导。我们的目标是让 $q_{\phi}(z|x)$ 逼近 $p(z|x)$，即最小化 $D_{\text{KL}}(q_{\phi}(z|x) | p(z|x))$。</p><p><strong>第一步：展开 KL 散度</strong></p><p>$$\begin{align}
D_{\text{KL}}(q_{\phi}(z|x) | p(z|x)) &= \mathbb{E}<em>{z \sim q} \left[ \log \frac{q</em>{\phi}(z|x)}{p(z|x)} \right] \
&= \mathbb{E}<em>{z \sim q} \left[ \log \frac{q</em>{\phi}(z|x) p(x)}{p(x, z)} \right] \
&= \mathbb{E}<em>{z \sim q} \left[ \log q</em>{\phi}(z|x) + \log p(x) - \log p(x, z) \right] \
&= \log p(x) + \mathbb{E}<em>{z \sim q} [\log q</em>{\phi}(z|x) - \log p(x|z) - \log p(z)]
\end{align}$$</p><p>这里的关键步骤是：</p><ol><li>使用贝叶斯公式：$p(z|x) = \frac{p(x,z)}{p(x)}$</li><li>将 $\log p(x)$ 从期望中提取出来（因为 $x$ 是固定的）</li><li>分离出 $\log p(x|z)$ 和 $\log p(z)$</li></ol><p><strong>第二步：重新整理</strong></p><p>$$\log p(x) = D_{\text{KL}}(q_{\phi}(z|x) | p(z|x)) - \mathbb{E}<em>{z \sim q} [\log q</em>{\phi}(z|x)] + \mathbb{E}<em>{z \sim q} [\log p(x|z)] + \mathbb{E}</em>{z \sim q} [\log p(z)]$$</p><p><strong>第三步：定义 ELBO</strong></p><p>将右边的期望项合并，我们定义<strong>证据下界（Evidence Lower Bound，ELBO）</strong>：</p><p>$$\text{ELBO} = \mathbb{E}<em>{z \sim q} [\log p(x|z) + \log p(z) - \log q</em>{\phi}(z|x)]$$</p><p>于是我们有：</p><p>$$\log p(x) = D_{\text{KL}}(q_{\phi}(z|x) | p(z|x)) + \text{ELBO}$$</p><p><strong>第四步：理解这个等式</strong></p><p>这个等式是 VAE 的核心。它的物理直觉是：</p><ul><li>$\log p(x)$ 是<strong>常数</strong>（它由数据决定，与 $q_{\phi}$ 无关）</li><li>$D_{\text{KL}}(q_{\phi}(z|x) | p(z|x)) \geq 0$</li><li>因此，<strong>最大化 ELBO 等价于最小化 KL 散度</strong></li></ul><p>换句话说，通过优化 ELBO，我们实际上是在让近似后验 $q_{\phi}(z|x)$ 接近真实后验 $p(z|x)$。</p><h2 id=第三章vae-的数学推导>第三章：VAE 的数学推导<a hidden class=anchor aria-hidden=true href=#第三章vae-的数学推导>#</a></h2><h3 id=31-vae-的概率模型设定>3.1 VAE 的概率模型设定<a hidden class=anchor aria-hidden=true href=#31-vae-的概率模型设定>#</a></h3><p>在 VAE 中，我们做出以下概率假设：</p><ol><li><p><strong>先验分布</strong>：潜在变量 $z$ 服从标准正态分布
$$p(z) = \mathcal{N}(z; 0, I)$$</p></li><li><p><strong>似然（解码器）</strong>：给定 $z$，$x$ 的条件分布为正态分布
$$p_{\theta}(x|z) = \mathcal{N}(x; \mu_{\theta}(z), \sigma_{\theta}^2(z) I)$$</p><p>其中 $\mu_{\theta}(z)$ 和 $\sigma_{\theta}(z)$ 是神经网络输出的均值和方差。</p></li><li><p><strong>近似后验（编码器）</strong>：给定 $x$，$z$ 的条件分布为正态分布
$$q_{\phi}(z|x) = \mathcal{N}(z; \mu_{\phi}(x), \text{diag}(\sigma_{\phi}^2(x)))$$</p><p>其中 $\mu_{\phi}(x)$ 和 $\sigma_{\phi}(x)$ 是编码器网络的输出。</p></li></ol><h3 id=32-elbo-的具体形式>3.2 ELBO 的具体形式<a hidden class=anchor aria-hidden=true href=#32-elbo-的具体形式>#</a></h3><p>对于高斯分布，ELBO 可以展开为两项：</p><p>$$\begin{align}
\text{ELBO} &= \mathbb{E}<em>{z \sim q} [\log p(x|z) + \log p(z) - \log q</em>{\phi}(z|x)] \
&= \mathbb{E}<em>{z \sim q} [\log p(x|z)] - \mathbb{E}</em>{z \sim q} \left[ \log \frac{q_{\phi}(z|x)}{p(z)} \right] \
&= \underbrace{\mathbb{E}<em>{z \sim q} [\log p(x|z)]}</em>{\text{重建误差项}} - \underbrace{D_{\text{KL}}(q_{\phi}(z|x) | p(z))}_{\text{正则化项}}
\end{align}$$</p><p><strong>展开详解</strong>：</p><ol><li>第一项 $\mathbb{E}_{z \sim q} [\log p(x|z)]$ 是<strong>重建误差项</strong>，衡量解码器重建 $x$ 的能力</li><li>第二项 $D_{\text{KL}}(q_{\phi}(z|x) | p(z))$ 是<strong>正则化项</strong>，约束编码器输出的分布接近先验分布 $p(z)$</li><li>这体现了 VAE 的核心思想：在重建质量和潜在空间正则化之间寻找平衡</li></ol><p><strong>第一项：重建误差项</strong></p><p>$$\mathbb{E}<em>{z \sim q} [\log p(x|z)] = \mathbb{E}</em>{z \sim q} \left[ -\frac{1}{2\sigma^2} | x - \mu_{\theta}(z) |^2 - \frac{d}{2} \log(2\pi\sigma^2) \right]$$</p><p>如果我们假设 $\sigma^2$ 是常数，优化这一项等价于最小化重建误差 $| x - \hat{x} |^2$。</p><p><strong>第二项：KL 散度项</strong></p><p>对于两个高斯分布：</p><ul><li>$q_{\phi}(z|x) = \mathcal{N}(z; \mu_{\phi}, \text{diag}(\sigma_{\phi}^2))$</li><li>$p(z) = \mathcal{N}(z; 0, I)$</li></ul><p>KL 散度有解析解：</p><p>$$D_{\text{KL}}(\mathcal{N}(\mu, \Sigma) | \mathcal{N}(0, I)) = \frac{1}{2} \left[ \text{tr}(\Sigma) + \mu^T \mu - d - \log \det(\Sigma) \right]$$</p><p>对于对角协方差矩阵，简化为：</p><p>$$D_{\text{KL}} = \frac{1}{2} \sum_{j=1}^{d} \left[ \sigma_{\phi,j}^2 + \mu_{\phi,j}^2 - 1 - \log \sigma_{\phi,j}^2 \right]$$</p><p>这个解析解说明：</p><ol><li>KL 散度与均值 $\mu$ 和方差 $\sigma^2$ 呈二次关系</li><li>当 $\mu=0$ 且 $\sigma=1$ 时，KL 散度为 0（两个分布相同）</li><li>方差 $\sigma^2$ 越大，KL 散度越大（分布越分散）</li></ol><div class=plot-container><iframe src=/images/plots/kl_divergence_3d.html width=100% height=600 frameborder=0></iframe></div><p>这个 3D 图展示了 KL 散度如何随均值 $\mu$ 和标准差 $\sigma$ 变化。红色标记点 (0,1) 是标准位置，此时 KL 散度为 0。您可以看到 KL 散度在远离这个点时如何增加。</p><div class=plot-container><iframe src=/images/plots/kl_divergence_formula.html width=100% height=600 frameborder=0></iframe></div><p>这个图展示了 1D 情况下的 KL 散度计算，其中蓝色曲线是先验分布 $p(z) = \mathcal{N}(0,1)$，红色虚线是近似后验 $q(z|x) = \mathcal{N}(\mu, \sigma^2)$。通过调整参数，您可以直观地理解 KL 散度的计算过程。</p><h3 id=33-完整的-vae-损失函数>3.3 完整的 VAE 损失函数<a hidden class=anchor aria-hidden=true href=#33-完整的-vae-损失函数>#</a></h3><p>VAE 的损失函数是 ELBO 的负数（最小化损失 = 最大化 ELBO）：</p><p>$$\mathcal{L}<em>{\text{VAE}}(\theta, \phi; x) = -\text{ELBO} = \mathbb{E}</em>{z \sim q} [-\log p_{\theta}(x|z)] + D_{\text{KL}}(q_{\phi}(z|x) | p(z))$$</p><p>在实现中，我们通常使用<strong>单个样本估计</strong>期望：</p><p>$$\mathcal{L}<em>{\text{VAE}}(\theta, \phi; x) \approx -\log p</em>{\theta}(x|z^{(l)}) + D_{\text{KL}}(q_{\phi}(z|x) | p(z))$$</p><p>其中 $z^{(l)}$ 是从 $q_{\phi}(z|x)$ 采样得到的单个样本。</p><h2 id=第四章重参数化技巧reparameterization-trick>第四章：重参数化技巧（Reparameterization Trick）<a hidden class=anchor aria-hidden=true href=#第四章重参数化技巧reparameterization-trick>#</a></h2><h3 id=41-采样阻碍了梯度反向传播>4.1 采样阻碍了梯度反向传播<a hidden class=anchor aria-hidden=true href=#41-采样阻碍了梯度反向传播>#</a></h3><p>现在我们面临一个关键问题：如何训练编码器 $q_{\phi}(z|x)$？</p><p>在损失函数中，$z$ 是从 $q_{\phi}(z|x)$ 采样的。这意味着：</p><p>$$z \sim \mathcal{N}(\mu_{\phi}(x), \sigma_{\phi}^2(x))$$</p><p>采样是一个<strong>随机操作</strong>，梯度无法通过采样过程反向传播。这就像我们试图对"掷骰子"求梯度——这是不可微的。</p><h3 id=42-重参数化的天才之处>4.2 重参数化的天才之处<a hidden class=anchor aria-hidden=true href=#42-重参数化的天才之处>#</a></h3><p>重参数化技巧的核心思想是：将随机性从参数中分离出来。</p><p>对于高斯分布采样：</p><p>$$z = \mu + \sigma \odot \epsilon$$</p><p>其中 $\epsilon \sim \mathcal{N}(0, I)$ 是从标准正态分布采样的噪声，$\odot$ 表示逐元素乘法。</p><p><strong>关键洞察</strong>：</p><ul><li>$\mu$ 和 $\sigma$ 是神经网络的可学习参数</li><li>$\epsilon$ 是随机噪声，但与 $\mu$ 和 $\sigma$ 无关</li><li>采样只对 $\epsilon$ 进行，不涉及 $\mu$ 和 $\sigma$</li></ul><p>因此，梯度可以通过 $\mu$ 和 $\sigma$ 反向传播！</p><div class=plot-container><iframe src=/images/plots/vae_flow.html width=100% height=400 frameborder=0></iframe></div><p>这个流程图展示了重参数化技巧的效果。通过将随机性分离为独立的噪声 $\epsilon$，我们可以对确定性参数 $\mu$ 和 $\sigma$ 进行梯度优化。蓝色表示编码器阶段，橙色表示重参数化采样，绿色表示解码器阶段。</p><h3 id=43-梯度流向的可视化>4.3 梯度流向的可视化<a hidden class=anchor aria-hidden=true href=#43-梯度流向的可视化>#</a></h3><p>在重参数化后，计算图的梯度流向为：</p><p>$$\begin{align}
\frac{\partial \mathcal{L}}{\partial \mu} &= \frac{\partial \mathcal{L}}{\partial z} \cdot \frac{\partial z}{\partial \mu} = \frac{\partial \mathcal{L}}{\partial z} \
\frac{\partial \mathcal{L}}{\partial \sigma} &= \frac{\partial \mathcal{L}}{\partial z} \cdot \frac{\partial z}{\partial \sigma} = \frac{\partial \mathcal{L}}{\partial z} \odot \epsilon
\end{align}$$</p><p>因为 $\epsilon$ 是独立于 $\mu$ 和 $\sigma$ 的随机变量，梯度可以顺利传播。</p><h3 id=44-网络架构>4.4 网络架构<a hidden class=anchor aria-hidden=true href=#44-网络架构>#</a></h3><p>结合重参数化技巧，VAE 的完整架构如下：</p><ol><li><strong>编码器</strong>：$x \rightarrow \mu_{\phi}(x), \log \sigma_{\phi}^2(x)$</li><li><strong>采样</strong>：$z = \mu_{\phi}(x) + \sigma_{\phi}(x) \odot \epsilon$</li><li><strong>解码器</strong>：$z \rightarrow \hat{x} = \mu_{\theta}(z)$</li></ol><p>在实现中，我们通常输出 $\log \sigma_{\phi}^2$ 而非 $\sigma_{\phi}^2$，以确保方差始终为正。</p><div class=plot-container><iframe src=/images/plots/kl_divergence_3d.html width=100% height=600 frameborder=0></iframe></div><p>这个 3D 图展示了 ELBO 的两个组成部分：</p><ul><li>紫色表面：KL 散度 $D_{\text{KL}}(q||p)$，随 $\mu$ 和 $\sigma$ 增加而增加</li><li>蓝色点：标记了标准位置 $(\mu=0, \sigma=1)$，此时 KL 散度为 0</li></ul><p>ELBO 是 $\log p(x) - D_{\text{KL}}$，最大化 ELBO 等价于最小化 KL 散度，同时保持足够的重建能力。</p><h2 id=第五章vae-的网络结构>第五章：VAE 的网络结构<a hidden class=anchor aria-hidden=true href=#第五章vae-的网络结构>#</a></h2><div class=plot-container><iframe src=/images/plots/vae_network.html width=100% height=700 frameborder=0></iframe></div><p>这个交互式流程图展示了 VAE 的完整网络架构。您可以通过点击节点查看详细信息，通过拖动来重新布局。图表展示了：</p><ul><li><strong>编码器</strong>：将输入 $x$ 映射到潜在空间的均值 $\mu_\phi(x)$ 和对数方差 $\log \sigma_\phi^2(x)$</li><li><strong>重参数化采样</strong>：使用噪声 $\epsilon$ 采样得到 $z$</li><li><strong>解码器</strong>：从潜在变量 $z$ 重建输入 $\hat{x}$</li><li><strong>损失计算</strong>：计算重建误差和 KL 散度的总和</li></ul><p>各部分的颜色编码：</p><ul><li>蓝色：输入节点</li><li>橙色：重参数化采样（关键创新）</li><li>绿色：重建输出</li><li>红色：总损失函数</li></ul><h2 id=第六章具体应用>第六章：具体应用<a hidden class=anchor aria-hidden=true href=#第六章具体应用>#</a></h2><h3 id=61-图像生成>6.1 图像生成<a hidden class=anchor aria-hidden=true href=#61-图像生成>#</a></h3><p>VAE 最直观的应用是图像生成。训练完成后，我们可以：</p><ol><li>从先验 $p(z) = \mathcal{N}(0, I)$ 采样 $z$</li><li>通过解码器 $p_{\theta}(x|z)$ 生成图像</li></ol><p>例如，在 MNIST 数据集上训练的 VAE 可以生成各种手写数字；在人脸数据集上训练的 VAE 可以生成不同姿态、表情的人脸。</p><h3 id=62-潜在空间的可视化与探索>6.2 潜在空间的可视化与探索<a hidden class=anchor aria-hidden=true href=#62-潜在空间的可视化与探索>#</a></h3><p>VAE 的潜在空间具有良好的结构。我们可以：</p><ol><li><strong>插值</strong>：在两个潜在向量 $z_1$ 和 $z_2$ 之间进行线性插值，观察生成的图像如何平滑过渡</li><li><strong>操控</strong>：找到控制特定属性的潜在维度（如旋转、光照），通过修改这个维度来控制生成图像</li></ol><div class=plot-container><iframe src=/images/plots/latent_interpolation.html width=100% height=600 frameborder=0></iframe></div><p>这个交互式图展示了在潜在空间中从点 $z_1$ 到 $z_2$ 的线性插值路径。您可以拖动控制点来改变插值路径，观察不同路径下的生成效果。这种平滑插值是 VAE 生成质量的重要指标。</p><h3 id=63-异常检测>6.3 异常检测<a hidden class=anchor aria-hidden=true href=#63-异常检测>#</a></h3><p>VAE 的重建误差可以用于异常检测：</p><ul><li>训练数据：正常样本，VAE 能很好地重建</li><li>测试数据：如果样本偏离训练分布，VAE 重建误差会很大</li></ul><p>这常用于：</p><ul><li>工业缺陷检测</li><li>医疗影像异常识别</li><li>网络入侵检测</li></ul><h3 id=64-半监督学习>6.4 半监督学习<a hidden class=anchor aria-hidden=true href=#64-半监督学习>#</a></h3><p>当只有部分数据有标签时，VAE 可以结合标签信息：</p><ol><li>有标签数据：使用分类损失</li><li>无标签数据：使用 VAE 重建损失</li><li>潜在变量同时包含内容和标签信息</li></ol><h3 id=65-文本生成>6.5 文本生成<a hidden class=anchor aria-hidden=true href=#65-文本生成>#</a></h3><p>虽然 VAE 在文本生成中面临一些挑战（离散输入的梯度问题），但通过一些变体（如 Categorical-VAE），仍可用于：</p><ul><li>文本风格转换</li><li>句子生成</li><li>机器翻译</li></ul><h2 id=第七章vae-的变体与扩展>第七章：VAE 的变体与扩展<a hidden class=anchor aria-hidden=true href=#第七章vae-的变体与扩展>#</a></h2><h3 id=71-条件-vaeconditional-vaecvae>7.1 条件 VAE（Conditional VAE，CVAE）<a hidden class=anchor aria-hidden=true href=#71-条件-vaeconditional-vaecvae>#</a></h3><p>标准 VAE 生成时完全随机，而 CVAE 允许我们控制生成过程：</p><p>$$p(z|x, y) = \mathcal{N}(z; \mu_{\phi}(x, y), \text{diag}(\sigma_{\phi}^2(x, y)))$$</p><p>其中 $y$ 是条件变量（如类别标签、文本描述）。这允许我们：</p><ul><li>生成特定类别的图像（如"生成数字 5"）</li><li>根据文本描述生成图像</li></ul><h3 id=72-β-vae解耦潜在变量>7.2 β-VAE：解耦潜在变量<a hidden class=anchor aria-hidden=true href=#72-β-vae解耦潜在变量>#</a></h3><p>标准 VAE 的 KL 散度项权重固定为 1，而 β-VAE 引入超参数 $\beta$：</p><p>$$\mathcal{L}<em>{\beta\text{-VAE}} = \mathbb{E}</em>{z \sim q} [-\log p_{\theta}(x|z)] + \beta \cdot D_{\text{KL}}(q_{\phi}(z|x) | p(z))$$</p><ul><li>$\beta > 1$：更强的正则化，潜在变量更解耦（每个维度对应一个语义因子）</li><li>$\beta &lt; 1$：更好的重建质量，但潜在空间可能纠缠</li></ul><div class=plot-container><iframe src=/images/plots/beta_vae_tradeoff.html width=100% height=600 frameborder=0></iframe></div><p>这个交互式图展示了不同 $\beta$ 值对重建误差和 KL 散度的影响。紫色曲线显示不同的 $\beta$ 值对应的权衡点。绿色菱形标记了标准 VAE（$\beta=1$）。通过调整 $\beta$：</p><ul><li>$\beta > 1$：更强的正则化，潜在变量更解耦</li><li>$\beta &lt; 1$：更好的重建质量，但潜在空间可能纠缠</li></ul><h3 id=73-vae-gan-混合模型>7.3 VAE-GAN 混合模型<a hidden class=anchor aria-hidden=true href=#73-vae-gan-混合模型>#</a></h3><p>VAE 生成的图像有时会模糊（因为损失函数是对数似然的变分下界，而非真实似然）。GAN 生成的图像清晰但难以训练。结合两者：</p><ul><li><strong>VAE 部分</strong>：编码器-解码器结构，提供可解释的潜在空间</li><li><strong>GAN 部分</strong>：判别器判断图像真伪，提供对抗损失</li></ul><p>混合损失：</p><p>$$\mathcal{L} = \mathcal{L}<em>{\text{VAE}} + \lambda \mathcal{L}</em>{\text{GAN}}$$</p><h3 id=74-vq-vae离散潜在空间>7.4 VQ-VAE：离散潜在空间<a hidden class=anchor aria-hidden=true href=#74-vq-vae离散潜在空间>#</a></h3><p>VQ-VAE（Vector Quantized-VAE）将连续潜在空间离散化：</p><ol><li>学习一个码本（codebook）$E = {e_1, e_2, \ldots, e_K}$</li><li>对每个潜在向量 $z_e$，找到最近的码字 $e_k$：$z_q = e_k$</li><li>使用 $z_q$ 进行重建</li></ol><p>这带来两个优势：</p><ul><li>潜在表示更紧凑</li><li>可以与自回归模型（如 PixelCNN、Transformer）结合</li></ul><h2 id=第八章vae-与其他生成模型的对比>第八章：VAE 与其他生成模型的对比<a hidden class=anchor aria-hidden=true href=#第八章vae-与其他生成模型的对比>#</a></h2><h3 id=81-vae-vs-gan>8.1 VAE vs GAN<a hidden class=anchor aria-hidden=true href=#81-vae-vs-gan>#</a></h3><table><thead><tr><th>特性</th><th>VAE</th><th>GAN</th></tr></thead><tbody><tr><td>训练稳定性</td><td>稳定</td><td>不稳定（模式崩溃）</td></tr><tr><td>生成质量</td><td>较模糊</td><td>清晰锐利</td></tr><tr><td>潜在空间</td><td>良好的结构</td><td>难以解释</td></tr><tr><td>可控性</td><td>高</td><td>低</td></tr><tr><td>训练目标</td><td>明确（最大化 ELBO）</td><td>博弈对抗</td></tr></tbody></table><h3 id=82-vae-vs-flow-based-models>8.2 VAE vs Flow-based Models<a hidden class=anchor aria-hidden=true href=#82-vae-vs-flow-based-models>#</a></h3><ul><li><strong>Normalizing Flows</strong>：可精确计算 $p(x)$，通过可逆变换建模复杂分布</li><li><strong>优势</strong>：精确的似然估计</li><li><strong>劣势</strong>：计算成本高，难以处理高维数据</li></ul><p>VAE 提供了一个<strong>近似</strong>但<strong>高效</strong>的框架。</p><h3 id=83-vae-vs-diffusion-models>8.3 VAE vs Diffusion Models<a hidden class=anchor aria-hidden=true href=#83-vae-vs-diffusion-models>#</a></h3><ul><li><strong>Diffusion Models</strong>：通过逐步添加噪声然后反转过程生成样本</li><li><strong>优势</strong>：生成质量极高（SOTA）</li><li><strong>劣势</strong>：生成速度慢（需要多次扩散步骤）</li></ul><p>有趣的是，Diffusion Models 可以看作是 VAE 的极限情况（潜在空间无限维，扩散过程无限步）。</p><div class=plot-container><iframe src=/images/plots/vae_training_curves.html width=100% height=600 frameborder=0></iframe></div><p>这个交互式图展示了典型的 VAE 训练曲线。您可以看到：</p><ul><li>蓝色曲线：重建误差随训练逐渐下降</li><li>红色曲线：KL 散度逐渐增加，最终达到平衡</li><li>这反映了 VAE 在重建质量和潜在空间正则化之间的动态平衡</li></ul><p>通过滑块可以调整不同的学习率和网络结构参数，观察训练曲线的变化。</p><h2 id=第九章数学深入为什么-vae-有效>第九章：数学深入：为什么 VAE 有效<a hidden class=anchor aria-hidden=true href=#第九章数学深入为什么-vae-有效>#</a></h2><h3 id=91-信息论视角>9.1 信息论视角<a hidden class=anchor aria-hidden=true href=#91-信息论视角>#</a></h3><p>ELBO 的两项有深刻的信息论含义：</p><p>$$\text{ELBO} = \mathbb{E}<em>{z \sim q} [\log p(x|z)] - D</em>{\text{KL}}(q_{\phi}(z|x) | p(z))$$</p><ul><li><strong>重建项</strong>：最大化 $I(x; z)$（互信息），即 $z$ 对 $x$ 的信息量</li><li><strong>KL 项</strong>：约束 $H(z)$（$z$ 的熵），防止 $q$ 偏离先验太远</li></ul><p>这实际上是在做<strong>率失真权衡（Rate-Distortion Tradeoff）</strong>：</p><ul><li>增加 $z$ 的维度（更多信息）→ 更好的重建</li><li>减小 $z$ 的维度（压缩）→ 更高的 KL 散度惩罚</li></ul><h3 id=92-几何视角潜在流形学习>9.2 几何视角：潜在流形学习<a hidden class=anchor aria-hidden=true href=#92-几何视角潜在流形学习>#</a></h3><p>数据通常位于高维空间中的低维流形上。VAE 试图：</p><ol><li>将流形"压平"到潜在空间（编码器）</li><li>通过先验 $p(z)$ 约束潜在空间的结构</li></ol><p>KL 散度项确保不同数据点的潜在表示不会"聚集"在一起，而是覆盖整个潜在空间。</p><h3 id=93-vae-与-em-算法的关系>9.3 VAE 与 EM 算法的关系<a hidden class=anchor aria-hidden=true href=#93-vae-与-em-算法的关系>#</a></h3><p>VAE 的训练可以看作是 <strong>EM 算法</strong>的随机梯度版本：</p><ul><li><strong>E 步</strong>：近似后验 $q_{\phi}(z|x)$</li><li><strong>M 步</strong>：优化生成模型 $p_{\theta}(x|z)$</li></ul><p>与传统 EM 不同，VAE 通过神经网络参数化 $q_{\phi}$ 和 $p_{\theta}$，并使用随机梯度下降进行端到端训练。</p><h2 id=结语概率与确定性的优雅舞蹈>结语：概率与确定性的优雅舞蹈<a hidden class=anchor aria-hidden=true href=#结语概率与确定性的优雅舞蹈>#</a></h2><p>变分自编码器是深度学习中一个真正的杰作。它不仅仅是一个算法，更是一种思维方式——一种在<strong>概率不确定性</strong>与<strong>深度学习的表达能力</strong>之间找到完美平衡的方式。</p><p>回顾这段旅程，我们看到了：</p><ol><li><strong>从确定性到概率</strong>：将自编码器的确定性映射推广为概率分布</li><li><strong>从精确到近似</strong>：接受后验推断的困难，采用变分近似</li><li><strong>从不可微到可微</strong>：通过重参数化技巧，让梯度能够通过采样传播</li><li><strong>从重建到生成</strong>：不仅学会重建，更学会创造</li></ol><p>VAE 的优雅之处在于：</p><ul><li><strong>理论基础扎实</strong>：建立在变分推断、信息论、概率图模型等成熟理论之上</li><li><strong>实践价值丰富</strong>：应用于图像生成、异常检测、半监督学习等多个领域</li><li><strong>可解释性强</strong>：潜在空间有明确的概率解释，易于分析和控制</li><li><strong>扩展性强</strong>：衍生出 CVAE、β-VAE、VQ-VAE 等众多变体</li></ul><p>在深度学习的浪潮中，VAE 始终保持着独特的地位。它不是最"炫酷"的算法，却是最"经典"的算法之一；它不是生成质量最高的模型，却是最有理论保障的模型之一。</p><p>当我们站在 VAE 的基础上继续探索——无论是扩散模型、流模型，还是其他未知的生成范式——我们会发现，VAE 教给我们的关于<strong>概率建模</strong>和<strong>变分优化</strong>的智慧，始终是前行的指路明灯。</p><hr><p><strong>参考文献</strong>：</p><ol><li>Kingma, D. P., & Welling, M. (2013). Auto-encoding variational bayes. <em>arXiv preprint arXiv:1312.6114</em>.</li><li>Doersch, C. (2016). Tutorial on variational autoencoders. <em>arXiv preprint arXiv:1606.05908</em>.</li><li>Higgins, I., et al. (2017). beta-VAE: Learning basic visual concepts with a constrained variational framework. <em>ICLR</em>.</li><li>Oord, A. van den, et al. (2017). Neural discrete representation learning. <em>NeurIPS</em>.</li><li>Goodfellow, I., et al. (2016). <em>Deep Learning</em>. MIT Press. Chapter 20: Deep Generative Models.</li></ol></div><footer class=post-footer><ul class=post-tags><li><a href=https://s-ai-unix.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/>机器学习</a></li><li><a href=https://s-ai-unix.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/>深度学习</a></li><li><a href=https://s-ai-unix.github.io/tags/%E7%BB%BC%E8%BF%B0/>综述</a></li><li><a href=https://s-ai-unix.github.io/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/>神经网络</a></li></ul><nav class=paginav><a class=prev href=https://s-ai-unix.github.io/posts/2026-01-25-linear-algebra-complete-guide/><span class=title>« Prev</span><br><span>线性代数：从理论到 AI 应用的完整旅程</span>
</a><a class=next href=https://s-ai-unix.github.io/posts/2026-01-24-gmm-comprehensive-guide/><span class=title>Next »</span><br><span>高斯混合模型：从数据中解构隐藏结构的艺术</span></a></nav><ul class=share-buttons><li><a target=_blank rel="noopener noreferrer" aria-label="share 变分自编码器：从概率建模到深度生成的优雅桥梁 on x" href="https://x.com/intent/tweet/?text=%e5%8f%98%e5%88%86%e8%87%aa%e7%bc%96%e7%a0%81%e5%99%a8%ef%bc%9a%e4%bb%8e%e6%a6%82%e7%8e%87%e5%bb%ba%e6%a8%a1%e5%88%b0%e6%b7%b1%e5%ba%a6%e7%94%9f%e6%88%90%e7%9a%84%e4%bc%98%e9%9b%85%e6%a1%a5%e6%a2%81&amp;url=https%3a%2f%2fs-ai-unix.github.io%2fposts%2f2026-01-24-variational-autoencoder%2f&amp;hashtags=%e6%9c%ba%e5%99%a8%e5%ad%a6%e4%b9%a0%2c%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0%2c%e7%bb%bc%e8%bf%b0%2c%e7%a5%9e%e7%bb%8f%e7%bd%91%e7%bb%9c"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446C483.971.0 512 28.03 512 62.554zM269.951 190.75 182.567 75.216H56L207.216 272.95 63.9 436.783h61.366L235.9 310.383l96.667 126.4H456L298.367 228.367l134-153.151H371.033zM127.633 110h36.468l219.38 290.065H349.5z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share 变分自编码器：从概率建模到深度生成的优雅桥梁 on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fs-ai-unix.github.io%2fposts%2f2026-01-24-variational-autoencoder%2f&amp;title=%e5%8f%98%e5%88%86%e8%87%aa%e7%bc%96%e7%a0%81%e5%99%a8%ef%bc%9a%e4%bb%8e%e6%a6%82%e7%8e%87%e5%bb%ba%e6%a8%a1%e5%88%b0%e6%b7%b1%e5%ba%a6%e7%94%9f%e6%88%90%e7%9a%84%e4%bc%98%e9%9b%85%e6%a1%a5%e6%a2%81&amp;summary=%e5%8f%98%e5%88%86%e8%87%aa%e7%bc%96%e7%a0%81%e5%99%a8%ef%bc%9a%e4%bb%8e%e6%a6%82%e7%8e%87%e5%bb%ba%e6%a8%a1%e5%88%b0%e6%b7%b1%e5%ba%a6%e7%94%9f%e6%88%90%e7%9a%84%e4%bc%98%e9%9b%85%e6%a1%a5%e6%a2%81&amp;source=https%3a%2f%2fs-ai-unix.github.io%2fposts%2f2026-01-24-variational-autoencoder%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share 变分自编码器：从概率建模到深度生成的优雅桥梁 on reddit" href="https://reddit.com/submit?url=https%3a%2f%2fs-ai-unix.github.io%2fposts%2f2026-01-24-variational-autoencoder%2f&title=%e5%8f%98%e5%88%86%e8%87%aa%e7%bc%96%e7%a0%81%e5%99%a8%ef%bc%9a%e4%bb%8e%e6%a6%82%e7%8e%87%e5%bb%ba%e6%a8%a1%e5%88%b0%e6%b7%b1%e5%ba%a6%e7%94%9f%e6%88%90%e7%9a%84%e4%bc%98%e9%9b%85%e6%a1%a5%e6%a2%81"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share 变分自编码器：从概率建模到深度生成的优雅桥梁 on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fs-ai-unix.github.io%2fposts%2f2026-01-24-variational-autoencoder%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a></li></ul></footer><script src=https://giscus.app/client.js data-repo=s-ai-unix/blog data-repo-id=R_kgDOQ3Njaw data-category=General data-category-id=DIC_kwDOQ3Nja84C0yve data-mapping=pathname data-strict=0 data-reactions-enabled=1 data-emit-metadata=0 data-input-position=bottom data-theme=preferred_color_scheme data-lang=zh-CN data-loading=lazy crossorigin=anonymous async></script></article></main><footer class=footer><span>&copy; 2026 <a href=https://s-ai-unix.github.io/>s-ai-unix's Blog</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
<a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script>(function(){"use strict";function e(){var e=document.querySelectorAll("p, li, td, div, span, h1, h2, h3, h4, h5, h6, ol, ul");e.forEach(function(e){if(e.classList.contains("classical-quote-container")||e.classList.contains("quote-text")||e.closest(".classical-quote-container"))return;var t,n=e.innerHTML,s=!1;for(n.indexOf("<em>")!==-1&&(t=n.replace(/\$([^$]*?)<em>([^<]+?)<\/em>([^$]*?)\$/g,function(e,t,n,s){return/^[\d.,]+$/.test((t+n+s).replace(/[.,]/g,""))?e:"$"+t+"_"+n+s+"$"}),t=t.replace(/\$\$([^$]*?)<em>([^<]+?)<\/em>([^$]*?)\$\$/g,function(e,t,n,s){return"$$"+t+"_"+n+s+"$$"}),t!==n&&(n=t,s=!0)),n.indexOf("</em>")!==-1&&(t=n.replace(/\$([^$]*?)<\/em>([^$]*?)\$/g,function(e,t,n){return"$"+t+"_{"+n+"$"}),t=t.replace(/\$\$([^$]*?)<\/em>([^$]*?)\$\$/g,function(e,t,n){return"$$"+t+"_{"+n+"$$"}),t!==n&&(n=t,s=!0)),n.indexOf("<em>$")!==-1&&(t=n.replace(/<em>\$/g,"$"),t!==n&&(n=t,s=!0)),n.indexOf("</em>$")!==-1&&(t=n.replace(/<\/em>\$/g,"$"),t!==n&&(n=t,s=!0));n.indexOf("<em>")!==-1&&n.indexOf("</em>")!==-1;){if(t=n.replace(/\$([^$]*?)<em>([^<]+?)<\/em>([^$]*?)\$/g,function(e,t,n,s){return/^[\d.,]+$/.test((t+n+s).replace(/[.,]/g,""))?e:"$"+t+"_"+n+s+"$"}),t=t.replace(/\$\$([^$]*?)<em>([^<]+?)<\/em>([^$]*?)\$\$/g,function(e,t,n,s){return"$$"+t+"_"+n+s+"$$"}),t===n)break;n=t,s=!0}n.indexOf("_{")!==-1&&(t=n.replace(/_{/g,"_{"),t!==n&&(n=t,s=!0)),n.indexOf("}_")!==-1&&(t=n.replace(/}_/g,"}"),t!==n&&(n=t,s=!0)),n.includes("</em>{")&&(t=n.replace(/\\mathbf\{(W|x|y|z)\}<\/em>\{\\mathrm\{([a-z]+)\}\}/g,"\\mathbf{$1}_{\\mathrm{$2}}"),t=t.replace(/([LHf])<\/em>\{\\mathrm\{([a-z]+)\}\}/g,"$1_{\\mathrm{$2}}"),t=t.replace(/\\nabla ([LHf])<\/em>\{\\mathrm\{([a-z]+)\}\}/g,`\\nabla $1_{\\mathrm{$2}}`),t=t.replace(/([A-Z])<\/em>\{\\mathrm\{([a-z]+)\}\}/g,"$1_{\\mathrm{$2}}"),t!==n&&(n=t,s=!0)),n.includes("<em>{\\mathrm{")&&(t=n.replace(/\\mathbf\{(W|x|y|z)\}<em>\{\\mathrm\{([a-z]+)\}\}/g,"\\mathbf{$1}_{\\mathrm{$2}}"),t=t.replace(/([LHf])<em>\{\\mathrm\{([a-z]+)\}\}/g,"$1_{\\mathrm{$2}}"),t=t.replace(/\\nabla ([LHf])<em>\{\\mathrm\{([a-z]+)\}\}/g,`\\nabla $1_{\\mathrm{$2}}`),t=t.replace(/([A-Z])<em>\{\\mathrm\{([a-z]+)\}\}/g,"$1_{\\mathrm{$2}}"),t!==n&&(n=t,s=!0)),(n.includes("</em>")||n.includes("<em>"))&&(t=n.replace(/(\$[^$]*?)<em>([^$]*?)<\/em>/g,"$1_{$2}"),t=t.replace(/(\$\$[^$]*?)<em>([^$]*?)<\/em>/g,"$1_{$2}"),t=t.replace(/(\$[^$]*?)<em>/g,"$1"),t=t.replace(/<em>([^$]*?\$)/g,"$1"),t=t.replace(/(\$[^$]*?)<\/em>/g,"$1"),t=t.replace(/<\/em>([^$]*?\$)/g,"$1"),t!==n&&(n=t,s=!0)),n.indexOf("\\\\")!==-1&&(t=n.replace(/(\$\{1,2\})([^$]*?)(\$\{1,2\})/g,function(e,t,n,s){for(;n.indexOf("\\\\")!==-1;)n=n.replace(/\\\\/g,"\\");return t+n+s}),t!==n&&(n=t,s=!0)),s&&(e.innerHTML=n)})}window.MathJax={tex:{inlineMath:[["$","$"]],displayMath:[["$$","$$"]],processEscapes:!0,processEnvironments:!0,tags:"ams",packages:{"[+]":["noerrors","noundefined","boldsymbol"]},macros:{oiint:"\\mathop{∯}",oiiint:"\\mathop{∰}"}},options:{skipHtmlTags:["script","noscript","style","textarea","pre","code"]},startup:{pageReady:function(){return e(),MathJax.startup.defaultPageReady().then(function(){console.log("MathJax formulas rendered successfully")})}}}})()</script><script src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script><link rel=stylesheet href=/css/mermaid-custom.css><script src=/js/mermaid-converter.js></script><script type=module>
  import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs';

  
  setTimeout(() => {
    mermaid.initialize({
      startOnLoad: true,
      theme: 'base',
      themeVariables: {
        primaryColor: '#e3f2fd',
        primaryTextColor: '#1565c0',
        primaryBorderColor: '#2196f3',
        lineColor: '#42a5f5',
        secondaryColor: '#f3e5f5',
        tertiaryColor: '#fff9c4',
        background: '#ffffff',
        mainBkg: '#ffffff',
        nodeBorder: '#2196f3',
        clusterBkg: '#ffffff',
        clusterBorder: '#e0e0e0',
        titleColor: '#1565c0',
        edgeLabelBackground: '#fafafa',
      },
      securityLevel: 'loose',
    });
  }, 100);
</script><script src=/js/toc.js></script><script>let menu=document.getElementById("menu");if(menu){const e=localStorage.getItem("menu-scroll-position");e&&(menu.scrollLeft=parseInt(e,10)),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}}document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{const e=document.querySelector("html");e.dataset.theme==="dark"?(e.dataset.theme="light",localStorage.setItem("pref-theme","light")):(e.dataset.theme="dark",localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script><script>(function(){"use strict";function e(){var e=document.querySelectorAll("p, li, td, div, span, h1, h2, h3, h4, h5, h6, ol, ul");e.forEach(function(e){if(e.classList.contains("classical-quote-container")||e.classList.contains("quote-text")||e.closest(".classical-quote-container"))return;var t,n=e.innerHTML,s=!1;for(n.indexOf("<em>")!==-1&&(t=n.replace(/\$([^$]*?)<em>([^<]+?)<\/em>([^$]*?)\$/g,function(e,t,n,s){return/^[\d.,]+$/.test((t+n+s).replace(/[.,]/g,""))?e:"$"+t+"_"+n+s+"$"}),t=t.replace(/\$\$([^$]*?)<em>([^<]+?)<\/em>([^$]*?)\$\$/g,function(e,t,n,s){return"$$"+t+"_"+n+s+"$$"}),t!==n&&(n=t,s=!0)),n.indexOf("</em>")!==-1&&(t=n.replace(/\$([^$]*?)<\/em>([^$]*?)\$/g,function(e,t,n){return"$"+t+"_{"+n+"$"}),t=t.replace(/\$\$([^$]*?)<\/em>([^$]*?)\$\$/g,function(e,t,n){return"$$"+t+"_{"+n+"$$"}),t!==n&&(n=t,s=!0)),n.indexOf("<em>$")!==-1&&(t=n.replace(/<em>\$/g,"$"),t!==n&&(n=t,s=!0)),n.indexOf("</em>$")!==-1&&(t=n.replace(/<\/em>\$/g,"$"),t!==n&&(n=t,s=!0));n.indexOf("<em>")!==-1&&n.indexOf("</em>")!==-1;){if(t=n.replace(/\$([^$]*?)<em>([^<]+?)<\/em>([^$]*?)\$/g,function(e,t,n,s){return/^[\d.,]+$/.test((t+n+s).replace(/[.,]/g,""))?e:"$"+t+"_"+n+s+"$"}),t=t.replace(/\$\$([^$]*?)<em>([^<]+?)<\/em>([^$]*?)\$\$/g,function(e,t,n,s){return"$$"+t+"_"+n+s+"$$"}),t===n)break;n=t,s=!0}n.indexOf("_{")!==-1&&(t=n.replace(/_{/g,"_{"),t!==n&&(n=t,s=!0)),n.indexOf("}_")!==-1&&(t=n.replace(/}_/g,"}"),t!==n&&(n=t,s=!0)),n.includes("</em>{")&&(t=n.replace(/\\mathbf\{(W|x|y|z)\}<\/em>\{\\mathrm\{([a-z]+)\}\}/g,"\\mathbf{$1}_{\\mathrm{$2}}"),t=t.replace(/([LHf])<\/em>\{\\mathrm\{([a-z]+)\}\}/g,"$1_{\\mathrm{$2}}"),t=t.replace(/\\nabla ([LHf])<\/em>\{\\mathrm\{([a-z]+)\}\}/g,`\\nabla $1_{\\mathrm{$2}}`),t=t.replace(/([A-Z])<\/em>\{\\mathrm\{([a-z]+)\}\}/g,"$1_{\\mathrm{$2}}"),t!==n&&(n=t,s=!0)),n.includes("<em>{\\mathrm{")&&(t=n.replace(/\\mathbf\{(W|x|y|z)\}<em>\{\\mathrm\{([a-z]+)\}\}/g,"\\mathbf{$1}_{\\mathrm{$2}}"),t=t.replace(/([LHf])<em>\{\\mathrm\{([a-z]+)\}\}/g,"$1_{\\mathrm{$2}}"),t=t.replace(/\\nabla ([LHf])<em>\{\\mathrm\{([a-z]+)\}\}/g,`\\nabla $1_{\\mathrm{$2}}`),t=t.replace(/([A-Z])<em>\{\\mathrm\{([a-z]+)\}\}/g,"$1_{\\mathrm{$2}}"),t!==n&&(n=t,s=!0)),(n.includes("</em>")||n.includes("<em>"))&&(t=n.replace(/(\$[^$]*?)<em>([^$]*?)<\/em>/g,"$1_{$2}"),t=t.replace(/(\$\$[^$]*?)<em>([^$]*?)<\/em>/g,"$1_{$2}"),t=t.replace(/(\$[^$]*?)<em>/g,"$1"),t=t.replace(/<em>([^$]*?\$)/g,"$1"),t=t.replace(/(\$[^$]*?)<\/em>/g,"$1"),t=t.replace(/<\/em>([^$]*?\$)/g,"$1"),t!==n&&(n=t,s=!0)),n.indexOf("\\\\")!==-1&&(t=n.replace(/(\$\{1,2\})([^$]*?)(\$\{1,2\})/g,function(e,t,n,s){for(;n.indexOf("\\\\")!==-1;)n=n.replace(/\\\\/g,"\\");return t+n+s}),t!==n&&(n=t,s=!0)),s&&(e.innerHTML=n)})}window.MathJax={tex:{inlineMath:[["$","$"]],displayMath:[["$$","$$"]],processEscapes:!0,processEnvironments:!0,tags:"ams",packages:{"[+]":["noerrors","noundefined","boldsymbol"]},macros:{oiint:"\\mathop{∯}",oiiint:"\\mathop{∰}"}},options:{skipHtmlTags:["script","noscript","style","textarea","pre","code"]},startup:{pageReady:function(){return e(),MathJax.startup.defaultPageReady().then(function(){console.log("MathJax formulas rendered successfully")})}}}})()</script><script src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script><link rel=stylesheet href=/css/mermaid-custom.css><script src=/js/mermaid-converter.js></script><script type=module>
  import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs';

  
  setTimeout(() => {
    mermaid.initialize({
      startOnLoad: true,
      theme: 'base',
      themeVariables: {
        primaryColor: '#e3f2fd',
        primaryTextColor: '#1565c0',
        primaryBorderColor: '#2196f3',
        lineColor: '#42a5f5',
        secondaryColor: '#f3e5f5',
        tertiaryColor: '#fff9c4',
        background: '#ffffff',
        mainBkg: '#ffffff',
        nodeBorder: '#2196f3',
        clusterBkg: '#ffffff',
        clusterBorder: '#e0e0e0',
        titleColor: '#1565c0',
        edgeLabelBackground: '#fafafa',
      },
      securityLevel: 'loose',
    });
  }, 100);
</script><script src=/js/toc.js></script></body></html>
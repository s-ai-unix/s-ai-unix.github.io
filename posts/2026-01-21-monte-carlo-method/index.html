<!doctype html><html lang=en dir=auto data-theme=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>蒙特卡罗算法：从原子弹到人工智能的随机之旅 | s-ai-unix's Blog</title><meta name=keywords content="综述,算法,概率论,数值计算"><meta name=description content="从曼哈顿计划的保密代号到现代科学计算的核心工具，本文系统介绍蒙特卡罗方法的发展历程、数学基础和广泛应用。"><meta name=author content="s-ai-unix"><link rel=canonical href=https://s-ai-unix.github.io/posts/2026-01-21-monte-carlo-method/><link crossorigin=anonymous href=/assets/css/stylesheet.0833aff7e1cf567ecfb9755701ee95a80535f671e2e1a0a770c9bc20a0a7b5bb.css integrity="sha256-CDOv9+HPVn7PuXVXAe6VqAU19nHi4aCncMm8IKCntbs=" rel="preload stylesheet" as=style><link rel=icon href=https://s-ai-unix.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://s-ai-unix.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://s-ai-unix.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://s-ai-unix.github.io/apple-touch-icon.png><link rel=mask-icon href=https://s-ai-unix.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://s-ai-unix.github.io/posts/2026-01-21-monte-carlo-method/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51);color-scheme:dark}.list{background:var(--theme)}.toc{background:var(--entry)}}@media(prefers-color-scheme:light){.list::-webkit-scrollbar-thumb{border-color:var(--code-bg)}}</style></noscript><script>localStorage.getItem("pref-theme")==="dark"?document.querySelector("html").dataset.theme="dark":localStorage.getItem("pref-theme")==="light"?document.querySelector("html").dataset.theme="light":window.matchMedia("(prefers-color-scheme: dark)").matches?document.querySelector("html").dataset.theme="dark":document.querySelector("html").dataset.theme="light"</script><meta property="og:url" content="https://s-ai-unix.github.io/posts/2026-01-21-monte-carlo-method/"><meta property="og:site_name" content="s-ai-unix's Blog"><meta property="og:title" content="蒙特卡罗算法：从原子弹到人工智能的随机之旅"><meta property="og:description" content="从曼哈顿计划的保密代号到现代科学计算的核心工具，本文系统介绍蒙特卡罗方法的发展历程、数学基础和广泛应用。"><meta property="og:locale" content="zh-cn"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2026-01-21T23:00:00+08:00"><meta property="article:modified_time" content="2026-01-21T23:00:00+08:00"><meta property="article:tag" content="综述"><meta property="article:tag" content="算法"><meta property="article:tag" content="概率论"><meta property="article:tag" content="数值计算"><meta property="og:image" content="https://s-ai-unix.github.io/images/covers/monte-carlo-method.jpg"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://s-ai-unix.github.io/images/covers/monte-carlo-method.jpg"><meta name=twitter:title content="蒙特卡罗算法：从原子弹到人工智能的随机之旅"><meta name=twitter:description content="从曼哈顿计划的保密代号到现代科学计算的核心工具，本文系统介绍蒙特卡罗方法的发展历程、数学基础和广泛应用。"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://s-ai-unix.github.io/posts/"},{"@type":"ListItem","position":2,"name":"蒙特卡罗算法：从原子弹到人工智能的随机之旅","item":"https://s-ai-unix.github.io/posts/2026-01-21-monte-carlo-method/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"蒙特卡罗算法：从原子弹到人工智能的随机之旅","name":"蒙特卡罗算法：从原子弹到人工智能的随机之旅","description":"从曼哈顿计划的保密代号到现代科学计算的核心工具，本文系统介绍蒙特卡罗方法的发展历程、数学基础和广泛应用。","keywords":["综述","算法","概率论","数值计算"],"articleBody":"引言：掷骰子解方程 想象一下，有人告诉你：要计算一个复杂的定积分，不需要微积分，只需要掷足够多的骰子。你大概会觉得这个人疯了。然而，这正是二十世纪最伟大的计算方法之一——蒙特卡罗方法（Monte Carlo Method）的核心思想。\n当我们面对那些传统方法难以处理的高维积分、复杂系统的模拟或者无法解析求解的概率问题时，蒙特卡罗方法给出了一个看似简单却深刻的答案：用随机性来求解确定性问题。这种方法已经深入到科学的方方面面——从核物理到金融工程，从生物进化到人工智能，无处不见它的身影。\n让我们从一个最经典的例子开始：如何用\"扔针\"来计算 $\\pi$ 的值。\n第一章：蒙特卡罗的诞生——曼哈顿计划的秘密代号 1.1 摩纳哥的赌场与原子弹的秘密 “蒙特卡罗\"这个名字，源自摩纳哥著名的赌城。1940 年代，在洛斯阿拉莫斯实验室，一群顶尖的科学家正在紧锣密鼓地研制世界上第一颗原子弹。在这个属于\"曼哈顿计划\"的绝密基地里，数学家约翰·冯·诺伊曼（John von Neumann）和斯坦尼斯拉夫·乌拉姆（Stanislaw Ulam）正在研究核裂变中的中子扩散问题。\n这个问题极其复杂：中子在原子弹内部的行为是随机的，它们可能被原子核捕获，可能引发新的裂变，也可能逃逸出去。传统的方法根本无法处理这种复杂的随机过程。\n乌拉姆后来回忆起他是如何产生这个想法的：\n“当时我正因病康复，在玩纸牌接龙。我开始思考：如果把牌随机排列一百次，大概有多少次能成功接龙？相比于把所有可能的情况都计算出来，直接实验似乎更容易…”\n这个看似简单的想法，孕育了一个全新的计算方法。由于这种方法涉及随机性，而蒙特卡罗又以赌场闻名，冯·诺伊曼就给它起了\"蒙特卡罗\"这个代号——既是保密的需要，也恰如其分地描述了方法的本质。\n1.2 早期的思想萌芽 虽然蒙特卡罗方法在1940年代才正式命名，但用随机性来解决确定性问题的思想古已有之。\n1777年，布丰投针实验\n法国数学家乔治-路易·勒克莱尔，布丰伯爵（Georges-Louis Leclerc, Comte de Buffon）提出了第一个著名的随机实验：\n在一张画满平行线的纸（线间距为 $d$）上随机投掷一根长度为 $l$ 的针（$l \u003c d$），针与任意一条平行线相交的概率是多少？\n布丰证明了，这个概率是：\n$$ P = \\frac{2l}{\\pi d} $$\n这给出了一个计算 $\\pi$ 的方法：如果我们投掷针 $N$ 次，其中 $n$ 次与线相交，那么：\n$$ \\frac{n}{N} \\approx \\frac{2l}{\\pi d} \\implies \\pi \\approx \\frac{2lN}{nd} $$\n这个实验被多次验证：1850年，沃尔夫在苏黎世投掷了5000次，得到 $\\pi \\approx 3.1596$；1901年，拉泽里尼投掷3408次，甚至得到了精确到小数点后6位的 $\\pi$ 值（虽然有人怀疑他可能\"选择性记录\"了结果）。\n19世纪末的统计学革命\n随着统计学的发展，卡尔·皮尔逊（Karl Pearson）等人开始使用随机抽样来解决统计问题。但这些方法仍然主要用于验证已知的结果，而不是作为通用的计算工具。\n第二章：数学基础——为什么随机性有效？ 要理解蒙特卡罗方法，我们需要先理解它的数学基础。这一切都建立在大数定律和中心极限定理这两大概率论支柱之上。\n2.1 大数定律：频率的稳定性 强大数定律告诉我们：如果 $X_1, X_2, \\ldots$ 是独立同分布的随机变量，期望为 $\\mu$，方差有限，那么：\n$$ \\lim_{N \\to \\infty} \\frac{1}{N}\\sum_{i=1}^{N} X_i = \\mu \\quad \\text{几乎必然成立} $$\n用通俗的话说：当试验次数足够多时，样本平均值会收敛到真实期望值。\n这正是蒙特卡罗方法的核心！如果我们能够把一个待求解的问题转化为某个随机变量的期望计算，那么通过大量的随机抽样，我们就可以得到这个期望的近似值。\n2.2 中心极限定理：误差的估计 大数定律告诉我们蒙特卡罗方法最终会收敛，但中心极限定理告诉我们收敛的速度。\n设 $X_1, X_2, \\ldots, X_N$ 是独立同分布的随机变量，期望为 $\\mu$，方差为 $\\sigma^2$。定义样本均值为：\n$$ \\bar{X}N = \\frac{1}{N}\\sum{i=1}^{N} X_i $$\n中心极限定理告诉我们：\n$$ \\frac{\\sqrt{N}(\\bar{X}_N - \\mu)}{\\sigma} \\xrightarrow{d} \\mathcal{N}(0, 1) $$\n这意味着对于大 $N$，$\\bar{X}_N$ 近似服从正态分布 $\\mathcal{N}(\\mu, \\sigma^2/N)$。\n这个结果极其重要，因为它给出了误差估计：\n标准误差是 $\\sigma/\\sqrt{N}$ 95% 置信区间大约是 $\\mu \\pm 1.96\\sigma/\\sqrt{N}$ 注意到一个关键事实：误差以 $1/\\sqrt{N}$ 的速度下降。这意味着：\n要把精度提高10倍，需要100倍的样本 要把精度提高100倍，需要10000倍的样本 这看起来似乎很慢，但我们稍后会看到，在高维问题中，这已经是非常优秀的收敛速度了。\n2.3 蒙特卡罗积分的基本原理 让我们看看如何用蒙特卡罗方法计算定积分。假设我们要计算：\n$$ I = \\int_{a}^{b} f(x) , dx $$\n我们可以把它改写为期望的形式：\n$$ I = \\int_{a}^{b} f(x) , dx = (b-a) \\int_{a}^{b} f(x) \\cdot \\frac{1}{b-a} , dx = (b-a) \\cdot \\mathbb{E}[f(X)] $$\n其中 $X$ 是在 $[a, b]$ 上均匀分布的随机变量。\n蒙特卡罗方法的做法是：\n生成 $N$ 个在 $[a, b]$ 上均匀分布的随机点 $X_1, X_2, \\ldots, X_N$ 计算 $I_N = \\frac{b-a}{N}\\sum_{i=1}^{N} f(X_i)$ 根据大数定律，$I_N \\to I$ 当 $N \\to \\infty$。\n高维积分的情况\n蒙特卡罗方法的真正威力在高维积分中体现。考虑 $d$ 维积分：\n$$ I = \\int_{[0,1]^d} f(\\mathbf{x}) , d\\mathbf{x} $$\n传统的数值积分方法（如梯形法则、辛普森法则）在 $d$ 维空间中的误差通常是 $O(N^{-2/d})$，这意味着随着维度 $d$ 的增加，收敛速度急剧下降——这就是著名的维度灾难（Curse of Dimensionality）。\n而蒙特卡罗方法的误差是 $O(N^{-1/2})$，与维度无关！这是蒙特卡罗方法在高维问题中无可替代的根本原因。\n第三章：蒙特卡罗方法的发展历程 3.1 初创时期（1940-1950年代） 洛斯阿拉莫斯的突破\n在曼哈顿计划中，蒙特卡罗方法被用于解决中子输运问题。冯·诺伊曼和乌拉姆开发了一套完整的算法框架，包括：\n重要抽样（Importance Sampling）：让随机抽样更加\"聪明” 分层抽样（Stratified Sampling）：把样本空间分区以提高精度 第一台计算机的助力\n有趣的是，蒙特卡罗方法的兴起与电子计算机的诞生几乎是同步的。在ENIAC上运行的早期蒙特卡罗模拟，第一次让科学家们看到了这种方法的巨大潜力。\n3.2 方法的成熟（1960-1980年代） 梅特罗波利斯算法（1953）\n尼古拉斯·梅特罗波利斯（Nicholas Metropolis）等人提出了梅特罗波利斯算法，这是第一个马尔可夫链蒙特卡罗（MCMC）方法。这个算法可以从复杂的概率分布中抽样，为统计物理和贝叶斯统计打开了新的大门。\n算法非常优雅：\n从当前状态 $x$ 开始 提议一个新状态 $x’ = x + \\delta$（$\\delta$ 是随机扰动） 计算接受概率 $\\alpha = \\min\\left(1, \\frac{p(x’)}{p(x)}\\right)$，其中 $p$ 是目标分布 以概率 $\\alpha$ 接受新状态，否则保持原状态 重复 这个简单的规则保证了马尔可夫链会收敛到目标分布 $p(x)$！\n哈斯廷斯的扩展（1970）\nW.K. Hastings将梅特罗波利斯算法推广到更一般的情况，形成了现在广泛使用的Metropolis-Hastings算法。\n3.3 现代发展（1980年代至今） 吉布斯采样（1984）\nGeman兄弟提出的吉布斯采样（Gibbs Sampling）简化了MCMC的实现，特别适合高维问题。在每次迭代中，它只更新一个变量，而保持其他变量不变。\nflowchart TD Start[\"开始: 初始状态 x⁽⁰⁾\"] --\u003e Step1[\"第t轮迭代\"] Step1 --\u003e Update1[\"更新 x₁: 从 p(x₁|x₂, ..., x_d) 抽样\"] Update1 --\u003e Update2[\"更新 x₂: 从 p(x₂|x₁, x₃, ..., x_d) 抽样\"] Update2 --\u003e Update3[\"...\"] Update3 --\u003e UpdateD[\"更新 x_d: 从 p(x_d|x₁, ..., x_{d-1}) 抽样\"] UpdateD --\u003e Check{\"达到收敛?\"} Check --\u003e|否| Step1 Check --\u003e|是| Collect[\"收集样本用于估计\"] style Start fill:#007AFF,stroke:#007AFF,stroke-width:3px,color:#ffffff style Step1 fill:#34C759,stroke:#34C759,stroke-width:2px,color:#ffffff style Update1 fill:#34C759,stroke:#34C759,stroke-width:2px,color:#ffffff style Update2 fill:#34C759,stroke:#34C759,stroke-width:2px,color:#ffffff style Update3 fill:#34C759,stroke:#34C759,stroke-width:2px,color:#ffffff style UpdateD fill:#34C759,stroke:#34C759,stroke-width:2px,color:#ffffff style Check fill:#FF9500,stroke:#FF9500,stroke-width:2px,color:#ffffff style Collect fill:#32D74B,stroke:#32D74B,stroke-width:3px,color:#ffffff No-U-Turn Sampler（NUTS, 2011）\n随着计算机性能的提升，更复杂的MCMC方法被提出。NUTS是Hamilton Monte Carlo的一个自适应版本，它能自动选择合适的步长，大大提高了贝叶斯推断的效率。现在流行的概率编程框架Stan就使用了NUTS。\n3.4 蒙特卡罗方法家族谱系 graph TB MC[\"蒙特卡罗方法Monte Carlo Methods\"] --\u003e Direct[\"直接蒙特卡罗Direct Monte Carlo\"] MC --\u003e MCMC[\"马尔可夫链蒙特卡罗MCMC\"] Direct --\u003e MCInt[\"蒙特卡罗积分\"] Direct --\u003e MCSim[\"系统模拟\"] Direct --\u003e Quasi[\"拟蒙特卡罗Quasi-Monte Carlo\"] MCMC --\u003e Metro[\"Metropolis-Hastings(1953/1970)\"] MCMC --\u003e Gibbs[\"吉布斯采样Gibbs (1984)\"] MCMC --\u003e HMC[\"Hamilton Monte Carlo(1994)\"] MCMC --\u003e Slice[\"切片采样Slice (2003)\"] HMC --\u003e NUTS[\"NUTS(2011)\"] style MC fill:#007AFF,stroke:#007AFF,stroke-width:3px,color:#ffffff style Direct fill:#34C759,stroke:#34C759,stroke-width:2px,color:#ffffff style MCMC fill:#34C759,stroke:#34C759,stroke-width:2px,color:#ffffff style MCInt fill:#5AC8FA,stroke:#5AC8FA,stroke-width:1px,color:#ffffff style MCSim fill:#5AC8FA,stroke:#5AC8FA,stroke-width:1px,color:#ffffff style Quasi fill:#5AC8FA,stroke:#5AC8FA,stroke-width:1px,color:#ffffff style Metro fill:#AF52DE,stroke:#AF52DE,stroke-width:2px,color:#ffffff style Gibbs fill:#AF52DE,stroke:#AF52DE,stroke-width:2px,color:#ffffff style HMC fill:#AF52DE,stroke:#AF52DE,stroke-width:2px,color:#ffffff style Slice fill:#AF52DE,stroke:#AF52DE,stroke-width:2px,color:#ffffff style NUTS fill:#AF52DE,stroke:#AF52DE,stroke-width:2px,color:#ffffff 第四章：经典应用举例 4.1 计算π值：布丰投针的现代实现 让我们用现代蒙特卡罗方法来计算 $\\pi$。这里使用一个更直观的方法：在单位正方形内随机投点，计算落在内切圆中的比例。\n$$ \\frac{\\text{圆内点数}}{\\text{总点数}} \\approx \\frac{\\pi \\cdot 1^2}{2 \\times 2} = \\frac{\\pi}{4} $$\n因此：\n$$ \\pi \\approx 4 \\times \\frac{\\text{圆内点数}}{\\text{总点数}} $$\n算法步骤：\n在 $[-1, 1] \\times [-1, 1]$ 的正方形内随机生成 $N$ 个点 统计满足 $x^2 + y^2 \\leq 1$ 的点的数量 $n$ 计算 $\\pi \\approx 4n/N$ import numpy as np def estimate_pi(N): points = np.random.uniform(-1, 1, size=(N, 2)) inside = np.sum(points[:, 0]**2 + points[:, 1]**2 \u003c= 1) return 4 * inside / N for N in [1000, 10000, 100000, 1000000]: print(f\"N = {N:7d}, π ≈ {estimate_pi(N):.6f}\") 随着 $N$ 的增加，估计值会逐渐收敛到 $\\pi$ 的真实值。\n4.2 金融工程：期权定价 布莱克-舒尔斯-默顿模型\n1973年，布莱克、舒尔斯和默顿提出了期权定价的解析公式，但这基于许多简化假设。对于更复杂的衍生品（如美式期权、路径依赖期权），蒙特卡罗模拟几乎是唯一可行的方法。\n几何布朗运动模型\n假设股票价格 $S_t$ 服从几何布朗运动：\n$$ dS_t = \\mu S_t dt + \\sigma S_t dW_t $$\n其中 $W_t$ 是标准布朗运动。欧式看涨期权的收益是 $\\max(S_T - K, 0)$，其中 $K$ 是行权价，$T$ 是到期时间。\n蒙特卡罗定价方法：\n模拟 $N$ 条股票价格路径 对每条路径计算期权收益 计算收益的期望值并折现 离散化后，股票价格的模拟公式为：\n$$ S_{t+\\Delta t} = S_t \\exp\\left[\\left(\\mu - \\frac{\\sigma^2}{2}\\right)\\Delta t + \\sigma\\sqrt{\\Delta t} \\cdot Z\\right] $$\n其中 $Z \\sim \\mathcal{N}(0, 1)$。\ndef asian_option_price(S0, K, T, r, sigma, N_paths=100000): \"\"\"亚式期权定价的蒙特卡罗方法\"\"\" dt = 1/252 # 每日 steps = int(T * 252) prices = np.zeros((N_paths, steps + 1)) prices[:, 0] = S0 for t in range(steps): Z = np.random.standard_normal(N_paths) prices[:, t + 1] = prices[:, t] * np.exp( (r - 0.5 * sigma**2) * dt + sigma * np.sqrt(dt) * Z ) # 亚式期权：依赖于平均价格 avg_prices = np.mean(prices[:, 1:], axis=1) payoffs = np.maximum(avg_prices - K, 0) price = np.exp(-r * T) * np.mean(payoffs) return price 4.3 物理模拟：粒子输运 蒙特卡罗方法在核物理中的应用是它的起源。中子在反应堆中的行为可以用以下过程模拟：\n源抽样：中子从裂变源产生，具有随机的初始位置和方向 输运：中子以直线运动，直到碰撞 碰撞： 被原子核捕获 散射（改变方向） 引发裂变（产生新中子） 泄漏或吸收：中子逃逸系统或被吸收 每个中子的历史都是一个随机过程，通过模拟大量中子，我们可以估计：\n临界参数（反应堆能否维持链式反应） 功率分布 屏蔽效率 4.4 机器学习：MCMC与贝叶斯推断 贝叶斯推断的核心问题\n在贝叶斯统计中，我们需要计算后验分布：\n$$ p(\\theta | D) = \\frac{p(D | \\theta) p(\\theta)}{\\int p(D | \\theta) p(\\theta) d\\theta} $$\n其中分母（证据因子）的积分通常难以计算。MCMC方法让我们可以从后验分布中直接抽样，而不需要计算这个积分。\n应用示例：Logistic回归的贝叶斯推断\ndef logistic(X, beta): return 1 / (1 + np.exp(-X @ beta)) def log_likelihood(beta, X, y): p = logistic(X, beta) return np.sum(y * np.log(p) + (1 - y) * np.log(1 - p)) def log_prior(beta): return np.sum(-0.5 * beta**2) # 标准正态先验 def metropolis_hastings(X, y, n_samples=10000, burn_in=1000): n_features = X.shape[1] beta = np.zeros(n_features) samples = [] for i in range(n_samples + burn_in): # 提议新的beta值 beta_new = beta + np.random.normal(0, 0.1, n_features) # 计算接受概率 log_ratio = (log_likelihood(beta_new, X, y) + log_prior(beta_new) - log_likelihood(beta, X, y) - log_prior(beta)) if np.log(np.random.uniform()) \u003c log_ratio: beta = beta_new if i \u003e= burn_in: samples.append(beta.copy()) return np.array(samples) 强化学习中的蒙特卡罗方法\n蒙特卡罗方法在强化学习中也有重要应用。在蒙特卡罗策略评估中，我们通过完整episode的回报来估计状态值：\n$$ V(s) = \\mathbb{E}[G_t | S_t = s] $$\n其中 $G_t = R_{t+1} + \\gamma R_{t+2} + \\gamma^2 R_{t+3} + \\cdots$ 是累积回报。\n通过多次运行episode并计算平均回报，我们可以估计每个状态的价值函数。\n4.5 其他重要应用 计算生物学：蛋白质折叠\n蛋白质的三维结构决定了它的功能。预测蛋白质结构需要在巨大的构象空间中搜索，蒙特卡罗方法（特别是Metropolis准则）是核心工具之一。\n计算机图形学：光线追踪\n在渲染真实感图像时，需要计算光线的积分方程。蒙特卡罗光线跟踪通过随机采样光线方向来模拟全局光照效果，产生了电影级的视觉效果。\n运筹学：排队系统模拟\n银行柜台、客服中心、医院急诊室等排队系统的优化，需要模拟顾客到达、服务时间、队列行为等随机过程。蒙特卡罗模拟是评估不同方案的标准工具。\n第五章：高级技巧与优化 基础的蒙特卡罗方法虽然强大，但有时收敛速度太慢。下面介绍几种常用的优化技巧。\n5.1 重要抽样 基本思想：如果我们知道函数在某些区域更重要，就应该在这些区域多抽样。\n考虑计算期望：\n$$ \\mathbb{E}{p}[f(X)] = \\int f(x) p(x) dx = \\int \\frac{f(x) p(x)}{q(x)} q(x) dx = \\mathbb{E}{q}\\left[\\frac{f(X) p(X)}{q(X)}\\right] $$\n如果我们选择一个与 $|f(x)| p(x)$ 成比例的分布 $q(x)$，方差可以显著减小。\n5.2 分层抽样 将样本空间分成若干层（strata），每层单独抽样：\n$$ \\mathbb{E}[f(X)] = \\sum_{h=1}^{H} P(h) \\cdot \\mathbb{E}[f(X) | h] $$\n其中 $P(h)$ 是落在第 $h$ 层的概率。这样可以保证样本在各层均匀分布。\n5.3 拟蒙特卡罗方法 拟蒙特卡罗方法使用确定性的低差异序列（如Sobol序列、Halton序列）替代随机序列。这些序列在空间中分布更加均匀，可以加速收敛到 $O(N^{-1} \\log^d N)$。\n5.4 方差缩减技术对比 graph LR Base[\"基础蒙特卡罗误差: O(N^(-1/2))\"] --\u003e IS[\"重要抽样选择最优抽样分布\"] Base --\u003e SS[\"分层抽样空间分区均匀抽样\"] Base --\u003e AV[\"对偶变量利用负相关性\"] Base --\u003e CV[\"控制变量利用相关变量\"] Base --\u003e QMC[\"拟蒙特卡罗误差: O(N^(-1) log^d N)\"] IS --\u003e Result1[\"大幅降低方差但需要领域知识\"] SS --\u003e Result2[\"均匀覆盖空间适合规则区域\"] AV --\u003e Result3[\"简单有效利用对称性\"] CV --\u003e Result4[\"显著降低方差需要找到好的控制变量\"] QMC --\u003e Result5[\"超线性收敛低维问题特别有效\"] style Base fill:#007AFF,stroke:#007AFF,stroke-width:3px,color:#ffffff style IS fill:#34C759,stroke:#34C759,stroke-width:2px,color:#ffffff style SS fill:#34C759,stroke:#34C759,stroke-width:2px,color:#ffffff style AV fill:#34C759,stroke:#34C759,stroke-width:2px,color:#ffffff style CV fill:#34C759,stroke:#34C759,stroke-width:2px,color:#ffffff style QMC fill:#AF52DE,stroke:#AF52DE,stroke-width:2px,color:#ffffff style Result1 fill:#5AC8FA,stroke:#5AC8FA,stroke-width:1px,color:#ffffff style Result2 fill:#5AC8FA,stroke:#5AC8FA,stroke-width:1px,color:#ffffff style Result3 fill:#5AC8FA,stroke:#5AC8FA,stroke-width:1px,color:#ffffff style Result4 fill:#5AC8FA,stroke:#5AC8FA,stroke-width:1px,color:#ffffff style Result5 fill:#FF9500,stroke:#FF9500,stroke-width:2px,color:#ffffff 第六章：蒙特卡罗方法在人工智能中的应用 6.1 蒙特卡罗树搜索（MCTS） 2006年提出的蒙特卡罗树搜索彻底改变了计算机博弈。AlphaGo的核心就是深度学习与MCTS的结合。\nMCTS有四个步骤：\nflowchart TD subgraph Selection[\"选择 Selection\"] S1[\"从根节点开始\"] --\u003e S2[\"根据UCB1公式选择子节点\"] S2 --\u003e S3{\"到达叶子节点?\"} S3 --\u003e|否| S2 end Selection --\u003e Expansion[\"扩展 Expansion添加一个新节点\"] Expansion --\u003e Simulation[\"模拟 Simulation随机对弈至终局\"] Simulation --\u003e Backprop[\"回溯 Backpropagation更新路径上所有节点的统计\"] style S1 fill:#34C759,stroke:#34C759,stroke-width:2px,color:#ffffff style S2 fill:#34C759,stroke:#34C759,stroke-width:2px,color:#ffffff style S3 fill:#FF9500,stroke:#FF9500,stroke-width:2px,color:#ffffff style Selection fill:#8E8E93,stroke:#8E8E93,stroke-width:1px,color:#ffffff style Expansion fill:#007AFF,stroke:#007AFF,stroke-width:3px,color:#ffffff style Simulation fill:#007AFF,stroke:#007AFF,stroke-width:3px,color:#ffffff style Backprop fill:#007AFF,stroke:#007AFF,stroke-width:3px,color:#ffffff UCB1公式（Upper Confidence Bound）：\n$$ \\text{UCB1}(i) = \\frac{W_i}{N_i} + c \\sqrt{\\frac{\\ln N}{N_i}} $$\n其中 $W_i$ 是节点 $i$ 的胜率，$N_i$ 是访问次数，$N$ 是父节点访问次数，$c$ 是探索参数。\n这个公式平衡了利用（exploitation，选择胜率高的节点）和探索（exploration，选择访问少的节点）。\n6.2 变分推断与MCMC的比较 在现代贝叶斯机器学习中，有两种主要的推断方法：\n特性 MCMC 变分推断 精度 渐近精确 近似 速度 慢 快 可扩展性 有限 强 适用场景 小数据，精确性要求高 大数据，实时应用 随着计算资源的增加，MCMC方法在机器学习中的应用正在复兴。\n6.3 强化学习中的蒙特卡罗方法 蒙特卡罗策略梯度\nREINFORCE算法是策略梯度方法的基础：\n$$ \\nabla J(\\theta) = \\mathbb{E}{\\pi\\theta}\\left[\\frac{\\nabla \\pi_\\theta(a|s)}{\\pi_\\theta(a|s)} G_t\\right] $$\n使用蒙特卡罗回报 $G_t$ 作为梯度估计：\n$$ \\hat{g} = \\sum_{t=0}^{T} \\nabla \\ln \\pi_\\theta(A_t|S_t) G_t $$\n这个简单的估计虽然方差大，但它是无偏的，是现代强化学习算法的基石。\n6.4 深度学习中的随机性 现代深度学习充满了蒙特卡罗思想：\n随机梯度下降：每次迭代随机选择一个小批量的数据 Dropout：训练时随机丢弃神经元，可视为模型平均的蒙特卡罗近似 Batch Normalization：使用小批量的统计量作为总体统计量的估计 结语：随机性作为工具 从曼哈顿计划保密代号到无处不在的计算工具，蒙特卡罗方法走过了八十年的历程。它的核心思想——用随机性来求解确定性问题——看似简单，却蕴含着深刻的数学原理。\n当我们回望这段历史，可以看到一些有趣的脉络：\n问题的驱动：蒙特卡罗方法诞生于核物理的具体需求，而非纯粹的数学探索 技术的协同：它与计算机的发展相互促进，互为因果 思想的普适性：从金融到生物学，从图形学到人工智能，它的应用跨越了几乎所有的科学领域 蒙特卡罗方法告诉我们：确定性的问题可以借助随机性来求解。这不仅是数学上的技巧，更是一种深刻的思维方式的转变——在混沌中寻找秩序，在随机中发现规律。\n随着量子计算的发展，我们或许正站在新的蒙特卡罗革命的门槛上。量子随机性可能为蒙特卡罗方法带来新的维度，就像当年电子计算机让它从理论变为现实一样。\n正如乌拉姆所说：\n“使用随机数来解决数学问题的想法，就像用骰子来决定晚餐吃什么一样荒谬——直到你意识到，这或许是唯一可行的方法。”\n在这个充满不确定性的世界里，蒙特卡罗方法给了我们一把钥匙，让随机性成为我们探索未知的工具，而不是障碍。\n参考文献\nMetropolis, N., \u0026 Ulam, S. (1949). The Monte Carlo Method. Journal of the American Statistical Association, 44(247), 335-341.\nHastings, W.K. (1970). Monte Carlo Sampling Methods Using Markov Chains and Their Applications. Biometrika, 57(1), 97-109.\nGeman, S., \u0026 Geman, D. (1984). Stochastic Relaxation, Gibbs Distributions, and the Bayesian Restoration of Images. IEEE Transactions on Pattern Analysis and Machine Intelligence, 6(6), 721-741.\nSilver, D., et al. (2016). Mastering the Game of Go with Deep Neural Networks and Tree Search. Nature, 529, 484-489.\nNeal, R.M. (2011). MCMC Using Hamiltonian Dynamics. In Handbook of Markov Chain Monte Carlo (pp. 113-162). Chapman and Hall/CRC.\n","wordCount":"1171","inLanguage":"en","image":"https://s-ai-unix.github.io/images/covers/monte-carlo-method.jpg","datePublished":"2026-01-21T23:00:00+08:00","dateModified":"2026-01-21T23:00:00+08:00","author":{"@type":"Person","name":"s-ai-unix"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://s-ai-unix.github.io/posts/2026-01-21-monte-carlo-method/"},"publisher":{"@type":"Organization","name":"s-ai-unix's Blog","logo":{"@type":"ImageObject","url":"https://s-ai-unix.github.io/favicon.ico"}}}</script><link rel=stylesheet href=https://s-ai-unix.github.io/css/classical-quote.css></head><body id=top><header class=header><nav class=nav><div class=logo><a href=https://s-ai-unix.github.io/ accesskey=h title="s-ai-unix's Blog (Alt + H)">s-ai-unix's Blog</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://s-ai-unix.github.io/ title="🏠 首页"><span>🏠 首页</span></a></li><li><a href=https://s-ai-unix.github.io/posts/ title="📚 文章"><span>📚 文章</span></a></li><li><a href=https://s-ai-unix.github.io/archives/ title="📁 归档"><span>📁 归档</span></a></li><li><a href=https://s-ai-unix.github.io/tags/ title="🏷️ 标签"><span>🏷️ 标签</span></a></li><li><a href=https://s-ai-unix.github.io/search/ title="🔍 搜索 (Alt + /)" accesskey=/><span>🔍 搜索</span></a></li><li><a href=https://s-ai-unix.github.io/about/ title="👤 关于"><span>👤 关于</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://s-ai-unix.github.io/>Home</a>&nbsp;»&nbsp;<a href=https://s-ai-unix.github.io/posts/>Posts</a></div><h1 class="post-title entry-hint-parent">蒙特卡罗算法：从原子弹到人工智能的随机之旅</h1><div class=post-description>从曼哈顿计划的保密代号到现代科学计算的核心工具，本文系统介绍蒙特卡罗方法的发展历程、数学基础和广泛应用。</div><div class=post-meta><span title='2026-01-21 23:00:00 +0800 CST'>January 21, 2026</span>&nbsp;·&nbsp;<span>6 min</span>&nbsp;·&nbsp;<span>1171 words</span>&nbsp;·&nbsp;<span>s-ai-unix</span></div></header><figure class=entry-cover><a href=https://s-ai-unix.github.io/images/covers/monte-carlo-method.jpg target=_blank rel="noopener noreferrer"><img loading=eager src=https://s-ai-unix.github.io/images/covers/monte-carlo-method.jpg alt=蒙特卡罗方法的随机性可视化></a><figcaption>随机性中蕴含的确定性</figcaption></figure><div class=toc><details open><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#%e5%bc%95%e8%a8%80%e6%8e%b7%e9%aa%b0%e5%ad%90%e8%a7%a3%e6%96%b9%e7%a8%8b aria-label=引言：掷骰子解方程>引言：掷骰子解方程</a></li><li><a href=#%e7%ac%ac%e4%b8%80%e7%ab%a0%e8%92%99%e7%89%b9%e5%8d%a1%e7%bd%97%e7%9a%84%e8%af%9e%e7%94%9f%e6%9b%bc%e5%93%88%e9%a1%bf%e8%ae%a1%e5%88%92%e7%9a%84%e7%a7%98%e5%af%86%e4%bb%a3%e5%8f%b7 aria-label=第一章：蒙特卡罗的诞生——曼哈顿计划的秘密代号>第一章：蒙特卡罗的诞生——曼哈顿计划的秘密代号</a><ul><li><a href=#11-%e6%91%a9%e7%ba%b3%e5%93%a5%e7%9a%84%e8%b5%8c%e5%9c%ba%e4%b8%8e%e5%8e%9f%e5%ad%90%e5%bc%b9%e7%9a%84%e7%a7%98%e5%af%86 aria-label="1.1 摩纳哥的赌场与原子弹的秘密">1.1 摩纳哥的赌场与原子弹的秘密</a></li><li><a href=#12-%e6%97%a9%e6%9c%9f%e7%9a%84%e6%80%9d%e6%83%b3%e8%90%8c%e8%8a%bd aria-label="1.2 早期的思想萌芽">1.2 早期的思想萌芽</a></li></ul></li><li><a href=#%e7%ac%ac%e4%ba%8c%e7%ab%a0%e6%95%b0%e5%ad%a6%e5%9f%ba%e7%a1%80%e4%b8%ba%e4%bb%80%e4%b9%88%e9%9a%8f%e6%9c%ba%e6%80%a7%e6%9c%89%e6%95%88 aria-label=第二章：数学基础——为什么随机性有效？>第二章：数学基础——为什么随机性有效？</a><ul><li><a href=#21-%e5%a4%a7%e6%95%b0%e5%ae%9a%e5%be%8b%e9%a2%91%e7%8e%87%e7%9a%84%e7%a8%b3%e5%ae%9a%e6%80%a7 aria-label="2.1 大数定律：频率的稳定性">2.1 大数定律：频率的稳定性</a></li><li><a href=#22-%e4%b8%ad%e5%bf%83%e6%9e%81%e9%99%90%e5%ae%9a%e7%90%86%e8%af%af%e5%b7%ae%e7%9a%84%e4%bc%b0%e8%ae%a1 aria-label="2.2 中心极限定理：误差的估计">2.2 中心极限定理：误差的估计</a></li><li><a href=#23-%e8%92%99%e7%89%b9%e5%8d%a1%e7%bd%97%e7%a7%af%e5%88%86%e7%9a%84%e5%9f%ba%e6%9c%ac%e5%8e%9f%e7%90%86 aria-label="2.3 蒙特卡罗积分的基本原理">2.3 蒙特卡罗积分的基本原理</a></li></ul></li><li><a href=#%e7%ac%ac%e4%b8%89%e7%ab%a0%e8%92%99%e7%89%b9%e5%8d%a1%e7%bd%97%e6%96%b9%e6%b3%95%e7%9a%84%e5%8f%91%e5%b1%95%e5%8e%86%e7%a8%8b aria-label=第三章：蒙特卡罗方法的发展历程>第三章：蒙特卡罗方法的发展历程</a><ul><li><a href=#31-%e5%88%9d%e5%88%9b%e6%97%b6%e6%9c%9f1940-1950%e5%b9%b4%e4%bb%a3 aria-label="3.1 初创时期（1940-1950年代）">3.1 初创时期（1940-1950年代）</a></li><li><a href=#32-%e6%96%b9%e6%b3%95%e7%9a%84%e6%88%90%e7%86%9f1960-1980%e5%b9%b4%e4%bb%a3 aria-label="3.2 方法的成熟（1960-1980年代）">3.2 方法的成熟（1960-1980年代）</a></li><li><a href=#33-%e7%8e%b0%e4%bb%a3%e5%8f%91%e5%b1%951980%e5%b9%b4%e4%bb%a3%e8%87%b3%e4%bb%8a aria-label="3.3 现代发展（1980年代至今）">3.3 现代发展（1980年代至今）</a></li><li><a href=#34-%e8%92%99%e7%89%b9%e5%8d%a1%e7%bd%97%e6%96%b9%e6%b3%95%e5%ae%b6%e6%97%8f%e8%b0%b1%e7%b3%bb aria-label="3.4 蒙特卡罗方法家族谱系">3.4 蒙特卡罗方法家族谱系</a></li></ul></li><li><a href=#%e7%ac%ac%e5%9b%9b%e7%ab%a0%e7%bb%8f%e5%85%b8%e5%ba%94%e7%94%a8%e4%b8%be%e4%be%8b aria-label=第四章：经典应用举例>第四章：经典应用举例</a><ul><li><a href=#41-%e8%ae%a1%e7%ae%97%cf%80%e5%80%bc%e5%b8%83%e4%b8%b0%e6%8a%95%e9%92%88%e7%9a%84%e7%8e%b0%e4%bb%a3%e5%ae%9e%e7%8e%b0 aria-label="4.1 计算π值：布丰投针的现代实现">4.1 计算π值：布丰投针的现代实现</a></li><li><a href=#42-%e9%87%91%e8%9e%8d%e5%b7%a5%e7%a8%8b%e6%9c%9f%e6%9d%83%e5%ae%9a%e4%bb%b7 aria-label="4.2 金融工程：期权定价">4.2 金融工程：期权定价</a></li><li><a href=#43-%e7%89%a9%e7%90%86%e6%a8%a1%e6%8b%9f%e7%b2%92%e5%ad%90%e8%be%93%e8%bf%90 aria-label="4.3 物理模拟：粒子输运">4.3 物理模拟：粒子输运</a></li><li><a href=#44-%e6%9c%ba%e5%99%a8%e5%ad%a6%e4%b9%a0mcmc%e4%b8%8e%e8%b4%9d%e5%8f%b6%e6%96%af%e6%8e%a8%e6%96%ad aria-label="4.4 机器学习：MCMC与贝叶斯推断">4.4 机器学习：MCMC与贝叶斯推断</a></li><li><a href=#45-%e5%85%b6%e4%bb%96%e9%87%8d%e8%a6%81%e5%ba%94%e7%94%a8 aria-label="4.5 其他重要应用">4.5 其他重要应用</a></li></ul></li><li><a href=#%e7%ac%ac%e4%ba%94%e7%ab%a0%e9%ab%98%e7%ba%a7%e6%8a%80%e5%b7%a7%e4%b8%8e%e4%bc%98%e5%8c%96 aria-label=第五章：高级技巧与优化>第五章：高级技巧与优化</a><ul><li><a href=#51-%e9%87%8d%e8%a6%81%e6%8a%bd%e6%a0%b7 aria-label="5.1 重要抽样">5.1 重要抽样</a></li><li><a href=#52-%e5%88%86%e5%b1%82%e6%8a%bd%e6%a0%b7 aria-label="5.2 分层抽样">5.2 分层抽样</a></li><li><a href=#53-%e6%8b%9f%e8%92%99%e7%89%b9%e5%8d%a1%e7%bd%97%e6%96%b9%e6%b3%95 aria-label="5.3 拟蒙特卡罗方法">5.3 拟蒙特卡罗方法</a></li><li><a href=#54-%e6%96%b9%e5%b7%ae%e7%bc%a9%e5%87%8f%e6%8a%80%e6%9c%af%e5%af%b9%e6%af%94 aria-label="5.4 方差缩减技术对比">5.4 方差缩减技术对比</a></li></ul></li><li><a href=#%e7%ac%ac%e5%85%ad%e7%ab%a0%e8%92%99%e7%89%b9%e5%8d%a1%e7%bd%97%e6%96%b9%e6%b3%95%e5%9c%a8%e4%ba%ba%e5%b7%a5%e6%99%ba%e8%83%bd%e4%b8%ad%e7%9a%84%e5%ba%94%e7%94%a8 aria-label=第六章：蒙特卡罗方法在人工智能中的应用>第六章：蒙特卡罗方法在人工智能中的应用</a><ul><li><a href=#61-%e8%92%99%e7%89%b9%e5%8d%a1%e7%bd%97%e6%a0%91%e6%90%9c%e7%b4%a2mcts aria-label="6.1 蒙特卡罗树搜索（MCTS）">6.1 蒙特卡罗树搜索（MCTS）</a></li><li><a href=#62-%e5%8f%98%e5%88%86%e6%8e%a8%e6%96%ad%e4%b8%8emcmc%e7%9a%84%e6%af%94%e8%be%83 aria-label="6.2 变分推断与MCMC的比较">6.2 变分推断与MCMC的比较</a></li><li><a href=#63-%e5%bc%ba%e5%8c%96%e5%ad%a6%e4%b9%a0%e4%b8%ad%e7%9a%84%e8%92%99%e7%89%b9%e5%8d%a1%e7%bd%97%e6%96%b9%e6%b3%95 aria-label="6.3 强化学习中的蒙特卡罗方法">6.3 强化学习中的蒙特卡罗方法</a></li><li><a href=#64-%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0%e4%b8%ad%e7%9a%84%e9%9a%8f%e6%9c%ba%e6%80%a7 aria-label="6.4 深度学习中的随机性">6.4 深度学习中的随机性</a></li></ul></li><li><a href=#%e7%bb%93%e8%af%ad%e9%9a%8f%e6%9c%ba%e6%80%a7%e4%bd%9c%e4%b8%ba%e5%b7%a5%e5%85%b7 aria-label=结语：随机性作为工具>结语：随机性作为工具</a></li></ul></div></details></div><div class=post-content><h2 id=引言掷骰子解方程>引言：掷骰子解方程<a hidden class=anchor aria-hidden=true href=#引言掷骰子解方程>#</a></h2><p>想象一下，有人告诉你：要计算一个复杂的定积分，不需要微积分，只需要掷足够多的骰子。你大概会觉得这个人疯了。然而，这正是二十世纪最伟大的计算方法之一——<strong>蒙特卡罗方法</strong>（Monte Carlo Method）的核心思想。</p><p>当我们面对那些传统方法难以处理的高维积分、复杂系统的模拟或者无法解析求解的概率问题时，蒙特卡罗方法给出了一个看似简单却深刻的答案：<strong>用随机性来求解确定性问题</strong>。这种方法已经深入到科学的方方面面——从核物理到金融工程，从生物进化到人工智能，无处不见它的身影。</p><p>让我们从一个最经典的例子开始：如何用"扔针"来计算 $\pi$ 的值。</p><h2 id=第一章蒙特卡罗的诞生曼哈顿计划的秘密代号>第一章：蒙特卡罗的诞生——曼哈顿计划的秘密代号<a hidden class=anchor aria-hidden=true href=#第一章蒙特卡罗的诞生曼哈顿计划的秘密代号>#</a></h2><h3 id=11-摩纳哥的赌场与原子弹的秘密>1.1 摩纳哥的赌场与原子弹的秘密<a hidden class=anchor aria-hidden=true href=#11-摩纳哥的赌场与原子弹的秘密>#</a></h3><p>&ldquo;蒙特卡罗"这个名字，源自摩纳哥著名的赌城。1940 年代，在洛斯阿拉莫斯实验室，一群顶尖的科学家正在紧锣密鼓地研制世界上第一颗原子弹。在这个属于"曼哈顿计划"的绝密基地里，数学家约翰·冯·诺伊曼（John von Neumann）和斯坦尼斯拉夫·乌拉姆（Stanislaw Ulam）正在研究核裂变中的中子扩散问题。</p><p>这个问题极其复杂：中子在原子弹内部的行为是随机的，它们可能被原子核捕获，可能引发新的裂变，也可能逃逸出去。传统的方法根本无法处理这种复杂的随机过程。</p><p>乌拉姆后来回忆起他是如何产生这个想法的：</p><blockquote><p>&ldquo;当时我正因病康复，在玩纸牌接龙。我开始思考：如果把牌随机排列一百次，大概有多少次能成功接龙？相比于把所有可能的情况都计算出来，直接实验似乎更容易&mldr;&rdquo;</p></blockquote><p>这个看似简单的想法，孕育了一个全新的计算方法。由于这种方法涉及随机性，而蒙特卡罗又以赌场闻名，冯·诺伊曼就给它起了"蒙特卡罗"这个代号——既是保密的需要，也恰如其分地描述了方法的本质。</p><h3 id=12-早期的思想萌芽>1.2 早期的思想萌芽<a hidden class=anchor aria-hidden=true href=#12-早期的思想萌芽>#</a></h3><p>虽然蒙特卡罗方法在1940年代才正式命名，但用随机性来解决确定性问题的思想古已有之。</p><p><strong>1777年，布丰投针实验</strong></p><p>法国数学家乔治-路易·勒克莱尔，布丰伯爵（Georges-Louis Leclerc, Comte de Buffon）提出了第一个著名的随机实验：</p><p>在一张画满平行线的纸（线间距为 $d$）上随机投掷一根长度为 $l$ 的针（$l &lt; d$），针与任意一条平行线相交的概率是多少？</p><p>布丰证明了，这个概率是：</p><p>$$
P = \frac{2l}{\pi d}
$$</p><p>这给出了一个计算 $\pi$ 的方法：如果我们投掷针 $N$ 次，其中 $n$ 次与线相交，那么：</p><p>$$
\frac{n}{N} \approx \frac{2l}{\pi d} \implies \pi \approx \frac{2lN}{nd}
$$</p><p>这个实验被多次验证：1850年，沃尔夫在苏黎世投掷了5000次，得到 $\pi \approx 3.1596$；1901年，拉泽里尼投掷3408次，甚至得到了精确到小数点后6位的 $\pi$ 值（虽然有人怀疑他可能"选择性记录"了结果）。</p><p><strong>19世纪末的统计学革命</strong></p><p>随着统计学的发展，卡尔·皮尔逊（Karl Pearson）等人开始使用随机抽样来解决统计问题。但这些方法仍然主要用于验证已知的结果，而不是作为通用的计算工具。</p><h2 id=第二章数学基础为什么随机性有效>第二章：数学基础——为什么随机性有效？<a hidden class=anchor aria-hidden=true href=#第二章数学基础为什么随机性有效>#</a></h2><p>要理解蒙特卡罗方法，我们需要先理解它的数学基础。这一切都建立在<strong>大数定律</strong>和<strong>中心极限定理</strong>这两大概率论支柱之上。</p><h3 id=21-大数定律频率的稳定性>2.1 大数定律：频率的稳定性<a hidden class=anchor aria-hidden=true href=#21-大数定律频率的稳定性>#</a></h3><p><strong>强大数定律</strong>告诉我们：如果 $X_1, X_2, \ldots$ 是独立同分布的随机变量，期望为 $\mu$，方差有限，那么：</p><p>$$
\lim_{N \to \infty} \frac{1}{N}\sum_{i=1}^{N} X_i = \mu \quad \text{几乎必然成立}
$$</p><p>用通俗的话说：<strong>当试验次数足够多时，样本平均值会收敛到真实期望值</strong>。</p><p>这正是蒙特卡罗方法的核心！如果我们能够把一个待求解的问题转化为某个随机变量的期望计算，那么通过大量的随机抽样，我们就可以得到这个期望的近似值。</p><h3 id=22-中心极限定理误差的估计>2.2 中心极限定理：误差的估计<a hidden class=anchor aria-hidden=true href=#22-中心极限定理误差的估计>#</a></h3><p>大数定律告诉我们蒙特卡罗方法<strong>最终会收敛</strong>，但中心极限定理告诉我们<strong>收敛的速度</strong>。</p><p>设 $X_1, X_2, \ldots, X_N$ 是独立同分布的随机变量，期望为 $\mu$，方差为 $\sigma^2$。定义样本均值为：</p><p>$$
\bar{X}<em>N = \frac{1}{N}\sum</em>{i=1}^{N} X_i
$$</p><p>中心极限定理告诉我们：</p><p>$$
\frac{\sqrt{N}(\bar{X}_N - \mu)}{\sigma} \xrightarrow{d} \mathcal{N}(0, 1)
$$</p><p>这意味着对于大 $N$，$\bar{X}_N$ 近似服从正态分布 $\mathcal{N}(\mu, \sigma^2/N)$。</p><p>这个结果极其重要，因为它给出了<strong>误差估计</strong>：</p><ul><li>标准误差是 $\sigma/\sqrt{N}$</li><li>95% 置信区间大约是 $\mu \pm 1.96\sigma/\sqrt{N}$</li></ul><p>注意到一个关键事实：<strong>误差以 $1/\sqrt{N}$ 的速度下降</strong>。这意味着：</p><ul><li>要把精度提高10倍，需要100倍的样本</li><li>要把精度提高100倍，需要10000倍的样本</li></ul><p>这看起来似乎很慢，但我们稍后会看到，在高维问题中，这已经是非常优秀的收敛速度了。</p><h3 id=23-蒙特卡罗积分的基本原理>2.3 蒙特卡罗积分的基本原理<a hidden class=anchor aria-hidden=true href=#23-蒙特卡罗积分的基本原理>#</a></h3><p>让我们看看如何用蒙特卡罗方法计算定积分。假设我们要计算：</p><p>$$
I = \int_{a}^{b} f(x) , dx
$$</p><p>我们可以把它改写为期望的形式：</p><p>$$
I = \int_{a}^{b} f(x) , dx = (b-a) \int_{a}^{b} f(x) \cdot \frac{1}{b-a} , dx = (b-a) \cdot \mathbb{E}[f(X)]
$$</p><p>其中 $X$ 是在 $[a, b]$ 上均匀分布的随机变量。</p><p>蒙特卡罗方法的做法是：</p><ol><li>生成 $N$ 个在 $[a, b]$ 上均匀分布的随机点 $X_1, X_2, \ldots, X_N$</li><li>计算 $I_N = \frac{b-a}{N}\sum_{i=1}^{N} f(X_i)$</li></ol><p>根据大数定律，$I_N \to I$ 当 $N \to \infty$。</p><p><strong>高维积分的情况</strong></p><p>蒙特卡罗方法的真正威力在高维积分中体现。考虑 $d$ 维积分：</p><p>$$
I = \int_{[0,1]^d} f(\mathbf{x}) , d\mathbf{x}
$$</p><p>传统的数值积分方法（如梯形法则、辛普森法则）在 $d$ 维空间中的误差通常是 $O(N^{-2/d})$，这意味着随着维度 $d$ 的增加，收敛速度急剧下降——这就是著名的<strong>维度灾难</strong>（Curse of Dimensionality）。</p><p>而蒙特卡罗方法的误差是 $O(N^{-1/2})$，<strong>与维度无关</strong>！这是蒙特卡罗方法在高维问题中无可替代的根本原因。</p><h2 id=第三章蒙特卡罗方法的发展历程>第三章：蒙特卡罗方法的发展历程<a hidden class=anchor aria-hidden=true href=#第三章蒙特卡罗方法的发展历程>#</a></h2><h3 id=31-初创时期1940-1950年代>3.1 初创时期（1940-1950年代）<a hidden class=anchor aria-hidden=true href=#31-初创时期1940-1950年代>#</a></h3><p><strong>洛斯阿拉莫斯的突破</strong></p><p>在曼哈顿计划中，蒙特卡罗方法被用于解决中子输运问题。冯·诺伊曼和乌拉姆开发了一套完整的算法框架，包括：</p><ul><li>重要抽样（Importance Sampling）：让随机抽样更加"聪明&rdquo;</li><li>分层抽样（Stratified Sampling）：把样本空间分区以提高精度</li></ul><p><strong>第一台计算机的助力</strong></p><p>有趣的是，蒙特卡罗方法的兴起与电子计算机的诞生几乎是同步的。在ENIAC上运行的早期蒙特卡罗模拟，第一次让科学家们看到了这种方法的巨大潜力。</p><h3 id=32-方法的成熟1960-1980年代>3.2 方法的成熟（1960-1980年代）<a hidden class=anchor aria-hidden=true href=#32-方法的成熟1960-1980年代>#</a></h3><p><strong>梅特罗波利斯算法（1953）</strong></p><p>尼古拉斯·梅特罗波利斯（Nicholas Metropolis）等人提出了<strong>梅特罗波利斯算法</strong>，这是第一个<strong>马尔可夫链蒙特卡罗</strong>（MCMC）方法。这个算法可以从复杂的概率分布中抽样，为统计物理和贝叶斯统计打开了新的大门。</p><p>算法非常优雅：</p><ol><li>从当前状态 $x$ 开始</li><li>提议一个新状态 $x&rsquo; = x + \delta$（$\delta$ 是随机扰动）</li><li>计算接受概率 $\alpha = \min\left(1, \frac{p(x&rsquo;)}{p(x)}\right)$，其中 $p$ 是目标分布</li><li>以概率 $\alpha$ 接受新状态，否则保持原状态</li><li>重复</li></ol><p>这个简单的规则保证了马尔可夫链会收敛到目标分布 $p(x)$！</p><p><strong>哈斯廷斯的扩展（1970）</strong></p><p>W.K. Hastings将梅特罗波利斯算法推广到更一般的情况，形成了现在广泛使用的<strong>Metropolis-Hastings算法</strong>。</p><h3 id=33-现代发展1980年代至今>3.3 现代发展（1980年代至今）<a hidden class=anchor aria-hidden=true href=#33-现代发展1980年代至今>#</a></h3><p><strong>吉布斯采样（1984）</strong></p><p>Geman兄弟提出的<strong>吉布斯采样</strong>（Gibbs Sampling）简化了MCMC的实现，特别适合高维问题。在每次迭代中，它只更新一个变量，而保持其他变量不变。</p><div class=mermaid-wrapper style="background:#fff;padding:2rem 1rem;margin:2rem 0;border-radius:8px;box-shadow:0 2px 12px rgba(0,0,0,8%)"><div class=mermaid>flowchart TD
Start["开始: 初始状态 x⁽⁰⁾"] --> Step1["第t轮迭代"]
Step1 --> Update1["更新 x₁: 从 p(x₁|x₂, ..., x_d) 抽样"]
Update1 --> Update2["更新 x₂: 从 p(x₂|x₁, x₃, ..., x_d) 抽样"]
Update2 --> Update3["..."]
Update3 --> UpdateD["更新 x_d: 从 p(x_d|x₁, ..., x_{d-1}) 抽样"]
UpdateD --> Check{"达到收敛?"}
Check -->|否| Step1
Check -->|是| Collect["收集样本用于估计"]
style Start fill:#007AFF,stroke:#007AFF,stroke-width:3px,color:#ffffff
style Step1 fill:#34C759,stroke:#34C759,stroke-width:2px,color:#ffffff
style Update1 fill:#34C759,stroke:#34C759,stroke-width:2px,color:#ffffff
style Update2 fill:#34C759,stroke:#34C759,stroke-width:2px,color:#ffffff
style Update3 fill:#34C759,stroke:#34C759,stroke-width:2px,color:#ffffff
style UpdateD fill:#34C759,stroke:#34C759,stroke-width:2px,color:#ffffff
style Check fill:#FF9500,stroke:#FF9500,stroke-width:2px,color:#ffffff
style Collect fill:#32D74B,stroke:#32D74B,stroke-width:3px,color:#ffffff</div></div><p><strong>No-U-Turn Sampler（NUTS, 2011）</strong></p><p>随着计算机性能的提升，更复杂的MCMC方法被提出。NUTS是Hamilton Monte Carlo的一个自适应版本，它能自动选择合适的步长，大大提高了贝叶斯推断的效率。现在流行的概率编程框架Stan就使用了NUTS。</p><h3 id=34-蒙特卡罗方法家族谱系>3.4 蒙特卡罗方法家族谱系<a hidden class=anchor aria-hidden=true href=#34-蒙特卡罗方法家族谱系>#</a></h3><div class=mermaid-wrapper style="background:#fff;padding:2rem 1rem;margin:2rem 0;border-radius:8px;box-shadow:0 2px 12px rgba(0,0,0,8%)"><div class=mermaid>graph TB
MC["蒙特卡罗方法<br>Monte Carlo Methods"] --> Direct["直接蒙特卡罗<br>Direct Monte Carlo"]
MC --> MCMC["马尔可夫链蒙特卡罗<br>MCMC"]
Direct --> MCInt["蒙特卡罗积分"]
Direct --> MCSim["系统模拟"]
Direct --> Quasi["拟蒙特卡罗<br>Quasi-Monte Carlo"]
MCMC --> Metro["Metropolis-Hastings<br>(1953/1970)"]
MCMC --> Gibbs["吉布斯采样<br>Gibbs (1984)"]
MCMC --> HMC["Hamilton Monte Carlo<br>(1994)"]
MCMC --> Slice["切片采样<br>Slice (2003)"]
HMC --> NUTS["NUTS<br>(2011)"]
style MC fill:#007AFF,stroke:#007AFF,stroke-width:3px,color:#ffffff
style Direct fill:#34C759,stroke:#34C759,stroke-width:2px,color:#ffffff
style MCMC fill:#34C759,stroke:#34C759,stroke-width:2px,color:#ffffff
style MCInt fill:#5AC8FA,stroke:#5AC8FA,stroke-width:1px,color:#ffffff
style MCSim fill:#5AC8FA,stroke:#5AC8FA,stroke-width:1px,color:#ffffff
style Quasi fill:#5AC8FA,stroke:#5AC8FA,stroke-width:1px,color:#ffffff
style Metro fill:#AF52DE,stroke:#AF52DE,stroke-width:2px,color:#ffffff
style Gibbs fill:#AF52DE,stroke:#AF52DE,stroke-width:2px,color:#ffffff
style HMC fill:#AF52DE,stroke:#AF52DE,stroke-width:2px,color:#ffffff
style Slice fill:#AF52DE,stroke:#AF52DE,stroke-width:2px,color:#ffffff
style NUTS fill:#AF52DE,stroke:#AF52DE,stroke-width:2px,color:#ffffff</div></div><h2 id=第四章经典应用举例>第四章：经典应用举例<a hidden class=anchor aria-hidden=true href=#第四章经典应用举例>#</a></h2><h3 id=41-计算π值布丰投针的现代实现>4.1 计算π值：布丰投针的现代实现<a hidden class=anchor aria-hidden=true href=#41-计算π值布丰投针的现代实现>#</a></h3><p>让我们用现代蒙特卡罗方法来计算 $\pi$。这里使用一个更直观的方法：在单位正方形内随机投点，计算落在内切圆中的比例。</p><p>$$
\frac{\text{圆内点数}}{\text{总点数}} \approx \frac{\pi \cdot 1^2}{2 \times 2} = \frac{\pi}{4}
$$</p><p>因此：</p><p>$$
\pi \approx 4 \times \frac{\text{圆内点数}}{\text{总点数}}
$$</p><p>算法步骤：</p><ol><li>在 $[-1, 1] \times [-1, 1]$ 的正方形内随机生成 $N$ 个点</li><li>统计满足 $x^2 + y^2 \leq 1$ 的点的数量 $n$</li><li>计算 $\pi \approx 4n/N$</li></ol><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>numpy</span> <span class=k>as</span> <span class=nn>np</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>estimate_pi</span><span class=p>(</span><span class=n>N</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>points</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>uniform</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=n>size</span><span class=o>=</span><span class=p>(</span><span class=n>N</span><span class=p>,</span> <span class=mi>2</span><span class=p>))</span>
</span></span><span class=line><span class=cl>    <span class=n>inside</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>sum</span><span class=p>(</span><span class=n>points</span><span class=p>[:,</span> <span class=mi>0</span><span class=p>]</span><span class=o>**</span><span class=mi>2</span> <span class=o>+</span> <span class=n>points</span><span class=p>[:,</span> <span class=mi>1</span><span class=p>]</span><span class=o>**</span><span class=mi>2</span> <span class=o>&lt;=</span> <span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=mi>4</span> <span class=o>*</span> <span class=n>inside</span> <span class=o>/</span> <span class=n>N</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>N</span> <span class=ow>in</span> <span class=p>[</span><span class=mi>1000</span><span class=p>,</span> <span class=mi>10000</span><span class=p>,</span> <span class=mi>100000</span><span class=p>,</span> <span class=mi>1000000</span><span class=p>]:</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;N = </span><span class=si>{</span><span class=n>N</span><span class=si>:</span><span class=s2>7d</span><span class=si>}</span><span class=s2>, π ≈ </span><span class=si>{</span><span class=n>estimate_pi</span><span class=p>(</span><span class=n>N</span><span class=p>)</span><span class=si>:</span><span class=s2>.6f</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span></code></pre></div><p>随着 $N$ 的增加，估计值会逐渐收敛到 $\pi$ 的真实值。</p><h3 id=42-金融工程期权定价>4.2 金融工程：期权定价<a hidden class=anchor aria-hidden=true href=#42-金融工程期权定价>#</a></h3><p><strong>布莱克-舒尔斯-默顿模型</strong></p><p>1973年，布莱克、舒尔斯和默顿提出了期权定价的解析公式，但这基于许多简化假设。对于更复杂的衍生品（如美式期权、路径依赖期权），蒙特卡罗模拟几乎是唯一可行的方法。</p><p><strong>几何布朗运动模型</strong></p><p>假设股票价格 $S_t$ 服从几何布朗运动：</p><p>$$
dS_t = \mu S_t dt + \sigma S_t dW_t
$$</p><p>其中 $W_t$ 是标准布朗运动。欧式看涨期权的收益是 $\max(S_T - K, 0)$，其中 $K$ 是行权价，$T$ 是到期时间。</p><p>蒙特卡罗定价方法：</p><ol><li>模拟 $N$ 条股票价格路径</li><li>对每条路径计算期权收益</li><li>计算收益的期望值并折现</li></ol><p>离散化后，股票价格的模拟公式为：</p><p>$$
S_{t+\Delta t} = S_t \exp\left[\left(\mu - \frac{\sigma^2}{2}\right)\Delta t + \sigma\sqrt{\Delta t} \cdot Z\right]
$$</p><p>其中 $Z \sim \mathcal{N}(0, 1)$。</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>asian_option_price</span><span class=p>(</span><span class=n>S0</span><span class=p>,</span> <span class=n>K</span><span class=p>,</span> <span class=n>T</span><span class=p>,</span> <span class=n>r</span><span class=p>,</span> <span class=n>sigma</span><span class=p>,</span> <span class=n>N_paths</span><span class=o>=</span><span class=mi>100000</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;亚式期权定价的蒙特卡罗方法&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>dt</span> <span class=o>=</span> <span class=mi>1</span><span class=o>/</span><span class=mi>252</span>  <span class=c1># 每日</span>
</span></span><span class=line><span class=cl>    <span class=n>steps</span> <span class=o>=</span> <span class=nb>int</span><span class=p>(</span><span class=n>T</span> <span class=o>*</span> <span class=mi>252</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>prices</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>zeros</span><span class=p>((</span><span class=n>N_paths</span><span class=p>,</span> <span class=n>steps</span> <span class=o>+</span> <span class=mi>1</span><span class=p>))</span>
</span></span><span class=line><span class=cl>    <span class=n>prices</span><span class=p>[:,</span> <span class=mi>0</span><span class=p>]</span> <span class=o>=</span> <span class=n>S0</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>t</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>steps</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>Z</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>standard_normal</span><span class=p>(</span><span class=n>N_paths</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>prices</span><span class=p>[:,</span> <span class=n>t</span> <span class=o>+</span> <span class=mi>1</span><span class=p>]</span> <span class=o>=</span> <span class=n>prices</span><span class=p>[:,</span> <span class=n>t</span><span class=p>]</span> <span class=o>*</span> <span class=n>np</span><span class=o>.</span><span class=n>exp</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=p>(</span><span class=n>r</span> <span class=o>-</span> <span class=mf>0.5</span> <span class=o>*</span> <span class=n>sigma</span><span class=o>**</span><span class=mi>2</span><span class=p>)</span> <span class=o>*</span> <span class=n>dt</span> <span class=o>+</span> <span class=n>sigma</span> <span class=o>*</span> <span class=n>np</span><span class=o>.</span><span class=n>sqrt</span><span class=p>(</span><span class=n>dt</span><span class=p>)</span> <span class=o>*</span> <span class=n>Z</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 亚式期权：依赖于平均价格</span>
</span></span><span class=line><span class=cl>    <span class=n>avg_prices</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>prices</span><span class=p>[:,</span> <span class=mi>1</span><span class=p>:],</span> <span class=n>axis</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>payoffs</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>maximum</span><span class=p>(</span><span class=n>avg_prices</span> <span class=o>-</span> <span class=n>K</span><span class=p>,</span> <span class=mi>0</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>price</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>exp</span><span class=p>(</span><span class=o>-</span><span class=n>r</span> <span class=o>*</span> <span class=n>T</span><span class=p>)</span> <span class=o>*</span> <span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>payoffs</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>price</span>
</span></span></code></pre></div><h3 id=43-物理模拟粒子输运>4.3 物理模拟：粒子输运<a hidden class=anchor aria-hidden=true href=#43-物理模拟粒子输运>#</a></h3><p>蒙特卡罗方法在核物理中的应用是它的起源。中子在反应堆中的行为可以用以下过程模拟：</p><ol><li><strong>源抽样</strong>：中子从裂变源产生，具有随机的初始位置和方向</li><li><strong>输运</strong>：中子以直线运动，直到碰撞</li><li><strong>碰撞</strong>：<ul><li>被原子核捕获</li><li>散射（改变方向）</li><li>引发裂变（产生新中子）</li></ul></li><li><strong>泄漏或吸收</strong>：中子逃逸系统或被吸收</li></ol><p>每个中子的历史都是一个随机过程，通过模拟大量中子，我们可以估计：</p><ul><li>临界参数（反应堆能否维持链式反应）</li><li>功率分布</li><li>屏蔽效率</li></ul><h3 id=44-机器学习mcmc与贝叶斯推断>4.4 机器学习：MCMC与贝叶斯推断<a hidden class=anchor aria-hidden=true href=#44-机器学习mcmc与贝叶斯推断>#</a></h3><p><strong>贝叶斯推断的核心问题</strong></p><p>在贝叶斯统计中，我们需要计算后验分布：</p><p>$$
p(\theta | D) = \frac{p(D | \theta) p(\theta)}{\int p(D | \theta) p(\theta) d\theta}
$$</p><p>其中分母（证据因子）的积分通常难以计算。MCMC方法让我们可以从后验分布中直接抽样，而不需要计算这个积分。</p><p><strong>应用示例：Logistic回归的贝叶斯推断</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>logistic</span><span class=p>(</span><span class=n>X</span><span class=p>,</span> <span class=n>beta</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=mi>1</span> <span class=o>/</span> <span class=p>(</span><span class=mi>1</span> <span class=o>+</span> <span class=n>np</span><span class=o>.</span><span class=n>exp</span><span class=p>(</span><span class=o>-</span><span class=n>X</span> <span class=o>@</span> <span class=n>beta</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>log_likelihood</span><span class=p>(</span><span class=n>beta</span><span class=p>,</span> <span class=n>X</span><span class=p>,</span> <span class=n>y</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>p</span> <span class=o>=</span> <span class=n>logistic</span><span class=p>(</span><span class=n>X</span><span class=p>,</span> <span class=n>beta</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>np</span><span class=o>.</span><span class=n>sum</span><span class=p>(</span><span class=n>y</span> <span class=o>*</span> <span class=n>np</span><span class=o>.</span><span class=n>log</span><span class=p>(</span><span class=n>p</span><span class=p>)</span> <span class=o>+</span> <span class=p>(</span><span class=mi>1</span> <span class=o>-</span> <span class=n>y</span><span class=p>)</span> <span class=o>*</span> <span class=n>np</span><span class=o>.</span><span class=n>log</span><span class=p>(</span><span class=mi>1</span> <span class=o>-</span> <span class=n>p</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>log_prior</span><span class=p>(</span><span class=n>beta</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>np</span><span class=o>.</span><span class=n>sum</span><span class=p>(</span><span class=o>-</span><span class=mf>0.5</span> <span class=o>*</span> <span class=n>beta</span><span class=o>**</span><span class=mi>2</span><span class=p>)</span>  <span class=c1># 标准正态先验</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>metropolis_hastings</span><span class=p>(</span><span class=n>X</span><span class=p>,</span> <span class=n>y</span><span class=p>,</span> <span class=n>n_samples</span><span class=o>=</span><span class=mi>10000</span><span class=p>,</span> <span class=n>burn_in</span><span class=o>=</span><span class=mi>1000</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>n_features</span> <span class=o>=</span> <span class=n>X</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=mi>1</span><span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=n>beta</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>zeros</span><span class=p>(</span><span class=n>n_features</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>samples</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>n_samples</span> <span class=o>+</span> <span class=n>burn_in</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=c1># 提议新的beta值</span>
</span></span><span class=line><span class=cl>        <span class=n>beta_new</span> <span class=o>=</span> <span class=n>beta</span> <span class=o>+</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>normal</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mf>0.1</span><span class=p>,</span> <span class=n>n_features</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># 计算接受概率</span>
</span></span><span class=line><span class=cl>        <span class=n>log_ratio</span> <span class=o>=</span> <span class=p>(</span><span class=n>log_likelihood</span><span class=p>(</span><span class=n>beta_new</span><span class=p>,</span> <span class=n>X</span><span class=p>,</span> <span class=n>y</span><span class=p>)</span> <span class=o>+</span> <span class=n>log_prior</span><span class=p>(</span><span class=n>beta_new</span><span class=p>)</span> <span class=o>-</span>
</span></span><span class=line><span class=cl>                     <span class=n>log_likelihood</span><span class=p>(</span><span class=n>beta</span><span class=p>,</span> <span class=n>X</span><span class=p>,</span> <span class=n>y</span><span class=p>)</span> <span class=o>-</span> <span class=n>log_prior</span><span class=p>(</span><span class=n>beta</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=n>np</span><span class=o>.</span><span class=n>log</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>uniform</span><span class=p>())</span> <span class=o>&lt;</span> <span class=n>log_ratio</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>beta</span> <span class=o>=</span> <span class=n>beta_new</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=n>i</span> <span class=o>&gt;=</span> <span class=n>burn_in</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>samples</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>beta</span><span class=o>.</span><span class=n>copy</span><span class=p>())</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>(</span><span class=n>samples</span><span class=p>)</span>
</span></span></code></pre></div><p><strong>强化学习中的蒙特卡罗方法</strong></p><p>蒙特卡罗方法在强化学习中也有重要应用。在蒙特卡罗策略评估中，我们通过完整episode的回报来估计状态值：</p><p>$$
V(s) = \mathbb{E}[G_t | S_t = s]
$$</p><p>其中 $G_t = R_{t+1} + \gamma R_{t+2} + \gamma^2 R_{t+3} + \cdots$ 是累积回报。</p><p>通过多次运行episode并计算平均回报，我们可以估计每个状态的价值函数。</p><h3 id=45-其他重要应用>4.5 其他重要应用<a hidden class=anchor aria-hidden=true href=#45-其他重要应用>#</a></h3><p><strong>计算生物学：蛋白质折叠</strong></p><p>蛋白质的三维结构决定了它的功能。预测蛋白质结构需要在巨大的构象空间中搜索，蒙特卡罗方法（特别是Metropolis准则）是核心工具之一。</p><p><strong>计算机图形学：光线追踪</strong></p><p>在渲染真实感图像时，需要计算光线的积分方程。蒙特卡罗光线跟踪通过随机采样光线方向来模拟全局光照效果，产生了电影级的视觉效果。</p><p><strong>运筹学：排队系统模拟</strong></p><p>银行柜台、客服中心、医院急诊室等排队系统的优化，需要模拟顾客到达、服务时间、队列行为等随机过程。蒙特卡罗模拟是评估不同方案的标准工具。</p><h2 id=第五章高级技巧与优化>第五章：高级技巧与优化<a hidden class=anchor aria-hidden=true href=#第五章高级技巧与优化>#</a></h2><p>基础的蒙特卡罗方法虽然强大，但有时收敛速度太慢。下面介绍几种常用的优化技巧。</p><h3 id=51-重要抽样>5.1 重要抽样<a hidden class=anchor aria-hidden=true href=#51-重要抽样>#</a></h3><p>基本思想：如果我们知道函数在某些区域更重要，就应该在这些区域多抽样。</p><p>考虑计算期望：</p><p>$$
\mathbb{E}<em>{p}[f(X)] = \int f(x) p(x) dx = \int \frac{f(x) p(x)}{q(x)} q(x) dx = \mathbb{E}</em>{q}\left[\frac{f(X) p(X)}{q(X)}\right]
$$</p><p>如果我们选择一个与 $|f(x)| p(x)$ 成比例的分布 $q(x)$，方差可以显著减小。</p><h3 id=52-分层抽样>5.2 分层抽样<a hidden class=anchor aria-hidden=true href=#52-分层抽样>#</a></h3><p>将样本空间分成若干层（strata），每层单独抽样：</p><p>$$
\mathbb{E}[f(X)] = \sum_{h=1}^{H} P(h) \cdot \mathbb{E}[f(X) | h]
$$</p><p>其中 $P(h)$ 是落在第 $h$ 层的概率。这样可以保证样本在各层均匀分布。</p><h3 id=53-拟蒙特卡罗方法>5.3 拟蒙特卡罗方法<a hidden class=anchor aria-hidden=true href=#53-拟蒙特卡罗方法>#</a></h3><p>拟蒙特卡罗方法使用<strong>确定性</strong>的低差异序列（如Sobol序列、Halton序列）替代随机序列。这些序列在空间中分布更加均匀，可以加速收敛到 $O(N^{-1} \log^d N)$。</p><h3 id=54-方差缩减技术对比>5.4 方差缩减技术对比<a hidden class=anchor aria-hidden=true href=#54-方差缩减技术对比>#</a></h3><div class=mermaid-wrapper style="background:#fff;padding:2rem 1rem;margin:2rem 0;border-radius:8px;box-shadow:0 2px 12px rgba(0,0,0,8%)"><div class=mermaid>graph LR
Base["基础蒙特卡罗<br>误差: O(N^(-1/2))"] --> IS["重要抽样<br>选择最优抽样分布"]
Base --> SS["分层抽样<br>空间分区均匀抽样"]
Base --> AV["对偶变量<br>利用负相关性"]
Base --> CV["控制变量<br>利用相关变量"]
Base --> QMC["拟蒙特卡罗<br>误差: O(N^(-1) log^d N)"]
IS --> Result1["大幅降低方差<br>但需要领域知识"]
SS --> Result2["均匀覆盖空间<br>适合规则区域"]
AV --> Result3["简单有效<br>利用对称性"]
CV --> Result4["显著降低方差<br>需要找到好的控制变量"]
QMC --> Result5["超线性收敛<br>低维问题特别有效"]
style Base fill:#007AFF,stroke:#007AFF,stroke-width:3px,color:#ffffff
style IS fill:#34C759,stroke:#34C759,stroke-width:2px,color:#ffffff
style SS fill:#34C759,stroke:#34C759,stroke-width:2px,color:#ffffff
style AV fill:#34C759,stroke:#34C759,stroke-width:2px,color:#ffffff
style CV fill:#34C759,stroke:#34C759,stroke-width:2px,color:#ffffff
style QMC fill:#AF52DE,stroke:#AF52DE,stroke-width:2px,color:#ffffff
style Result1 fill:#5AC8FA,stroke:#5AC8FA,stroke-width:1px,color:#ffffff
style Result2 fill:#5AC8FA,stroke:#5AC8FA,stroke-width:1px,color:#ffffff
style Result3 fill:#5AC8FA,stroke:#5AC8FA,stroke-width:1px,color:#ffffff
style Result4 fill:#5AC8FA,stroke:#5AC8FA,stroke-width:1px,color:#ffffff
style Result5 fill:#FF9500,stroke:#FF9500,stroke-width:2px,color:#ffffff</div></div><h2 id=第六章蒙特卡罗方法在人工智能中的应用>第六章：蒙特卡罗方法在人工智能中的应用<a hidden class=anchor aria-hidden=true href=#第六章蒙特卡罗方法在人工智能中的应用>#</a></h2><h3 id=61-蒙特卡罗树搜索mcts>6.1 蒙特卡罗树搜索（MCTS）<a hidden class=anchor aria-hidden=true href=#61-蒙特卡罗树搜索mcts>#</a></h3><p>2006年提出的蒙特卡罗树搜索彻底改变了计算机博弈。AlphaGo的核心就是深度学习与MCTS的结合。</p><p>MCTS有四个步骤：</p><div class=mermaid-wrapper style="background:#fff;padding:2rem 1rem;margin:2rem 0;border-radius:8px;box-shadow:0 2px 12px rgba(0,0,0,8%)"><div class=mermaid>flowchart TD
subgraph Selection["选择 Selection"]
S1["从根节点开始"] --> S2["根据UCB1公式选择子节点"]
S2 --> S3{"到达叶子节点?"}
S3 -->|否| S2
end
Selection --> Expansion["扩展 Expansion<br>添加一个新节点"]
Expansion --> Simulation["模拟 Simulation<br>随机对弈至终局"]
Simulation --> Backprop["回溯 Backpropagation<br>更新路径上所有节点的统计"]
style S1 fill:#34C759,stroke:#34C759,stroke-width:2px,color:#ffffff
style S2 fill:#34C759,stroke:#34C759,stroke-width:2px,color:#ffffff
style S3 fill:#FF9500,stroke:#FF9500,stroke-width:2px,color:#ffffff
style Selection fill:#8E8E93,stroke:#8E8E93,stroke-width:1px,color:#ffffff
style Expansion fill:#007AFF,stroke:#007AFF,stroke-width:3px,color:#ffffff
style Simulation fill:#007AFF,stroke:#007AFF,stroke-width:3px,color:#ffffff
style Backprop fill:#007AFF,stroke:#007AFF,stroke-width:3px,color:#ffffff</div></div><p><strong>UCB1公式</strong>（Upper Confidence Bound）：</p><p>$$
\text{UCB1}(i) = \frac{W_i}{N_i} + c \sqrt{\frac{\ln N}{N_i}}
$$</p><p>其中 $W_i$ 是节点 $i$ 的胜率，$N_i$ 是访问次数，$N$ 是父节点访问次数，$c$ 是探索参数。</p><p>这个公式平衡了<strong>利用</strong>（exploitation，选择胜率高的节点）和<strong>探索</strong>（exploration，选择访问少的节点）。</p><h3 id=62-变分推断与mcmc的比较>6.2 变分推断与MCMC的比较<a hidden class=anchor aria-hidden=true href=#62-变分推断与mcmc的比较>#</a></h3><p>在现代贝叶斯机器学习中，有两种主要的推断方法：</p><table><thead><tr><th>特性</th><th>MCMC</th><th>变分推断</th></tr></thead><tbody><tr><td>精度</td><td>渐近精确</td><td>近似</td></tr><tr><td>速度</td><td>慢</td><td>快</td></tr><tr><td>可扩展性</td><td>有限</td><td>强</td></tr><tr><td>适用场景</td><td>小数据，精确性要求高</td><td>大数据，实时应用</td></tr></tbody></table><p>随着计算资源的增加，MCMC方法在机器学习中的应用正在复兴。</p><h3 id=63-强化学习中的蒙特卡罗方法>6.3 强化学习中的蒙特卡罗方法<a hidden class=anchor aria-hidden=true href=#63-强化学习中的蒙特卡罗方法>#</a></h3><p><strong>蒙特卡罗策略梯度</strong></p><p>REINFORCE算法是策略梯度方法的基础：</p><p>$$
\nabla J(\theta) = \mathbb{E}<em>{\pi</em>\theta}\left[\frac{\nabla \pi_\theta(a|s)}{\pi_\theta(a|s)} G_t\right]
$$</p><p>使用蒙特卡罗回报 $G_t$ 作为梯度估计：</p><p>$$
\hat{g} = \sum_{t=0}^{T} \nabla \ln \pi_\theta(A_t|S_t) G_t
$$</p><p>这个简单的估计虽然方差大，但它是无偏的，是现代强化学习算法的基石。</p><h3 id=64-深度学习中的随机性>6.4 深度学习中的随机性<a hidden class=anchor aria-hidden=true href=#64-深度学习中的随机性>#</a></h3><p>现代深度学习充满了蒙特卡罗思想：</p><ul><li><strong>随机梯度下降</strong>：每次迭代随机选择一个小批量的数据</li><li><strong>Dropout</strong>：训练时随机丢弃神经元，可视为模型平均的蒙特卡罗近似</li><li><strong>Batch Normalization</strong>：使用小批量的统计量作为总体统计量的估计</li></ul><h2 id=结语随机性作为工具>结语：随机性作为工具<a hidden class=anchor aria-hidden=true href=#结语随机性作为工具>#</a></h2><p>从曼哈顿计划保密代号到无处不在的计算工具，蒙特卡罗方法走过了八十年的历程。它的核心思想——用随机性来求解确定性问题——看似简单，却蕴含着深刻的数学原理。</p><p>当我们回望这段历史，可以看到一些有趣的脉络：</p><ol><li><strong>问题的驱动</strong>：蒙特卡罗方法诞生于核物理的具体需求，而非纯粹的数学探索</li><li><strong>技术的协同</strong>：它与计算机的发展相互促进，互为因果</li><li><strong>思想的普适性</strong>：从金融到生物学，从图形学到人工智能，它的应用跨越了几乎所有的科学领域</li></ol><p>蒙特卡罗方法告诉我们：<strong>确定性的问题可以借助随机性来求解</strong>。这不仅是数学上的技巧，更是一种深刻的思维方式的转变——在混沌中寻找秩序，在随机中发现规律。</p><p>随着量子计算的发展，我们或许正站在新的蒙特卡罗革命的门槛上。量子随机性可能为蒙特卡罗方法带来新的维度，就像当年电子计算机让它从理论变为现实一样。</p><p>正如乌拉姆所说：</p><blockquote><p>&ldquo;使用随机数来解决数学问题的想法，就像用骰子来决定晚餐吃什么一样荒谬——直到你意识到，这或许是唯一可行的方法。&rdquo;</p></blockquote><p>在这个充满不确定性的世界里，蒙特卡罗方法给了我们一把钥匙，让随机性成为我们探索未知的工具，而不是障碍。</p><hr><p><strong>参考文献</strong></p><ol><li><p>Metropolis, N., & Ulam, S. (1949). The Monte Carlo Method. <em>Journal of the American Statistical Association</em>, 44(247), 335-341.</p></li><li><p>Hastings, W.K. (1970). Monte Carlo Sampling Methods Using Markov Chains and Their Applications. <em>Biometrika</em>, 57(1), 97-109.</p></li><li><p>Geman, S., & Geman, D. (1984). Stochastic Relaxation, Gibbs Distributions, and the Bayesian Restoration of Images. <em>IEEE Transactions on Pattern Analysis and Machine Intelligence</em>, 6(6), 721-741.</p></li><li><p>Silver, D., et al. (2016). Mastering the Game of Go with Deep Neural Networks and Tree Search. <em>Nature</em>, 529, 484-489.</p></li><li><p>Neal, R.M. (2011). MCMC Using Hamiltonian Dynamics. In <em>Handbook of Markov Chain Monte Carlo</em> (pp. 113-162). Chapman and Hall/CRC.</p></li></ol></div><footer class=post-footer><ul class=post-tags><li><a href=https://s-ai-unix.github.io/tags/%E7%BB%BC%E8%BF%B0/>综述</a></li><li><a href=https://s-ai-unix.github.io/tags/%E7%AE%97%E6%B3%95/>算法</a></li><li><a href=https://s-ai-unix.github.io/tags/%E6%A6%82%E7%8E%87%E8%AE%BA/>概率论</a></li><li><a href=https://s-ai-unix.github.io/tags/%E6%95%B0%E5%80%BC%E8%AE%A1%E7%AE%97/>数值计算</a></li></ul><nav class=paginav><a class=prev href=https://s-ai-unix.github.io/posts/2026-01-22-ricci-flow-comprehensive-review/><span class=title>« Prev</span><br><span>Ricci Flow - A Comprehensive Review</span>
</a><a class=next href=https://s-ai-unix.github.io/posts/2026-01-21-transformer/><span class=title>Next »</span><br><span>Transformer：重塑AI世界的架构革命</span></a></nav><ul class=share-buttons><li><a target=_blank rel="noopener noreferrer" aria-label="share 蒙特卡罗算法：从原子弹到人工智能的随机之旅 on x" href="https://x.com/intent/tweet/?text=%e8%92%99%e7%89%b9%e5%8d%a1%e7%bd%97%e7%ae%97%e6%b3%95%ef%bc%9a%e4%bb%8e%e5%8e%9f%e5%ad%90%e5%bc%b9%e5%88%b0%e4%ba%ba%e5%b7%a5%e6%99%ba%e8%83%bd%e7%9a%84%e9%9a%8f%e6%9c%ba%e4%b9%8b%e6%97%85&amp;url=https%3a%2f%2fs-ai-unix.github.io%2fposts%2f2026-01-21-monte-carlo-method%2f&amp;hashtags=%e7%bb%bc%e8%bf%b0%2c%e7%ae%97%e6%b3%95%2c%e6%a6%82%e7%8e%87%e8%ae%ba%2c%e6%95%b0%e5%80%bc%e8%ae%a1%e7%ae%97"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446C483.971.0 512 28.03 512 62.554zM269.951 190.75 182.567 75.216H56L207.216 272.95 63.9 436.783h61.366L235.9 310.383l96.667 126.4H456L298.367 228.367l134-153.151H371.033zM127.633 110h36.468l219.38 290.065H349.5z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share 蒙特卡罗算法：从原子弹到人工智能的随机之旅 on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fs-ai-unix.github.io%2fposts%2f2026-01-21-monte-carlo-method%2f&amp;title=%e8%92%99%e7%89%b9%e5%8d%a1%e7%bd%97%e7%ae%97%e6%b3%95%ef%bc%9a%e4%bb%8e%e5%8e%9f%e5%ad%90%e5%bc%b9%e5%88%b0%e4%ba%ba%e5%b7%a5%e6%99%ba%e8%83%bd%e7%9a%84%e9%9a%8f%e6%9c%ba%e4%b9%8b%e6%97%85&amp;summary=%e8%92%99%e7%89%b9%e5%8d%a1%e7%bd%97%e7%ae%97%e6%b3%95%ef%bc%9a%e4%bb%8e%e5%8e%9f%e5%ad%90%e5%bc%b9%e5%88%b0%e4%ba%ba%e5%b7%a5%e6%99%ba%e8%83%bd%e7%9a%84%e9%9a%8f%e6%9c%ba%e4%b9%8b%e6%97%85&amp;source=https%3a%2f%2fs-ai-unix.github.io%2fposts%2f2026-01-21-monte-carlo-method%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share 蒙特卡罗算法：从原子弹到人工智能的随机之旅 on reddit" href="https://reddit.com/submit?url=https%3a%2f%2fs-ai-unix.github.io%2fposts%2f2026-01-21-monte-carlo-method%2f&title=%e8%92%99%e7%89%b9%e5%8d%a1%e7%bd%97%e7%ae%97%e6%b3%95%ef%bc%9a%e4%bb%8e%e5%8e%9f%e5%ad%90%e5%bc%b9%e5%88%b0%e4%ba%ba%e5%b7%a5%e6%99%ba%e8%83%bd%e7%9a%84%e9%9a%8f%e6%9c%ba%e4%b9%8b%e6%97%85"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share 蒙特卡罗算法：从原子弹到人工智能的随机之旅 on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fs-ai-unix.github.io%2fposts%2f2026-01-21-monte-carlo-method%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a></li></ul></footer><script src=https://giscus.app/client.js data-repo=s-ai-unix/blog data-repo-id=R_kgDOQ3Njaw data-category=General data-category-id=DIC_kwDOQ3Nja84C0yve data-mapping=pathname data-strict=0 data-reactions-enabled=1 data-emit-metadata=0 data-input-position=bottom data-theme=preferred_color_scheme data-lang=zh-CN data-loading=lazy crossorigin=anonymous async></script></article></main><footer class=footer><span>&copy; 2026 <a href=https://s-ai-unix.github.io/>s-ai-unix's Blog</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
<a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script>(function(){"use strict";function e(){var e=document.querySelectorAll("p, li, td, div, span, h1, h2, h3, h4, h5, h6, ol, ul");e.forEach(function(e){if(e.classList.contains("classical-quote-container")||e.classList.contains("quote-text")||e.closest(".classical-quote-container"))return;var n,t=e.innerHTML,s=!1;for(t.indexOf("<em>")!==-1&&(n=t.replace(/\$([^$]*?)<em>([^<]+?)<\/em>([^$]*?)\$/g,function(e,t,n,s){return/^[\d.,]+$/.test((t+n+s).replace(/[.,]/g,""))?e:"$"+t+"_"+n+s+"$"}),n=n.replace(/\$\$([^$]*?)<em>([^<]+?)<\/em>([^$]*?)\$\$/g,function(e,t,n,s){return"$$"+t+"_"+n+s+"$$"}),n!==t&&(t=n,s=!0)),t.indexOf("</em>")!==-1&&(n=t.replace(/\$([^$]*?)<\/em>([^$]*?)\$/g,function(e,t,n){return"$"+t+"_{"+n+"$"}),n=n.replace(/\$\$([^$]*?)<\/em>([^$]*?)\$\$/g,function(e,t,n){return"$$"+t+"_{"+n+"$$"}),n!==t&&(t=n,s=!0)),t.indexOf("<em>$")!==-1&&(n=t.replace(/<em>\$/g,"$"),n!==t&&(t=n,s=!0)),t.indexOf("</em>$")!==-1&&(n=t.replace(/<\/em>\$/g,"$"),n!==t&&(t=n,s=!0));t.indexOf("<em>")!==-1&&t.indexOf("</em>")!==-1;){if(n=t.replace(/\$([^$]*?)<em>([^<]+?)<\/em>([^$]*?)\$/g,function(e,t,n,s){return/^[\d.,]+$/.test((t+n+s).replace(/[.,]/g,""))?e:"$"+t+"_"+n+s+"$"}),n=n.replace(/\$\$([^$]*?)<em>([^<]+?)<\/em>([^$]*?)\$\$/g,function(e,t,n,s){return"$$"+t+"_"+n+s+"$$"}),n===t)break;t=n,s=!0}t.indexOf("_{")!==-1&&(n=t.replace(/_{/g,"_{"),n!==t&&(t=n,s=!0)),t.indexOf("}_")!==-1&&(n=t.replace(/}_/g,"}"),n!==t&&(t=n,s=!0)),t.indexOf("\\\\")!==-1&&(n=t.replace(/(\$\{1,2\})([^$]*?)(\$\{1,2\})/g,function(e,t,n,s){for(;n.indexOf("\\\\")!==-1;)n=n.replace(/\\\\/g,"\\");return t+n+s}),n!==t&&(t=n,s=!0)),s&&(e.innerHTML=t)})}window.MathJax={tex:{inlineMath:[["$","$"]],displayMath:[["$$","$$"]],processEscapes:!0,processEnvironments:!0,tags:"ams",macros:{oiint:"\\mathop{∯}",oiiint:"\\mathop{∰}"}},options:{skipHtmlTags:["script","noscript","style","textarea","pre","code"]},startup:{pageReady:function(){return e(),MathJax.startup.defaultPageReady().then(function(){console.log("MathJax formulas rendered successfully")})}}}})()</script><script src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script><link rel=stylesheet href=/css/mermaid-custom.css><script src=/js/mermaid-converter.js></script><script type=module>
  import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs';

  
  setTimeout(() => {
    mermaid.initialize({
      startOnLoad: true,
      theme: 'base',
      themeVariables: {
        primaryColor: '#e3f2fd',
        primaryTextColor: '#1565c0',
        primaryBorderColor: '#2196f3',
        lineColor: '#42a5f5',
        secondaryColor: '#f3e5f5',
        tertiaryColor: '#fff9c4',
        background: '#ffffff',
        mainBkg: '#ffffff',
        nodeBorder: '#2196f3',
        clusterBkg: '#ffffff',
        clusterBorder: '#e0e0e0',
        titleColor: '#1565c0',
        edgeLabelBackground: '#fafafa',
      },
      securityLevel: 'loose',
    });
  }, 100);
</script><script src=/js/toc.js></script><script>let menu=document.getElementById("menu");if(menu){const e=localStorage.getItem("menu-scroll-position");e&&(menu.scrollLeft=parseInt(e,10)),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}}document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{const e=document.querySelector("html");e.dataset.theme==="dark"?(e.dataset.theme="light",localStorage.setItem("pref-theme","light")):(e.dataset.theme="dark",localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script><script>(function(){"use strict";function e(){var e=document.querySelectorAll("p, li, td, div, span, h1, h2, h3, h4, h5, h6, ol, ul");e.forEach(function(e){if(e.classList.contains("classical-quote-container")||e.classList.contains("quote-text")||e.closest(".classical-quote-container"))return;var n,t=e.innerHTML,s=!1;for(t.indexOf("<em>")!==-1&&(n=t.replace(/\$([^$]*?)<em>([^<]+?)<\/em>([^$]*?)\$/g,function(e,t,n,s){return/^[\d.,]+$/.test((t+n+s).replace(/[.,]/g,""))?e:"$"+t+"_"+n+s+"$"}),n=n.replace(/\$\$([^$]*?)<em>([^<]+?)<\/em>([^$]*?)\$\$/g,function(e,t,n,s){return"$$"+t+"_"+n+s+"$$"}),n!==t&&(t=n,s=!0)),t.indexOf("</em>")!==-1&&(n=t.replace(/\$([^$]*?)<\/em>([^$]*?)\$/g,function(e,t,n){return"$"+t+"_{"+n+"$"}),n=n.replace(/\$\$([^$]*?)<\/em>([^$]*?)\$\$/g,function(e,t,n){return"$$"+t+"_{"+n+"$$"}),n!==t&&(t=n,s=!0)),t.indexOf("<em>$")!==-1&&(n=t.replace(/<em>\$/g,"$"),n!==t&&(t=n,s=!0)),t.indexOf("</em>$")!==-1&&(n=t.replace(/<\/em>\$/g,"$"),n!==t&&(t=n,s=!0));t.indexOf("<em>")!==-1&&t.indexOf("</em>")!==-1;){if(n=t.replace(/\$([^$]*?)<em>([^<]+?)<\/em>([^$]*?)\$/g,function(e,t,n,s){return/^[\d.,]+$/.test((t+n+s).replace(/[.,]/g,""))?e:"$"+t+"_"+n+s+"$"}),n=n.replace(/\$\$([^$]*?)<em>([^<]+?)<\/em>([^$]*?)\$\$/g,function(e,t,n,s){return"$$"+t+"_"+n+s+"$$"}),n===t)break;t=n,s=!0}t.indexOf("_{")!==-1&&(n=t.replace(/_{/g,"_{"),n!==t&&(t=n,s=!0)),t.indexOf("}_")!==-1&&(n=t.replace(/}_/g,"}"),n!==t&&(t=n,s=!0)),t.indexOf("\\\\")!==-1&&(n=t.replace(/(\$\{1,2\})([^$]*?)(\$\{1,2\})/g,function(e,t,n,s){for(;n.indexOf("\\\\")!==-1;)n=n.replace(/\\\\/g,"\\");return t+n+s}),n!==t&&(t=n,s=!0)),s&&(e.innerHTML=t)})}window.MathJax={tex:{inlineMath:[["$","$"]],displayMath:[["$$","$$"]],processEscapes:!0,processEnvironments:!0,tags:"ams",macros:{oiint:"\\mathop{∯}",oiiint:"\\mathop{∰}"}},options:{skipHtmlTags:["script","noscript","style","textarea","pre","code"]},startup:{pageReady:function(){return e(),MathJax.startup.defaultPageReady().then(function(){console.log("MathJax formulas rendered successfully")})}}}})()</script><script src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script><link rel=stylesheet href=/css/mermaid-custom.css><script src=/js/mermaid-converter.js></script><script type=module>
  import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs';

  
  setTimeout(() => {
    mermaid.initialize({
      startOnLoad: true,
      theme: 'base',
      themeVariables: {
        primaryColor: '#e3f2fd',
        primaryTextColor: '#1565c0',
        primaryBorderColor: '#2196f3',
        lineColor: '#42a5f5',
        secondaryColor: '#f3e5f5',
        tertiaryColor: '#fff9c4',
        background: '#ffffff',
        mainBkg: '#ffffff',
        nodeBorder: '#2196f3',
        clusterBkg: '#ffffff',
        clusterBorder: '#e0e0e0',
        titleColor: '#1565c0',
        edgeLabelBackground: '#fafafa',
      },
      securityLevel: 'loose',
    });
  }, 100);
</script><script src=/js/toc.js></script></body></html>
<!doctype html><html lang=en dir=auto data-theme=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Posts | s-ai-unix's Blog</title><meta name=keywords content><meta name=description content="Posts - s-ai-unix's Blog"><meta name=author content="s-ai-unix"><link rel=canonical href=https://s-ai-unix.github.io/posts/><link crossorigin=anonymous href=/assets/css/stylesheet.0833aff7e1cf567ecfb9755701ee95a80535f671e2e1a0a770c9bc20a0a7b5bb.css integrity="sha256-CDOv9+HPVn7PuXVXAe6VqAU19nHi4aCncMm8IKCntbs=" rel="preload stylesheet" as=style><link rel=icon href=https://s-ai-unix.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://s-ai-unix.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://s-ai-unix.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://s-ai-unix.github.io/apple-touch-icon.png><link rel=mask-icon href=https://s-ai-unix.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate type=application/rss+xml href=https://s-ai-unix.github.io/posts/index.xml title=rss><link rel=alternate hreflang=en href=https://s-ai-unix.github.io/posts/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51);color-scheme:dark}.list{background:var(--theme)}.toc{background:var(--entry)}}@media(prefers-color-scheme:light){.list::-webkit-scrollbar-thumb{border-color:var(--code-bg)}}</style></noscript><script>localStorage.getItem("pref-theme")==="dark"?document.querySelector("html").dataset.theme="dark":localStorage.getItem("pref-theme")==="light"?document.querySelector("html").dataset.theme="light":window.matchMedia("(prefers-color-scheme: dark)").matches?document.querySelector("html").dataset.theme="dark":document.querySelector("html").dataset.theme="light"</script><meta property="og:url" content="https://s-ai-unix.github.io/posts/"><meta property="og:site_name" content="s-ai-unix's Blog"><meta property="og:title" content="Posts"><meta property="og:description" content="s-ai-unix 的个人技术博客，分享数学、AI、产品设计、数据科学、智能汽车(设计、研发、质量、合规)、历史等领域的知识和思考"><meta property="og:locale" content="zh-cn"><meta property="og:type" content="website"><meta name=twitter:card content="summary"><meta name=twitter:title content="Posts"><meta name=twitter:description content="s-ai-unix 的个人技术博客，分享数学、AI、产品设计、数据科学、智能汽车(设计、研发、质量、合规)、历史等领域的知识和思考"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://s-ai-unix.github.io/posts/"}]}</script><link rel=stylesheet href=https://s-ai-unix.github.io/css/classical-quote.css></head><body class=list id=top><header class=header><nav class=nav><div class=logo><a href=https://s-ai-unix.github.io/ accesskey=h title="s-ai-unix's Blog (Alt + H)">s-ai-unix's Blog</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://s-ai-unix.github.io/ title="🏠 首页"><span>🏠 首页</span></a></li><li><a href=https://s-ai-unix.github.io/posts/ title="📚 文章"><span class=active>📚 文章</span></a></li><li><a href=https://s-ai-unix.github.io/archives/ title="📁 归档"><span>📁 归档</span></a></li><li><a href=https://s-ai-unix.github.io/tags/ title="🏷️ 标签"><span>🏷️ 标签</span></a></li><li><a href=https://s-ai-unix.github.io/search/ title="🔍 搜索 (Alt + /)" accesskey=/><span>🔍 搜索</span></a></li><li><a href=https://s-ai-unix.github.io/about/ title="👤 关于"><span>👤 关于</span></a></li></ul></nav></header><main class=main><header class=page-header><div class=breadcrumbs><a href=https://s-ai-unix.github.io/>Home</a></div><h1>Posts</h1></header><article class=post-entry><figure class=entry-cover><img loading=lazy src=https://s-ai-unix.github.io/images/covers/wisconsin-geese-4602386.jpg alt=抽象的几何图案></figure><header class=entry-header><h2 class=entry-hint-parent>梯度、梯度下降与反向传播：从最优化到深度学习的数学引擎</h2></header><div class=entry-content><p>引言：从山路说起 想象你是一名登山者，被困在浓雾笼罩的山坡上，四周一片白茫茫。你手里只有一个指南针，它指向的似乎是你所在位置海拔下降最快的方向。这是你最希望知道的：该往哪个方向迈出第一步，才能尽快走出这座山？
这就是梯度下降算法最直观的物理类比。你所在的位置，是一个函数在某点的值；你想要的，是找到函数的最小值（山谷的最低点）；而那个指南针，就是梯度——告诉你哪个方向上升最快的向量。
这个看似简单的思想，却成为了现代人工智能的数学引擎。从AlphaGo击败李世石，到ChatGPT生成流畅的文字，再到自动驾驶汽车的感知系统，背后都依赖着梯度、梯度下降和反向传播这三个核心概念的精密协作。
但在深入这些概念之前，我们需要先理解一个更基础的数学对象：梯度。
梯度：地形的最陡方向 历史背景：从Hamilton到向量微积分 梯度的概念并非一蹴而就。它的起源可以追溯到19世纪中叶，那个数学物理大爆发的时代。
1843年，爱尔兰数学家William Rowan Hamilton（哈密顿）在研究四元数时，引入了一个算子符号$\nabla$，他称之为"nabla"（源自希腊语，意为一种竖琴）。这个倒三角符号后来成为了梯度、散度和旋度的统一表示。
1850年代，苏格兰数学家James Clerk Maxwell（麦克斯韦）进一步发展了向量微积分理论，他将$\nabla$算子应用于不同的运算：$\nabla \phi$表示梯度，$\nabla \cdot \mathbf{F}$表示散度，$\nabla \times \mathbf{F}$表示旋度。这三大运算构成了现代电磁学理论的数学语言。
更早之前，法国数学家Augustin-Louis Cauchy（柯西）在1847年就提出了梯度下降算法的雏形，这是最古老的优化算法之一。
数学定义：偏导数的向量 给定一个多元标量函数 $f: \mathbb{R}^n \rightarrow \mathbb{R}$，它的梯度 $\nabla f$（读作"del f"或"grad f"）定义为：
$$ \nabla f = \left(\frac{\partial f}{\partial x_1}, \frac{\partial f}{\partial x_2}, \ldots, \frac{\partial f}{\partial x_n}\right)^T $$
这是一个向量，每个分量是函数对相应变量的偏导数。
具体计算示例 考虑一个简单的二次函数：$f(x, y) = x^2 + 2y^2 - 4x - 8y + 17$
计算梯度：
$$ \frac{\partial f}{\partial x} = 2x - 4, \quad \frac{\partial f}{\partial y} = 4y - 8 $$
...</p></div><footer class=entry-footer><span title='2026-01-14 08:34:44 +0800 CST'>January 14, 2026</span>&nbsp;·&nbsp;<span>10 min</span>&nbsp;·&nbsp;<span>2040 words</span>&nbsp;·&nbsp;<span>s-ai-unix</span></footer><a class=entry-link aria-label="post link to 梯度、梯度下降与反向传播：从最优化到深度学习的数学引擎" href=https://s-ai-unix.github.io/posts/2026-01-14-gradient-descent-backpropagation-overview/></a></article><article class=post-entry><figure class=entry-cover><img loading=lazy src=https://s-ai-unix.github.io/images/covers/photo-1620712943543-bcc4688e7485.jpg alt=神经网络连接></figure><header class=entry-header><h2 class=entry-hint-parent>基于神经网络的深度学习算法：从感知机到Transformer的完整指南</h2></header><div class=entry-content><p>引言：从生物启发到智能革命 1943年，Warren McCulloch和Walter Pitts提出了第一个神经元数学模型。他们用一个简单的数学公式模拟了生物神经元的工作方式：接收输入、加权求和、激活输出。这个看似简单的想法，却孕育了后来改变世界的人工智能技术。
1958年，Frank Rosenblatt发明了感知机（Perceptron），这是第一个可以学习的神经网络。但1969年，Minsky和Papert在《Perceptrons》一书中证明了单层感知机无法解决异或（XOR）问题，这个致命缺陷导致了神经网络研究的第一次寒冬。
1986年，David Rumelhart、Geoffrey Hinton和Ronald Williams重新发现了反向传播算法，解决了多层网络的训练问题。神经网络迎来了短暂的春天。
但在90年代到2000年代初，支持向量机（SVM）等传统机器学习算法统治了学术界。神经网络因为数据量不足、计算能力有限、缺乏有效的训练技巧，再次陷入沉寂。
2012年，ImageNet竞赛上，Hinton的学生Alex Krizhevsky使用深度卷积神经网络AlexNet，以压倒性优势击败了传统方法，分类错误率从26%降低到15.3%。这一年，深度学习时代正式开启。
从此，深度学习以惊人的速度发展：2014年的VGG、GoogLeNet，2015年的ResNet解决深度退化问题，2017年的Transformer彻底改变自然语言处理，2022年的ChatGPT让全世界见识到大模型的力量。
本文将从数学原理出发，系统讲解深度学习的核心算法：从基础神经网络到卷积神经网络（CNN），从循环神经网络（RNN）到Transformer，最后探讨未来发展趋势。
第一章：神经网络的数学基础 1.1 单神经元：感知机的数学模型 1.1.1 前向传播 感知机是最基础的神经网络单元，模拟生物神经元的工作原理。给定输入向量 $x \in \mathbb{R}^d$，权重向量 $w \in \mathbb{R}^d$，偏置 $b \in \mathbb{R}$：
$$z = w^Tx + b = \sum_{i=1}^d w_i x_i + b$$
激活函数 $\sigma(z)$ 决定神经元的输出：
$$a = \sigma(z)$$
1.1.2 常用激活函数 Sigmoid函数： $$\sigma(z) = \frac{1}{1 + e^{-z}}$$
导数： $$\sigma’(z) = \sigma(z)(1 - \sigma(z))$$
性质：
输出范围：$(0, 1)$ S型曲线，可微 缺点：梯度消失（$| \sigma’(z) | \leq 0.25$），输出不以零为中心 Tanh函数： $$\tanh(z) = \frac{e^z - e^{-z}}{e^z + e^{-z}}$$
...</p></div><footer class=entry-footer><span title='2026-01-14 08:30:00 +0800 CST'>January 14, 2026</span>&nbsp;·&nbsp;<span>11 min</span>&nbsp;·&nbsp;<span>2188 words</span>&nbsp;·&nbsp;<span>s-ai-unix</span></footer><a class=entry-link aria-label="post link to 基于神经网络的深度学习算法：从感知机到Transformer的完整指南" href=https://s-ai-unix.github.io/posts/2026-01-14-deep-learning-algorithms-comprehensive-guide/></a></article><article class=post-entry><figure class=entry-cover><img loading=lazy src=https://s-ai-unix.github.io/images/covers/rl-network.jpg alt=神经网络连接示意图></figure><header class=entry-header><h2 class=entry-hint-parent>强化学习：从试错到智能的数学之旅</h2></header><div class=entry-content><p>引言：试错的智慧 想象一下，你第一次玩《超级马里奥》这款游戏。屏幕上的小人在管道和蘑菇之间跳跃，你必须不断尝试：有时候跳得太早撞到了蘑菇，有时候跳得太晚掉进了坑里。但随着尝试次数的增多，你逐渐掌握了时机——你知道什么时候该加速，什么时候该按跳跃键。
这种通过试错来学习的过程，就是强化学习（Reinforcement Learning, RL）的核心思想。不同于监督学习从标注好的数据中学习，强化学习通过与环境的交互来获取反馈，并逐渐优化自己的行为策略。
从数学的角度看，强化学习可以被视为一个优化问题：智能体（Agent）需要在环境中选择动作（Action），以最大化累积奖励（Reward）。这个过程可以用概率论和微积分的语言来精确描述。
本文将带你踏上这段数学之旅，从马尔可夫决策过程（MDP）的基础框架出发，逐步推导经典的Q-learning、Policy Gradient和Actor-Critic算法，最后探讨强化学习的应用场景和未来前景。
第一章：强化学习的基本框架 1.1 核心概念 在正式进入数学推导之前，让我们先建立一个直观的图像。想象一只老鼠在迷宫中寻找奶酪：
智能体（Agent）：这只老鼠 环境（Environment）：迷宫 状态（State）：老鼠在迷宫中的位置 动作（Action）：老鼠可以向前后左右移动 奖励（Reward）：找到奶酪+10分，撞墙-1分，每走一步-0.1分（鼓励快速找到） 智能体的目标是学习一个策略（Policy），即在不同状态下选择最优的动作，以最大化长期累积奖励。
1.2 数学表示 现在让我们用数学语言来描述这个框架。一个强化学习问题通常由以下元组表示：
$$ (S, A, P, R, \gamma) $$
其中：
$S$：状态空间（State Space） $A$：动作空间（Action Space） $P$：状态转移概率（Transition Probability） $R$：奖励函数（Reward Function） $\gamma$：折扣因子（Discount Factor），$\gamma \in [0,1]$ 状态转移概率 $P(s’|s,a)$ 表示在状态 $s$ 执行动作 $a$ 后，转移到状态 $s’$ 的概率：
$$ P(s’|s,a) = \mathbb{P}[S_{t+1} = s’ | S_t = s, A_t = a] $$
奖励函数 $R(s,a)$ 可以定义为：
$$ R(s,a) = \mathbb{E}[R_{t+1} | S_t = s, A_t = a] $$
...</p></div><footer class=entry-footer><span title='2026-01-14 08:30:00 +0800 CST'>January 14, 2026</span>&nbsp;·&nbsp;<span>7 min</span>&nbsp;·&nbsp;<span>1291 words</span>&nbsp;·&nbsp;<span>s-ai-unix</span></footer><a class=entry-link aria-label="post link to 强化学习：从试错到智能的数学之旅" href=https://s-ai-unix.github.io/posts/2026-01-14-reinforcement-learning-comprehensive-guide/></a></article><article class=post-entry><figure class=entry-cover><img loading=lazy src=https://s-ai-unix.github.io/images/covers/photo-1509228468518-180dd4864904.jpg alt=抽象几何图形></figure><header class=entry-header><h2 class=entry-hint-parent>传统机器学习与统计学习算法：从理论到实践的完整指南</h2></header><div class=entry-content><p>引言：从统计学到机器学习 1956年，达特茅斯会议上正式提出了"人工智能"这个词。但在那之前的一百年里，统计学家们已经在用数学工具从数据中提取规律。高斯在1809年就用最小二乘法解决了天文学中的观测数据拟合问题，这可以看作是最早的机器学习算法。
机器学习和统计学习，本质上是一回事：从数据中学习规律，并用这些规律做出预测。只是出发点略有不同——统计学家关注估计的可靠性和显著性检验，而计算机科学家更关心算法的计算效率和泛化能力。
当我们说"传统机器学习"时，指的是深度学习时代之前的那些经典算法。这些算法虽然不像神经网络那样"万能"，但在数据量有限、需要可解释性的场景下，依然发挥着不可替代的作用。
第一章：统计学习的理论基础 1.1 学习问题的数学框架 假设我们有一个数据集 $D = {(x_1, y_1), (x_2, y_2), \ldots, (x_n, y_n)}$，其中 $x_i \in \mathcal{X}$ 是输入（特征），$y_i \in \mathcal{Y}$ 是输出（标签）。我们的目标是找到一个函数 $f: \mathcal{X} \to \mathcal{Y}$，使得对于新的输入 $x$，$f(x)$ 能准确预测对应的 $y$。
但在统计学习的框架下，我们还需要引入概率论的概念。假设数据是按照某个未知的联合分布 $P(X,Y)$ 生成的，我们的目标是学习一个决策函数 $f$，使得期望风险最小化：
$$R(f) = \mathbb{E}_{(X,Y) \sim P}[L(Y, f(X))]$$
其中 $L$ 是损失函数。对于回归问题，常用平方损失；对于分类问题，常用0-1损失或交叉熵损失。
问题在于：我们不知道 $P(X,Y)$，无法直接计算 $R(f)$。我们只能用经验风险（Empirical Risk）来近似：
$$\hat{R}(f) = \frac{1}{n}\sum_{i=1}^n L(y_i, f(x_i))$$
这就是经验风险最小化（ERM）的基本思想。但直接最小化经验风险会导致过拟合（overfitting）。
1.2 偏差-方差权衡 这是统计学习中最重要的概念之一。模型的预测误差可以分解为三个部分：
$$\mathbb{E}[(y - \hat{f}(x))^2] = \text{Bias}[\hat{f}(x)]^2 + \text{Var}[\hat{f}(x)] + \sigma^2$$
其中：
$\text{Bias}[\hat{f}(x)] = \mathbb{E}[\hat{f}(x)] - f^*(x)$：模型预测的期望与真实值的差距 $\text{Var}[\hat{f}(x)] = \mathbb{E}[(\hat{f}(x) - \mathbb{E}[\hat{f}(x)])^2]$：模型预测的方差 $\sigma^2$：不可约误差（数据本身的噪声） 偏差反映了模型的"假设强度"。如果模型过于简单（比如用线性模型拟合高度非线性的数据），会产生高偏差，导致欠拟合。
...</p></div><footer class=entry-footer><span title='2026-01-14 08:18:25 +0800 CST'>January 14, 2026</span>&nbsp;·&nbsp;<span>11 min</span>&nbsp;·&nbsp;<span>2161 words</span>&nbsp;·&nbsp;<span>s-ai-unix</span></footer><a class=entry-link aria-label="post link to 传统机器学习与统计学习算法：从理论到实践的完整指南" href=https://s-ai-unix.github.io/posts/2026-01-14-traditional-ml-algorithms-comprehensive-guide/></a></article><article class=post-entry><figure class=entry-cover><img loading=lazy src=https://s-ai-unix.github.io/images/covers/1533573772-682710944375.jpg alt=弯曲的几何></figure><header class=entry-header><h2 class=entry-hint-parent>克里斯托费尔符号：弯曲空间的导航系统</h2></header><div class=entry-content><p>引言：平坦世界中的迷失 想象你站在一个平坦的机场跑道上。你可以沿着东西方向走，也可以沿着南北方向走。如果你从起点向东走1000米，然后向北走1000米，再向西走1000米，最后向南走1000米，你会回到起点——这是常识。
但如果你站在一个巨大的球面上，比如地球表面，情况就完全不同了。从赤道出发，向北走到北极，再沿着同一经度线向南走回赤道，你会发现自己在起点以西。不是因为你走歪了，而是因为你走的是一个弯曲的空间。
在弯曲空间中，我们需要重新思考什么是"直线"，什么是"平行"，甚至什么是"导数"。克里斯托费尔符号（Christoffel symbols），正是为了解决这些问题而诞生的数学工具。
它不仅仅是一堆符号，它是弯曲空间中的导航系统。它告诉我们，当我们沿着空间移动时，坐标系本身会发生什么变化。
让我们从一个最简单的问题开始：为什么我们会在弯曲空间中迷失？
第一章：从平地到弯曲世界 1.1 向量场：每一点都有一个箭头 在三维欧几里得空间中，我们可以用笛卡尔坐标系来描述点的位置：$\mathbf{r} = (x, y, z)$。在这个熟悉的坐标系中，一个向量场 $\mathbf{V}(\mathbf{r})$ 可以写成：
$$\mathbf{V} = V^x \frac{\partial}{\partial x} + V^y \frac{\partial}{\partial y} + V^z \frac{\partial}{\partial z}$$
其中 $\frac{\partial}{\partial x}, \frac{\partial}{\partial y}, \frac{\partial}{\partial z}$ 是基向量，$V^x, V^y, V^z$ 是向量场的分量。
关键问题：在笛卡尔坐标系中，基向量 $\frac{\partial}{\partial x}, \frac{\partial}{\partial y}, \frac{\partial}{\partial z}$ 在空间中是恒定不变的。无论你在哪里，$x$ 方向的单位向量都指向同一方向。
这就是为什么我们可以在平坦空间中轻松计算导数：
$$\frac{\partial \mathbf{V}}{\partial x} = \frac{\partial V^x}{\partial x} \frac{\partial}{\partial x} + \frac{\partial V^y}{\partial x} \frac{\partial}{\partial y} + \frac{\partial V^z}{\partial x} \frac{\partial}{\partial z}$$
...</p></div><footer class=entry-footer><span title='2026-01-13 20:00:00 +0800 CST'>January 13, 2026</span>&nbsp;·&nbsp;<span>5 min</span>&nbsp;·&nbsp;<span>951 words</span>&nbsp;·&nbsp;<span>s-ai-unix</span></footer><a class=entry-link aria-label="post link to 克里斯托费尔符号：弯曲空间的导航系统" href=https://s-ai-unix.github.io/posts/2026-01-13-christoffel-symbols-guide/></a></article><article class=post-entry><figure class=entry-cover><img loading=lazy src=https://s-ai-unix.github.io/images/covers/1555255707-c07966088b7b.jpg alt="Monge–Ampère equation"></figure><header class=entry-header><h2 class=entry-hint-parent>蒙日-安培方程详解：历史、演进、推导与应用</h2></header><div class=entry-content><p>$
\det(D^2 u) = f(x, u, \nabla u), \quad x \in \Omega \subset \mathbb{R}^n $
其中 $u$ 通常为凸函数，$D^2 u$ 是 Hessian 矩阵，$\det(D^2 u)$ 表示 Hessian 的行列式。它是所有二阶偏导的“体积型”组合，与线性椭圆方程（如拉普拉斯方程）相比高度非线性。
2. 二维一般形式 $ A(u_{xx}u_{yy}-u_{xy}^2)+B u_{xx}+2C u_{xy}+D u_{yy}+E=0 $
其中 $A,B,C,D,E$ 可依赖于 $(x,y,u,u_x,u_y)$。当 $A \neq 0$ 时，方程具有典型的 Monge–Ampère 结构。
公式推导（核心思路） 1. 曲率处方式推导 设曲面由函数 $z = u(x)$ 给出，其高斯曲率为 $ K = \frac{\det(D^2 u)}{(1+|\nabla u|^2)^{(n+2)/2}} $
因此，如果希望曲面具有给定曲率 $K(x)$，则必须满足 $ \det(D^2 u) = K(x),(1+|\nabla u|^2)^{(n+2)/2} $
这正是 Monge–Ampère 方程的几何起源之一，也解释了其在凸几何问题（如 Minkowski 问题）中的核心地位。
2. 最优传输与雅可比行列式推导 设 $T: \Omega \to \Omega’$ 为传输映射，将密度 $f_\Omega$ 传输到 $f_{\Omega’}$，满足质量守恒： $ \int_A f_\Omega(x),dx = \int_{T(A)} f_{\Omega’}(y),dy $
...</p></div><footer class=entry-footer><span title='2026-01-13 16:00:00 +0800 CST'>January 13, 2026</span>&nbsp;·&nbsp;<span>2 min</span>&nbsp;·&nbsp;<span>261 words</span>&nbsp;·&nbsp;<span>s-ai-unix</span></footer><a class=entry-link aria-label="post link to 蒙日-安培方程详解：历史、演进、推导与应用" href=https://s-ai-unix.github.io/posts/2026-01-13-monge-ampere-equation-detailed-introduction/></a></article><article class=post-entry><figure class=entry-cover><img loading=lazy src=https://s-ai-unix.github.io/images/covers/1618005182384-a83a8bd57fbe.jpg alt=柔和光影下的曲线></figure><header class=entry-header><h2 class=entry-hint-parent>测地线方程：历史、推导与现实应用</h2></header><div class=entry-content><p>引言：最短路径的直觉 想象你在一颗巨大星球上行走：从赤道的一个点出发，走到另一个经度的点。如果你沿着纬线走，那只是最省力的直觉，却未必是最短的距离。真正的最短路径，是那条看起来“弯着走”的大圆弧。
在平坦世界里，最短路径就是直线。但在弯曲空间中，“最短”和“最直”变成了一个更深的几何问题：测地线。测地线方程是一条连接历史、数学与现实的主线，它告诉我们：自由运动的轨迹在曲率中如何被重新定义。
第一章：测地线到底是什么 测地线（geodesic）可以从两个角度理解：
几何角度：曲面或流形上“最直”的曲线，即切向量沿自身平行移动。 变分角度：使弧长泛函取极值的曲线。 设曲线由参数 $ \lambda$ 描述：
$$x^i = x^i(\lambda), \quad i=1,\dots,n$$
弧长为：
$$S = \int_{\lambda_1}^{\lambda_2} ds = \int_{\lambda_1}^{\lambda_2} \sqrt{g_{ij}(x) \dot{x}^i \dot{x}^j} , d\lambda$$
让 $S$ 取极值的曲线，就是测地线。
第二章：测地线方程的历史脉络 测地线的故事几乎和微积分一样古老。
2.1 17-18世纪：变分法的萌芽 1697，伯努利：研究凸曲面最短路径，提出几何条件。 1732，欧拉：给出隐式曲面的测地线方程。 1744，欧拉《Methodus inveniendi》：系统建立变分法。 1788，拉格朗日《解析力学》：发展欧拉-拉格朗日方程，为测地线提供通用框架。 2.2 19世纪：几何语言的形成 1854，黎曼：引入度量张量，奠定弯曲空间几何基础。 1869，克里斯托费尔：提出克里斯托费尔符号，描述坐标基的变化。 1896，里奇与列维-奇维塔：形成绝对微分学与协变导数。 1917，列维-奇维塔：以平行移动解释协变导数，测地线获得清晰几何意义。 2.3 20世纪：物理的舞台 1915，爱因斯坦：将测地线方程作为自由落体的运动定律。 由此，测地线不仅属于几何，也成为引力理论的核心。 第三章：测地线方程的完整推导 3.1 变分原理 我们从弧长泛函开始：
$$S = \int \sqrt{g_{ij} \dot{x}^i \dot{x}^j} , d\lambda$$
由于平方根带来计算困难，我们使用等价的作用量：
$$S’ = \frac{1}{2} \int g_{ij} \dot{x}^i \dot{x}^j , d\lambda$$
...</p></div><footer class=entry-footer><span title='2026-01-13 13:00:00 +0800 CST'>January 13, 2026</span>&nbsp;·&nbsp;<span>2 min</span>&nbsp;·&nbsp;<span>276 words</span>&nbsp;·&nbsp;<span>s-ai-unix</span></footer><a class=entry-link aria-label="post link to 测地线方程：历史、推导与现实应用" href=https://s-ai-unix.github.io/posts/2026-01-13-geodesic-equation-history-and-derivation/></a></article><article class=post-entry><figure class=entry-cover><img loading=lazy src=https://s-ai-unix.github.io/images/covers/1618005182384-a83a8bd57fbe.jpg alt=弯曲的数学世界></figure><header class=entry-header><h2 class=entry-hint-parent>微分几何：从数学抽象到自动驾驶的现实</h2></header><div class=entry-content><p>引言：平坦世界的局限 想象你站在一个巨大的球面上，比如地球。你手里有一个指南针，可以告诉你"北"的方向。你沿着"北"的方向走，一直走到北极。然后，你继续沿着原来的"南"方向（相对于你的起点）走下去。
奇怪的事情发生了：你永远不会回到原来的方向。北极点的"北"没有意义——所有方向都是"南"！
这就是微分几何要解决的问题：在弯曲的世界中，我们如何定义方向、距离、曲线和导数？
从平坦到弯曲
在欧几里得几何中，空间是平坦的、均匀的。平行线永不相交，三角形内角和总是180度，两点之间直线最短。我们中学学的几何，都是这样的。
但真实世界不是平坦的。地球是球面（近似），时空是弯曲的（广义相对论），高维数据分布在复杂的流形上（深度学习）。
微分几何，就是研究这些弯曲空间的数学工具。它告诉我们：在弯曲的世界里，什么是"直线"，什么是"平行"，甚至什么是"导数"。
而今天，这个曾经抽象的数学分支，已经成为深度学习、机器人工程和自动驾驶的核心。
让我们从最基本的概念开始，逐步走向这些现代技术的深处。
第一章：流形——弯曲空间的数学 1.1 什么是流形？ 流形（manifold）的概念源于这样一个观察：局部看，任何光滑的弯曲空间都像平坦的欧几里得空间。
例子：球面
局部看：一个小区域的地球表面，看起来是平的（所以我们可以画平面地图） 整体看：它是弯曲的（所以所有地图都有变形） 数学上，一个$n$维流形$\mathcal{M}$是这样一个空间：每一点$p\in\mathcal{M}$都有一个邻域，同胚于$\mathbb{R}^n$。
直观理解：流形是"局部平坦，整体弯曲"的空间。
1.2 切空间和切向量 在弯曲的流形上，我们不能直接说"向量指向某个方向"。向量必须定义在切空间（tangent space）上。
切空间$T_p\mathcal{M}$：在点$p$处，所有可能的"方向"构成的线性空间。
对于球面上的点，切空间是该点的切平面。在这个平面上，我们可以定义向量和线性运算。
关键：不同点的切空间是不同的！你不能直接比较点$p$的切向量和点$q$的切向量。
这就是为什么我们需要联络（connection）——它告诉我们如何在相邻的切空间之间移动向量。
1.3 度量张量 在平坦的欧几里得空间中，两个向量$\mathbf{u}, \mathbf{v}$的内积很简单：
$$\langle \mathbf{u}, \mathbf{v} \rangle = \mathbf{u}^T \mathbf{v} = u_1 v_1 + u_2 v_2 + \cdots + u_n v_n$$
但在弯曲空间中，每个点的度量可能是不同的。我们需要度量张量$g_{ij}$：
$$\langle \mathbf{u}, \mathbf{v} \rangle_p = g_{ij}(p) u^i v^j$$
使用爱因斯坦求和约定（重复指标自动求和）。
直观理解：$g_{ij}$告诉我们这个点空间的"拉伸"和"扭曲"程度。
1.4 曲率 曲率（curvature）描述了空间弯曲的程度。
在平坦空间中，平行移动一个向量回到原点，方向不变。在弯曲空间中，方向会改变。
黎曼曲率张量$R^k_{lij}$：
$$(\nabla_i \nabla_j - \nabla_j \nabla_i) V^k = R^k_{lij} V^l$$
...</p></div><footer class=entry-footer><span title='2026-01-13 12:00:00 +0800 CST'>January 13, 2026</span>&nbsp;·&nbsp;<span>4 min</span>&nbsp;·&nbsp;<span>655 words</span>&nbsp;·&nbsp;<span>s-ai-unix</span></footer><a class=entry-link aria-label="post link to 微分几何：从数学抽象到自动驾驶的现实" href=https://s-ai-unix.github.io/posts/2026-01-13-differential-geometry-applications/></a></article><article class=post-entry><figure class=entry-cover><img loading=lazy src=https://s-ai-unix.github.io/images/covers/iso26262-1-vocabulary.jpg alt="ISO 26262 词汇定义"></figure><header class=entry-header><h2 class=entry-hint-parent>ISO 26262-1 词汇：功能安全标准的语言基础</h2></header><div class=entry-content><p>引言 在汽车电子的世界里，功能安全是一个关乎生命的重要议题。想象一下，当你驾驶汽车以每小时 100 公里的速度行驶在高速公路上，你的 ABS（防抱死制动系统）突然失效，或者动力转向突然不工作，这些情况都可能导致灾难性的后果。为了防止这些情况的发生，国际标准化组织制定了 ISO 26262 标准，而这一系列的第一部分——ISO 26262-1 词汇，就是理解整个标准的基础。
你可能会有这样的疑问：为什么词汇部分如此重要？ 让我们用一个简单的比喻来说明。就像学习一门新的编程语言，首先需要理解其语法和关键字一样，ISO 26262 的每一个术语都有其精确的定义和特定的含义。如果不能准确理解这些术语，就无法正确应用后续各个部分的要求。
在本文中，我们将深入解读 ISO 26262-1 的核心术语，通过丰富的案例实践，让你不仅理解这些术语的定义，更能掌握它们在实际工程中的应用。
核心概念：功能安全的本质 什么是功能安全？ ISO 26262-1 将**功能安全（Functional Safety）**定义为：
不存在因电子电气系统故障导致的不合理风险
这个定义看似简单，但包含了几个关键的要素：
风险的不合理性：不是所有风险都要完全消除，而是要将风险降低到"合理"的水平 电子电气系统：关注的是 E/E 系统（Electrical and Electronic systems） 故障导向：关注的是系统可能发生的故障行为 让我们用一个实际的例子来说明。
案例：汽车制动系统 假设我们正在设计一个电动车的制动系统。这个系统包含：
机械制动（主缸、刹车片等） 电子制动控制（ABS、ESP 等控制器） 传感器（轮速传感器、压力传感器等） 功能安全的目标是确保：即使电子控制系统出现故障，车辆仍然能够被驾驶员安全地制动。
如果 ABS 控制器发生故障，系统进入降级模式，但基本的制动功能仍然有效，那么这就满足了功能安全的要求。
安全目标（Safety Goal） 安全目标是 ISO 26262 中最顶层的安全要求。它描述了为了实现功能安全，必须达到的具体目标。
案例：动力转向系统安全目标 对于电动助力转向系统（EPS），一个典型的安全目标可能是：
“在所有可预见的使用场景下，EPS 系统的故障不得导致转向力的突然完全丧失。”
这个安全目标的几个特点：
明确了保护对象：转向力的连续性 明确了风险场景：突然完全丧失 明确了约束条件：所有可预见的使用场景 ASIL：汽车安全完整性等级 ASIL 的四个等级 **ASIL（Automotive Safety Integrity Level，汽车安全完整性等级）**是 ISO 26262 中最核心的概念之一。它将汽车功能安全的严格要求分为四个等级：ASIL A、B、C、D。
...</p></div><footer class=entry-footer><span title='2026-01-13 00:00:00 +0000 UTC'>January 13, 2026</span>&nbsp;·&nbsp;<span>4 min</span>&nbsp;·&nbsp;<span>789 words</span>&nbsp;·&nbsp;<span>s-ai-unix</span></footer><a class=entry-link aria-label="post link to ISO 26262-1 词汇：功能安全标准的语言基础" href=https://s-ai-unix.github.io/posts/2026-01-13-iso26262-1-vocabulary/></a></article><article class=post-entry><figure class=entry-cover><img loading=lazy src=https://s-ai-unix.github.io/images/covers/1620641788421-7a1c342ea42e.jpg alt=流形的可视化></figure><header class=entry-header><h2 class=entry-hint-parent>流形：从弯曲空间到深度学习与机器人学的漫游</h2></header><div class=entry-content><p>引言：当空间开始弯曲 想象一下，你是一只生活在二维平面上的蚂蚁。你可以自由地在平面上行走，测量距离，画出直线和三角形。你所知道的几何——欧几里得几何——似乎是那么完美、那么自洽。
现在，让我们把这只蚂蚁放到一个巨大的篮球表面。
蚂蚁会发现什么呢？首先，它会发现"直线"不再存在。如果它一直往前走，最终会回到起点——它走的是"大圆"，而不是直线。其次，它会发现三角形的内角和不再是180度，而是大于180度。最神奇的是，如果它足够聪明，它可以通过测量距离和角度来发现这个空间的曲率——尽管它从未"跳出"过这个二维曲面。
这就是内蕴几何的魔力，也是流形（Manifold）概念的起点。
在接下来的篇幅中，我将带你进行一次从19世纪的几何革命到21世纪人工智能的漫游。我们会看到：
流形的诞生：高斯和黎曼如何改变了我们对空间的理解 流形的数学：为什么流形是"局部平坦、整体弯曲"的几何对象 流形在深度学习：从流形假设到球面Embedding 流形在机器人学：从四元数到SLAM 实战案例：四个让你真正理解流形威力的例子 准备好了吗？让我们开始这段跨越时空的数学之旅。
第一章：几何的危机与重生 1.1 欧几里得的第五公设 公元前300年，亚历山大港的数学家欧几里得写下了《几何原本》——这部奠定了西方科学基础的巨著。欧几里得从五条公设出发，推导出无数深刻的几何定理。其中第五条公设——平行公设——却让数学家们困惑了两千多年。
平行公设：如果一条直线与两条直线相交，且同侧内角之和小于两个直角，则这两条直线在该侧无限延伸后必定相交。
这条公设看起来比其他公设复杂得多。数学家们不禁想问：它能否从前四条公设中推导出来？如果可以，那它就不是真正的公设；如果不可以，那是否存在一种"非欧几里得几何"，其中平行公设不成立？
1.2 罗巴切夫斯基的革命 1829年，俄罗斯数学家罗巴切夫斯基（Nikolai Lobachevsky）发表了第一篇非欧几何的论文。他假设过一点可以作多条平行线，由此推导出一套完整的几何体系——双曲几何。
在双曲几何中：
三角形的内角和小于180度 相似三角形只有大小完全相同才算相似 不存在矩形，因为四边形的内角和小于360度 罗巴切夫斯基的发现彻底改变了数学家对几何本质的认识：几何不是关于"真实空间"的真理，而是关于某种抽象结构的逻辑系统。
1.3 高斯的绝妙定理 几乎在同一时间，德国数学家高斯也在思考类似的问题。高斯不仅是一个理论家，还是一个实测工作者——他参与了汉诺威的大地测量。在测量中，高斯意识到一个深刻的问题：地球表面的几何能告诉我们什么？
1827年，高斯发表了绝妙定理（Theorema Egregium）：曲面的高斯曲率是一个内蕴不变量——它完全由曲面自身的几何性质决定，与曲面如何嵌入周围空间无关。
这个定理的惊人之处在于：曲率不是"外部"观察者看到的弯曲，而是曲面"内部"几何结构的必然结果。一只生活在曲面上的蚂蚁，通过测量距离和角度，可以计算出它所在空间的曲率——即使它永远无法"看到"曲面在三维空间中的弯曲方式。
高斯的工作开创了内蕴几何的新时代，为流形的诞生奠定了基础。
1.4 黎曼的推广 1854年，高斯的学生黎曼（Bernhard Riemann）在哥廷根大学发表了著名的就职演讲《论作为几何学基础的假设》。黎曼将高斯的二维曲面理论推广到任意维数，创立了黎曼几何。
黎曼的核心思想是：几何不在于"空间是什么"，而在于"我们如何测量空间中的距离"。
黎曼提出用一个度规张量（Metric Tensor）来描述空间的几何性质。度规告诉我们如何在空间的每一点测量距离和角度。有了度规，我们就可以定义：
曲线的长度 向量的点积 角度和面积 平行移动 测地线（最直的曲线） 黎曼几何成为了20世纪物理学的基石。1915年，爱因斯坦用黎曼几何描述时空的弯曲，建立了广义相对论。
第二章：流形的数学定义 2.1 什么是流形？ 在数学中，流形（Manifold）是一个抽象的空间概念。直观地说，流形是一个"局部看起来像欧几里得空间"的空间。
流形的定义：
一个 $n$ 维流形 $M$ 是一个满足以下条件的拓扑空间：
局部欧几里得性：对于 $M$ 中的每一点 $p$，存在一个开集 $U \subseteq M$ 包含 $p$，以及一个从 $U$ 到 $\mathbb{R}^n$ 的开集的同胚映射（称为坐标图）： $$\varphi: U \to \mathbb{R}^n$$
...</p></div><footer class=entry-footer><span title='2026-01-12 23:10:00 +0800 CST'>January 12, 2026</span>&nbsp;·&nbsp;<span>10 min</span>&nbsp;·&nbsp;<span>2090 words</span>&nbsp;·&nbsp;<span>s-ai-unix</span></footer><a class=entry-link aria-label="post link to 流形：从弯曲空间到深度学习与机器人学的漫游" href=https://s-ai-unix.github.io/posts/2026-01-12-manifold-deep-learning-robotics/></a></article><footer class=page-footer><nav class=pagination><a class=prev href=https://s-ai-unix.github.io/posts/page/5/>«&nbsp;Prev&nbsp;
</a><a class=next href=https://s-ai-unix.github.io/posts/page/7/>Next&nbsp;&nbsp;»</a></nav></footer></main><footer class=footer><span>&copy; 2026 <a href=https://s-ai-unix.github.io/>s-ai-unix's Blog</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
<a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script>(function(){"use strict";function e(){var e=document.querySelectorAll("p, li, td, div, span, h1, h2, h3, h4, h5, h6, ol, ul");e.forEach(function(e){if(e.classList.contains("classical-quote-container")||e.classList.contains("quote-text")||e.closest(".classical-quote-container"))return;var n,t=e.innerHTML,s=!1;for(t.indexOf("<em>")!==-1&&(n=t.replace(/\$([^$]*?)<em>([^<]+?)<\/em>([^$]*?)\$/g,function(e,t,n,s){return/^[\d.,]+$/.test((t+n+s).replace(/[.,]/g,""))?e:"$"+t+"_"+n+s+"$"}),n=n.replace(/\$\$([^$]*?)<em>([^<]+?)<\/em>([^$]*?)\$\$/g,function(e,t,n,s){return"$$"+t+"_"+n+s+"$$"}),n!==t&&(t=n,s=!0)),t.indexOf("</em>")!==-1&&(n=t.replace(/\$([^$]*?)<\/em>([^$]*?)\$/g,function(e,t,n){return"$"+t+"_{"+n+"$"}),n=n.replace(/\$\$([^$]*?)<\/em>([^$]*?)\$\$/g,function(e,t,n){return"$$"+t+"_{"+n+"$$"}),n!==t&&(t=n,s=!0)),t.indexOf("<em>$")!==-1&&(n=t.replace(/<em>\$/g,"$"),n!==t&&(t=n,s=!0)),t.indexOf("</em>$")!==-1&&(n=t.replace(/<\/em>\$/g,"$"),n!==t&&(t=n,s=!0));t.indexOf("<em>")!==-1&&t.indexOf("</em>")!==-1;){if(n=t.replace(/\$([^$]*?)<em>([^<]+?)<\/em>([^$]*?)\$/g,function(e,t,n,s){return/^[\d.,]+$/.test((t+n+s).replace(/[.,]/g,""))?e:"$"+t+"_"+n+s+"$"}),n=n.replace(/\$\$([^$]*?)<em>([^<]+?)<\/em>([^$]*?)\$\$/g,function(e,t,n,s){return"$$"+t+"_"+n+s+"$$"}),n===t)break;t=n,s=!0}t.indexOf("_{")!==-1&&(n=t.replace(/_{/g,"_{"),n!==t&&(t=n,s=!0)),t.indexOf("}_")!==-1&&(n=t.replace(/}_/g,"}"),n!==t&&(t=n,s=!0)),t.indexOf("\\\\")!==-1&&(n=t.replace(/(\$\{1,2\})([^$]*?)(\$\{1,2\})/g,function(e,t,n,s){for(;n.indexOf("\\\\")!==-1;)n=n.replace(/\\\\/g,"\\");return t+n+s}),n!==t&&(t=n,s=!0)),s&&(e.innerHTML=t)})}window.MathJax={tex:{inlineMath:[["$","$"]],displayMath:[["$$","$$"]],processEscapes:!0,processEnvironments:!0,tags:"ams",macros:{oiint:"\\mathop{∯}",oiiint:"\\mathop{∰}"}},options:{skipHtmlTags:["script","noscript","style","textarea","pre","code"]},startup:{pageReady:function(){return e(),MathJax.startup.defaultPageReady().then(function(){console.log("MathJax formulas rendered successfully")})}}}})()</script><script src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script><link rel=stylesheet href=/css/mermaid-custom.css><script src=/js/mermaid-converter.js></script><script type=module>
  import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs';

  
  setTimeout(() => {
    mermaid.initialize({
      startOnLoad: true,
      theme: 'base',
      themeVariables: {
        primaryColor: '#e3f2fd',
        primaryTextColor: '#1565c0',
        primaryBorderColor: '#2196f3',
        lineColor: '#42a5f5',
        secondaryColor: '#f3e5f5',
        tertiaryColor: '#fff9c4',
        background: '#ffffff',
        mainBkg: '#ffffff',
        nodeBorder: '#2196f3',
        clusterBkg: '#ffffff',
        clusterBorder: '#e0e0e0',
        titleColor: '#1565c0',
        edgeLabelBackground: '#fafafa',
      },
      securityLevel: 'loose',
    });
  }, 100);
</script><script src=/js/toc.js></script><script>let menu=document.getElementById("menu");if(menu){const e=localStorage.getItem("menu-scroll-position");e&&(menu.scrollLeft=parseInt(e,10)),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}}document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{const e=document.querySelector("html");e.dataset.theme==="dark"?(e.dataset.theme="light",localStorage.setItem("pref-theme","light")):(e.dataset.theme="dark",localStorage.setItem("pref-theme","dark"))})</script><script>(function(){"use strict";function e(){var e=document.querySelectorAll("p, li, td, div, span, h1, h2, h3, h4, h5, h6, ol, ul");e.forEach(function(e){if(e.classList.contains("classical-quote-container")||e.classList.contains("quote-text")||e.closest(".classical-quote-container"))return;var n,t=e.innerHTML,s=!1;for(t.indexOf("<em>")!==-1&&(n=t.replace(/\$([^$]*?)<em>([^<]+?)<\/em>([^$]*?)\$/g,function(e,t,n,s){return/^[\d.,]+$/.test((t+n+s).replace(/[.,]/g,""))?e:"$"+t+"_"+n+s+"$"}),n=n.replace(/\$\$([^$]*?)<em>([^<]+?)<\/em>([^$]*?)\$\$/g,function(e,t,n,s){return"$$"+t+"_"+n+s+"$$"}),n!==t&&(t=n,s=!0)),t.indexOf("</em>")!==-1&&(n=t.replace(/\$([^$]*?)<\/em>([^$]*?)\$/g,function(e,t,n){return"$"+t+"_{"+n+"$"}),n=n.replace(/\$\$([^$]*?)<\/em>([^$]*?)\$\$/g,function(e,t,n){return"$$"+t+"_{"+n+"$$"}),n!==t&&(t=n,s=!0)),t.indexOf("<em>$")!==-1&&(n=t.replace(/<em>\$/g,"$"),n!==t&&(t=n,s=!0)),t.indexOf("</em>$")!==-1&&(n=t.replace(/<\/em>\$/g,"$"),n!==t&&(t=n,s=!0));t.indexOf("<em>")!==-1&&t.indexOf("</em>")!==-1;){if(n=t.replace(/\$([^$]*?)<em>([^<]+?)<\/em>([^$]*?)\$/g,function(e,t,n,s){return/^[\d.,]+$/.test((t+n+s).replace(/[.,]/g,""))?e:"$"+t+"_"+n+s+"$"}),n=n.replace(/\$\$([^$]*?)<em>([^<]+?)<\/em>([^$]*?)\$\$/g,function(e,t,n,s){return"$$"+t+"_"+n+s+"$$"}),n===t)break;t=n,s=!0}t.indexOf("_{")!==-1&&(n=t.replace(/_{/g,"_{"),n!==t&&(t=n,s=!0)),t.indexOf("}_")!==-1&&(n=t.replace(/}_/g,"}"),n!==t&&(t=n,s=!0)),t.indexOf("\\\\")!==-1&&(n=t.replace(/(\$\{1,2\})([^$]*?)(\$\{1,2\})/g,function(e,t,n,s){for(;n.indexOf("\\\\")!==-1;)n=n.replace(/\\\\/g,"\\");return t+n+s}),n!==t&&(t=n,s=!0)),s&&(e.innerHTML=t)})}window.MathJax={tex:{inlineMath:[["$","$"]],displayMath:[["$$","$$"]],processEscapes:!0,processEnvironments:!0,tags:"ams",macros:{oiint:"\\mathop{∯}",oiiint:"\\mathop{∰}"}},options:{skipHtmlTags:["script","noscript","style","textarea","pre","code"]},startup:{pageReady:function(){return e(),MathJax.startup.defaultPageReady().then(function(){console.log("MathJax formulas rendered successfully")})}}}})()</script><script src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script><link rel=stylesheet href=/css/mermaid-custom.css><script src=/js/mermaid-converter.js></script><script type=module>
  import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs';

  
  setTimeout(() => {
    mermaid.initialize({
      startOnLoad: true,
      theme: 'base',
      themeVariables: {
        primaryColor: '#e3f2fd',
        primaryTextColor: '#1565c0',
        primaryBorderColor: '#2196f3',
        lineColor: '#42a5f5',
        secondaryColor: '#f3e5f5',
        tertiaryColor: '#fff9c4',
        background: '#ffffff',
        mainBkg: '#ffffff',
        nodeBorder: '#2196f3',
        clusterBkg: '#ffffff',
        clusterBorder: '#e0e0e0',
        titleColor: '#1565c0',
        edgeLabelBackground: '#fafafa',
      },
      securityLevel: 'loose',
    });
  }, 100);
</script><script src=/js/toc.js></script></body></html>
<!doctype html><html lang=en dir=auto data-theme=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Posts | s-ai-unix's Blog</title><meta name=keywords content><meta name=description content="Posts - s-ai-unix's Blog"><meta name=author content="s-ai-unix"><link rel=canonical href=https://s-ai-unix.github.io/posts/><link crossorigin=anonymous href=/assets/css/stylesheet.0833aff7e1cf567ecfb9755701ee95a80535f671e2e1a0a770c9bc20a0a7b5bb.css integrity="sha256-CDOv9+HPVn7PuXVXAe6VqAU19nHi4aCncMm8IKCntbs=" rel="preload stylesheet" as=style><link rel=icon href=https://s-ai-unix.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://s-ai-unix.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://s-ai-unix.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://s-ai-unix.github.io/apple-touch-icon.png><link rel=mask-icon href=https://s-ai-unix.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate type=application/rss+xml href=https://s-ai-unix.github.io/posts/index.xml title=rss><link rel=alternate hreflang=en href=https://s-ai-unix.github.io/posts/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51);color-scheme:dark}.list{background:var(--theme)}.toc{background:var(--entry)}}@media(prefers-color-scheme:light){.list::-webkit-scrollbar-thumb{border-color:var(--code-bg)}}</style></noscript><script>localStorage.getItem("pref-theme")==="dark"?document.querySelector("html").dataset.theme="dark":localStorage.getItem("pref-theme")==="light"?document.querySelector("html").dataset.theme="light":window.matchMedia("(prefers-color-scheme: dark)").matches?document.querySelector("html").dataset.theme="dark":document.querySelector("html").dataset.theme="light"</script><meta property="og:url" content="https://s-ai-unix.github.io/posts/"><meta property="og:site_name" content="s-ai-unix's Blog"><meta property="og:title" content="Posts"><meta property="og:description" content="s-ai-unix 的个人技术博客，分享数学、AI、产品设计、数据科学、智能汽车(设计、研发、质量、合规)、历史等领域的知识和思考"><meta property="og:locale" content="zh-cn"><meta property="og:type" content="website"><meta name=twitter:card content="summary"><meta name=twitter:title content="Posts"><meta name=twitter:description content="s-ai-unix 的个人技术博客，分享数学、AI、产品设计、数据科学、智能汽车(设计、研发、质量、合规)、历史等领域的知识和思考"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://s-ai-unix.github.io/posts/"}]}</script><link rel=stylesheet href=https://s-ai-unix.github.io/css/classical-quote.css></head><body class=list id=top><header class=header><nav class=nav><div class=logo><a href=https://s-ai-unix.github.io/ accesskey=h title="s-ai-unix's Blog (Alt + H)">s-ai-unix's Blog</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://s-ai-unix.github.io/ title="🏠 首页"><span>🏠 首页</span></a></li><li><a href=https://s-ai-unix.github.io/posts/ title="📚 文章"><span class=active>📚 文章</span></a></li><li><a href=https://s-ai-unix.github.io/archives/ title="📁 归档"><span>📁 归档</span></a></li><li><a href=https://s-ai-unix.github.io/tags/ title="🏷️ 标签"><span>🏷️ 标签</span></a></li><li><a href=https://s-ai-unix.github.io/search/ title="🔍 搜索 (Alt + /)" accesskey=/><span>🔍 搜索</span></a></li><li><a href=https://s-ai-unix.github.io/about/ title="👤 关于"><span>👤 关于</span></a></li></ul></nav></header><main class=main><header class=page-header><div class=breadcrumbs><a href=https://s-ai-unix.github.io/>Home</a></div><h1>Posts</h1></header><article class=post-entry><figure class=entry-cover><img loading=lazy src=https://s-ai-unix.github.io/images/covers/%E5%90%AB%E5%8F%82%E5%8F%98%E9%87%8F%E7%A7%AF%E5%88%86%E4%BB%8E%E6%AC%A7%E6%8B%89%E5%88%B0%E7%8E%B0%E4%BB%A3%E7%89%A9%E7%90%86%E7%9A%84%E6%95%B0%E5%AD%A6%E4%B9%8B%E6%97%85-cover.jpg alt="含参变量积分：从欧拉到现代物理的数学之旅 cover image"></figure><header class=entry-header><h2 class=entry-hint-parent>含参变量积分：从欧拉到现代物理的数学之旅</h2></header><div class=entry-content><p>引言 想象你是一位物理学家，正在计算一个运动物体在不同阻力系数下的轨迹；或者你是一位工程师，需要优化一个系统的参数以达到最佳性能。在这些场景中，你会发现积分表达式中不仅包含积分变量，还包含一个或多个参数——它们控制着积分的形态，但不参与积分过程本身。这就是含参变量积分（Parametric Integral）的世界。
简单来说，含参变量积分就是形如
$$F(t) = \int_a^b f(x, t) , dx$$
的积分，其中 $x$ 是积分变量，$t$ 是参数。当参数 $t$ 变化时，积分的结果 $F(t)$ 也随之变化，形成一个关于参数的函数。
这看似简单的扩展，却蕴含着极其丰富的数学内涵。从欧拉对 Gamma 函数的研究，到费曼在量子力学中发展的"路径积分"技巧，含参变量积分始终贯穿在数学与物理的发展脉络之中。本文将带领读者踏上一段从基础概念到高级应用的数学之旅，揭示这一工具的优雅与力量。
图1：含参变量积分发展历史时间线，从牛顿、莱布尼茨到费曼的重要里程碑
第一章：历史溯源——从流数法到现代分析学 1.1 微积分的诞生与早期探索 故事要从 17 世纪说起。1666 年，年轻的艾萨克·牛顿（Isaac Newton）在家乡躲避瘟疫期间，发展出了他称之为"流数法"（Method of Fluxions）的数学工具——这就是我们今天所说的微积分。几乎在同一时期，德国的戈特弗里德·莱布尼茨（Gottfried Leibniz）独立发展出了类似的理论，并引入了沿用至今的积分符号 $\int$。
在微积分创立的初期，数学家们主要关注的是如何计算具体的几何量：曲线下的面积、物体的体积、曲线的长度等。然而，随着问题的深入，人们逐渐意识到：有些问题的答案不是一个固定的数值，而是依赖于某个参数的函数。
一个典型的例子来自变分法的早期研究。1696 年，约翰·伯努利（Johann Bernoulli）提出了著名的"最速降线问题"：求一条曲线，使得质点在重力作用下从一点滑到另一点所需的时间最短。这个问题的解法涉及到对曲线形状参数的优化，本质上就是在处理含参积分。
1.2 欧拉时代——系统化的研究 到了 18 世纪，莱昂哈德·欧拉（Leonhard Euler）将含参积分的研究推向了新的高度。欧拉不仅是历史上最高产的数学家之一，更是第一个系统研究 Gamma 函数的人。
Gamma 函数是含参积分的经典范例：
$$\Gamma(t) = \int_0^{\infty} x^{t-1} e^{-x} , dx$$
这个定义在 $t > 0$ 时收敛，它将阶乘的概念推广到了非整数：$\Gamma(n) = (n-1)!$ 对所有正整数 $n$ 成立。
图2：Gamma 函数图像，展示 Γ(t) = ∫₀^∞ x^(t-1) e^(-x) dx 的函数形态及其整数值
...</p></div><footer class=entry-footer><span title='2026-02-01 19:04:13 +0800 CST'>February 1, 2026</span>&nbsp;·&nbsp;<span>5 min</span>&nbsp;·&nbsp;<span>1048 words</span>&nbsp;·&nbsp;<span>s-ai-unix</span></footer><a class=entry-link aria-label="post link to 含参变量积分：从欧拉到现代物理的数学之旅" href=https://s-ai-unix.github.io/posts/2026-02-01-%E5%90%AB%E5%8F%82%E5%8F%98%E9%87%8F%E7%A7%AF%E5%88%86%E4%BB%8E%E6%AC%A7%E6%8B%89%E5%88%B0%E7%8E%B0%E4%BB%A3%E7%89%A9%E7%90%86%E7%9A%84%E6%95%B0%E5%AD%A6%E4%B9%8B%E6%97%85/></a></article><article class=post-entry><figure class=entry-cover><img loading=lazy src=https://s-ai-unix.github.io/images/covers/line-surface-integrals-cover.jpg alt=曲线与曲面几何></figure><header class=entry-header><h2 class=entry-hint-parent>曲线与曲面积分：从第一类到第二类的演化</h2></header><div class=entry-content><p>引言：积分的几何延伸 当我们第一次学习定积分 $\int_a^b f(x) , dx$ 时，我们计算的是函数图像与 $x$ 轴之间的"有向面积"。这个定义基于一个基本的假设：积分是在一条直线段上进行的。
但在现实世界中，物理量的分布往往不局限于直线。水流沿着弯曲的河道流动，电场环绕着电荷分布，温度在复杂的曲面上变化。为了描述这些现象，数学家们必须将积分的概念从直线段推广到曲线和曲面。
这就是曲线积分（Line Integrals）和曲面积分（Surface Integrals）诞生的原因。
然而，故事并没有这么简单。当我们试图在曲线和曲面上进行积分时，很快就发现了一个根本性的问题：我们究竟在积分什么？
是曲线本身的弧长？ 还是曲线在坐标轴上的投影？ 是曲面的面积元？ 还是曲面相对于某个方向的有向投影？ 对这些问题的不同回答，导致了四种不同类型的积分：
$$ \begin{aligned} \text{第一类曲线积分} &: \int_C f(x,y) , ds \ \text{第二类曲线积分} &: \int_C P , dx + Q , dy \ \text{第一类曲面积分} &: \iint_S f(x,y,z) , dS \ \text{第二类曲面积分} &: \iint_S P , dy , dz + Q , dz , dx + R , dx , dy \end{aligned} $$
本文将带领读者深入理解这四种积分的历史背景、物理动机、数学定义以及计算方法，揭示它们之间的深刻联系。
第一章：第一类曲线积分——对弧长的积分 1.1 物理背景：不均匀细杆的质量 第一类曲线积分的历史可以追溯到18世纪，当时数学家们开始研究具有非均匀密度的物理对象。
...</p></div><footer class=entry-footer><span title='2026-02-01 18:56:56 +0800 CST'>February 1, 2026</span>&nbsp;·&nbsp;<span>7 min</span>&nbsp;·&nbsp;<span>1313 words</span>&nbsp;·&nbsp;<span>s-ai-unix</span></footer><a class=entry-link aria-label="post link to 曲线与曲面积分：从第一类到第二类的演化" href=https://s-ai-unix.github.io/posts/2026-02-01-line-surface-integrals/></a></article><article class=post-entry><figure class=entry-cover><img loading=lazy src=https://s-ai-unix.github.io/images/covers/poincare-volume-form-cover.jpg alt=几何抽象背景></figure><header class=entry-header><h2 class=entry-hint-parent>Poincaré的洞察：体积元的定向与外微分形式的诞生</h2></header><div class=entry-content><p>引言：一个看似平凡的发现 1890年代末，巴黎的学术圈正沉浸在分析学的繁荣之中。法国数学家亨利·庞加莱（Henri Poincaré, 1854-1912）坐在书桌前，凝视着多重积分的变换公式。在旁人看来，这只是一个技术性的细节问题——如何计算曲面积分、体积分在坐标变换下的行为？
然而，Poincaré敏锐地意识到一个被前人忽视的事实：多重积分的体积元应该有一个正负定向。
这一看似平凡的看法使得多重积分在坐标变换下原来有些拖泥带水的变换公式，有了一个精练的形式，并使Newton-Leibniz公式的推广，步入了坦途。
这一发现看似微不足道——不过是给积分测度加上一个正负号而已——但它却如同一把钥匙，打开了通往现代微分几何的大门。它直接催生了外微分形式（differential forms）的概念，为Stokes定理、de Rham上同调、甚至是现代物理学中的规范场论奠定了基础。
让我们循着历史的足迹，探寻这一发现的来龙去脉。
第一章：Poincaré之前的多重积分 1.1 单变量的辉煌与局限 让我们先回到单变量微积分的美好时代。Newton和Leibniz在17世纪末创立的微积分基本定理告诉我们：
$$ \int_a^b f’(x) , dx = f(b) - f(a) $$
这个公式之所以优美，在于它将区间 $[a,b]$ 上的积分与边界 ${a, b}$ 上的函数值联系起来。更妙的是，它暗示了积分具有某种"定向"的性质：从 $a$ 到 $b$ 的积分，与从 $b$ 到 $a$ 的积分差一个负号：
$$ \int_b^a f(x) , dx = -\int_a^b f(x) , dx $$
然而，当数学家们尝试将这一框架推广到多变量时，他们遇到了意想不到的困难。
1.2 早期的多重积分变换 考虑一个二重积分：
$$ I = \iint_D f(x,y) , dx , dy $$
假设我们进行坐标变换 $(x,y) \mapsto (u,v)$，其中 $x = x(u,v)$，$y = y(u,v)$。在18、19世纪，数学家们知道变换公式涉及雅可比行列式（Jacobian determinant）：
...</p></div><footer class=entry-footer><span title='2026-02-01 18:47:22 +0800 CST'>February 1, 2026</span>&nbsp;·&nbsp;<span>5 min</span>&nbsp;·&nbsp;<span>894 words</span>&nbsp;·&nbsp;<span>s-ai-unix</span></footer><a class=entry-link aria-label="post link to Poincaré的洞察：体积元的定向与外微分形式的诞生" href=https://s-ai-unix.github.io/posts/2026-02-01-poincare-volume-form/></a></article><article class=post-entry><figure class=entry-cover><img loading=lazy src=https://s-ai-unix.github.io/images/covers/epsilon-delta-cover.jpg alt="Epsilon-Delta 严格化革命"></figure><header class=entry-header><h2 class=entry-hint-parent>Epsilon-Delta：数学分析的严格化革命</h2></header><div class=entry-content><p>引言：一个困惑的大数学家 1999年，在接受美国数学学会（AMS）的采访时，20世纪最杰出的数学家之一——让-皮埃尔·塞尔（Jean-Pierre Serre）被问及他对数学教育的看法。这位在代数几何、拓扑学和数论领域做出了奠基性贡献的菲尔兹奖得主，给出了一个令人意外的回答：
“我从来没有真正搞懂过 epsilon-delta 语言。我总是通过直观的邻域概念来理解极限和连续性。”
塞尔不是第一个对 epsilon-delta 语言感到困惑的人，也不会是最后一个。每年，数以万计的本科生在第一次接触这套符号系统时，都会经历从困惑到恍然大悟（或持续的困惑）的心路历程。
但这个让塞尔都感到棘手的语言，却成为了现代数学分析的基石。它诞生于19世纪中叶的数学危机，由卡尔·魏尔斯特拉斯（Karl Weierstrass）系统化，并在随后的一个多世纪里，塑造了我们今天理解连续性、极限和微积分的方式。
这就引出了一个根本性的问题：epsilon-delta 语言到底重不重要？它真的必要吗？还是如塞尔所言，直觉的理解就已足够？
让我们一起回溯这段数学史，从牛顿和莱布尼茨的时代开始，穿越第二次数学危机的风暴，最终抵达严格化的彼岸。
第一章：微积分的光荣与混沌 1.1 直观的时代 1687年，牛顿发表了《自然哲学的数学原理》，莱布尼茨也在同一时期独立发展出微积分。这套革命性的工具使得数学家们能够描述运动、变化率和累积量，但其基础却建立在一个模糊的概念之上——无穷小。
让我们看看牛顿是如何计算导数的。对于函数 $f(x) = x^2$，牛顿考虑：
$$ f(x + o) - f(x) = (x + o)^2 - x^2 = 2xo + o^2 $$
其中 $o$ 是一个无穷小量——既不为零（因此可以作除数），又小到可以忽略不计。于是：
$$ \frac{f(x + o) - f(x)}{o} = 2x + o \approx 2x $$
最终的答案是 $2x$，但这个过程充满了逻辑上的暧昧：$o$ 到底是不是零？如果是，为什么要写成 $2x + o$ 而非 $2x$？如果不是，为什么最后又把它"扔掉"了？
大主教乔治·贝克莱（George Berkeley）在1734年的《分析学家》中辛辣地讽刺道：
“这些流数（fluxions，牛顿的术语）是什么？是消逝的增量的速度。那么这些消逝的增量是什么？它们既不是有限的量，也不是无穷小的量，但也不是无。难道我们不能称它们为消逝的量的鬼魂吗？”
贝克莱的批评并非无理取闹。无穷小的概念确实充满了内在的矛盾：它既要参与运算（所以不能是零），又要在最后消失（所以必须被忽略）。这种"既要又要"的逻辑，在当时被称为无穷小的悖论。
1.2 柯西的初步严格化 到了19世纪初，数学家们开始意识到问题的严重性。奥古斯丁-路易·柯西（Augustin-Louis Cauchy）在他的《分析教程》（1821年）中做出了重要的第一步。
...</p></div><footer class=entry-footer><span title='2026-02-01 17:45:20 +0800 CST'>February 1, 2026</span>&nbsp;·&nbsp;<span>5 min</span>&nbsp;·&nbsp;<span>1002 words</span>&nbsp;·&nbsp;<span>s-ai-unix</span></footer><a class=entry-link aria-label="post link to Epsilon-Delta：数学分析的严格化革命" href=https://s-ai-unix.github.io/posts/2026-02-01-epsilon-delta%E6%95%B0%E5%AD%A6%E5%88%86%E6%9E%90%E7%9A%84%E4%B8%A5%E6%A0%BC%E5%8C%96%E9%9D%A9%E5%91%BD/></a></article><article class=post-entry><figure class=entry-cover><img loading=lazy src=https://s-ai-unix.github.io/images/covers/llama3-herd-cover.jpg alt="Llama 3 模型集群架构示意图"></figure><header class=entry-header><h2 class=entry-hint-parent>AI 论文解读系列：The Llama 3 Herd of Models —— 开源大模型的巅峰之作</h2></header><div class=entry-content><p>引言：开源 AI 的黎明 2024 年 7 月 23 日，Meta AI 发布了一篇重磅论文——《The Llama 3 Herd of Models》。这篇论文不仅介绍了一个拥有 4050 亿参数的巨型语言模型，更标志着开源人工智能正式迈入了与闭源巨头分庭抗礼的新纪元。
回想 2022 年底，ChatGPT 的横空出世让整个 AI 领域为之震动。然而，最强大的模型始终被封闭在 OpenAI、Google 等公司的围墙之内。研究者无法探究其内部机理，开发者无法自由定制，这种"黑箱"状态严重阻碍了 AI 技术的普惠发展。
Llama 3 的出现改变了这一切。Meta 不仅开源了完整的模型权重，还详细披露了从数据筛选到训练优化的每一个技术细节。这意味着，任何研究者和开发者都可以在自己的硬件上运行这个媲美 GPT-4 的模型，深入理解它的工作原理，甚至在此基础上进行创新。
本文将带领读者深入这篇 92 页的论文，从数据、规模、复杂性管理三个核心维度，层层剥开 Llama 3 的技术奥秘。
第一章：模型概览 —— “模型群"的设计理念 1.1 为什么叫 “Herd”（群）？ 论文标题中的 “Herd of Models” 并非随意命名。Meta 同时发布了三个不同规模的模型：
模型 参数量 上下文长度 目标场景 Llama 3 8B $8 \times 10^9$ 128K tokens 边缘设备、低延迟推理 Llama 3 70B $70 \times 10^9$ 128K tokens 平衡性能与效率 Llama 3 405B $405 \times 10^9$ 128K tokens 顶级性能、复杂推理 这种"群"策略的核心思想是：用一个旗舰模型（405B）指导整个家族的优化方向，同时让每个成员在特定场景下发挥最大价值。
...</p></div><footer class=entry-footer><span title='2026-01-31 09:30:00 +0800 CST'>January 31, 2026</span>&nbsp;·&nbsp;<span>6 min</span>&nbsp;·&nbsp;<span>1184 words</span>&nbsp;·&nbsp;<span>s-ai-unix</span></footer><a class=entry-link aria-label="post link to AI 论文解读系列：The Llama 3 Herd of Models —— 开源大模型的巅峰之作" href=https://s-ai-unix.github.io/posts/2026-01-31-ai-paper-llama3-herd-of-models/></a></article><article class=post-entry><figure class=entry-cover><img loading=lazy src=https://s-ai-unix.github.io/images/covers/alphazero-cover.jpg alt="AlphaZero 国际象棋棋盘"></figure><header class=entry-header><h2 class=entry-hint-parent>AI 论文解读系列：AlphaZero - 从零开始的自我博弈通用算法</h2></header><div class=entry-content><p>引言：超越人类知识 2017年12月，一个历史性的事件发生在伦敦 DeepMind 的实验室里。一个名为 AlphaZero 的算法，在仅接受游戏规则、没有任何人类棋谱输入的情况下，通过短短 24 小时的自我对弈训练，不仅掌握了国际象棋，还击败了当时世界最强的国际象棋程序 Stockfish。
这不是科幻小说。2018 年 12 月，DeepMind 团队在《科学》杂志上发表了题为"Mastering Chess and Shogi by Self-Play with a General Reinforcement Learning Algorithm"的论文，向世界展示了这一突破。
AlphaZero 的意义远超它击败的对手。它证明了：一个通用的学习算法可以从随机初始状态开始，仅通过自我博弈，就能达到超越人类数千年积累的专业知识水平。这一成就不仅震撼了棋类世界，更深刻地影响了我们对机器学习和人工智能的认知。
第一章：从 AlphaGo 到 AlphaZero 1.1 AlphaGo 的局限 要理解 AlphaZero 的革命性，我们需要先回顾它的前辈 AlphaGo。
AlphaGo 在 2016 年击败了围棋世界冠军李世石，这是人工智能史上的里程碑。但 AlphaGo 的训练过程依赖于人类专家的知识：
监督学习阶段：使用 16 万盘人类高手棋谱训练策略网络 强化学习阶段：在监督学习基础上进一步优化 价值网络：需要人类棋谱数据进行训练 这种对人类数据的依赖带来了几个问题：
知识瓶颈：模型的上限受限于人类棋谱的质量 领域限制：针对围棋设计的架构难以迁移到其他游戏 数据成本：获取高质量人类棋谱需要大量资源 1.2 完全自主学习的愿景 AlphaZero 的核心突破在于：完全抛弃人类棋谱，从零开始学习。
这一想法的理论基础来自强化学习的一个核心洞察：如果环境是确定的，且我们能够模拟环境的动态，那么一个智能体可以通过与环境的交互来学习最优策略，而无需任何外部示范。
在棋类游戏中，这个条件完美满足：
规则完全已知且确定 可以完美模拟任意棋局的发展 胜负结果是明确的奖励信号 图 1：AlphaGo 与 AlphaZero 训练流程对比。AlphaGo 从人类棋谱开始，AlphaZero 则从随机初始化开始纯自我博弈
...</p></div><footer class=entry-footer><span title='2026-01-30 13:00:00 +0800 CST'>January 30, 2026</span>&nbsp;·&nbsp;<span>4 min</span>&nbsp;·&nbsp;<span>702 words</span>&nbsp;·&nbsp;<span>s-ai-unix</span></footer><a class=entry-link aria-label="post link to AI 论文解读系列：AlphaZero - 从零开始的自我博弈通用算法" href=https://s-ai-unix.github.io/posts/2026-01-30-alphazero-paper-interpretation/></a></article><article class=post-entry><figure class=entry-cover><img loading=lazy src=https://s-ai-unix.github.io/images/covers/alphago-cover.jpg alt="AlphaGo 围棋人工智能"></figure><header class=entry-header><h2 class=entry-hint-parent>AI 论文解读系列：AlphaGo - 深度学习与树搜索征服围棋</h2></header><div class=entry-content><p>引言：最后的堡垒 2016年1月27日，伦敦。DeepMind 团队在《自然》杂志上发表了一篇注定要载入人工智能史册的论文：“Mastering the game of Go with deep neural networks and tree search”。这篇论文介绍了 AlphaGo——一个结合了深度神经网络和蒙特卡洛树搜索的计算机围棋程序。
就在论文发表两个月后，AlphaGo 以 4:1 的比分击败了世界围棋冠军李世石。这是人工智能历史上的一个转折点。在此之前，围棋被普遍认为是人工智能难以攻克的"最后的堡垒"。
为什么围棋如此困难？让我们从这个问题开始，逐步揭开 AlphaGo 的神秘面纱。
第一章：围棋——人工智能的终极挑战 1.1 搜索空间的爆炸性增长 围棋起源于中国，已有超过 2500 年的历史。它的规则极其简单：黑白双方轮流在 $19 \times 19$ 的棋盘交叉点上落子，以围地多者为胜。然而，这种简单规则却孕育出了近乎无穷的复杂性。
从数学角度分析，围棋的复杂度体现在两个维度：
分支因子：平均每步有约 250 种合法着法。相比之下，国际象棋约为 35。
对局长度：典型围棋对局约有 150 步。国际象棋约为 80 步。
游戏树的规模可以用 $b^d$ 来估计，其中 $b$ 是分支因子，$d$ 是深度。围棋的游戏树复杂度约为 $250^{150} \approx 10^{360}$，而国际象棋约为 $35^{80} \approx 10^{123}$。
为了理解这个数字的庞大程度，可以对比：
宇宙中估计的原子数量：约 $10^{80}$ 个 可观测宇宙的体积（以普朗克体积计）：约 $10^{185}$ 这意味着，即使使用穷举搜索——即使我们拥有由宇宙中所有原子构成的超级计算机，每颗原子每秒能进行 $10^{20}$ 次运算——也无法在宇宙年龄（约 138 亿年）内遍历完围棋的所有可能局面。
1.2 局面评估的困难 比搜索空间更棘手的是局面评估。在国际象棋中，程序员可以编写明确的评估函数：王的安全性、子力价值、控制中心等。这些启发式规则可以被形式化为可计算的函数。
但在围棋中，局面评估极其微妙。一个看似被围困的棋子群可能在 20 步后"起死回生"；一片看似稳固的领地可能因为一个隐蔽的劫争而化为乌有。人类棋手依靠直觉和"棋感"来判断局面优劣，而这种直觉很难被编码为显式规则。
...</p></div><footer class=entry-footer><span title='2026-01-30 12:30:00 +0800 CST'>January 30, 2026</span>&nbsp;·&nbsp;<span>4 min</span>&nbsp;·&nbsp;<span>667 words</span>&nbsp;·&nbsp;<span>s-ai-unix</span></footer><a class=entry-link aria-label="post link to AI 论文解读系列：AlphaGo - 深度学习与树搜索征服围棋" href=https://s-ai-unix.github.io/posts/2026-01-30-alphago-paper-interpretation/></a></article><article class=post-entry><figure class=entry-cover><img loading=lazy src=https://s-ai-unix.github.io/images/covers/inception-v4-cover.jpg alt="AI 论文解读系列 Inception-v4 Going Deeper with Convolutions"></figure><header class=entry-header><h2 class=entry-hint-parent>AI 论文解读系列：Inception-v4 - Going Deeper with Convolutions</h2></header><div class=entry-content><p>AI 论文解读系列：Inception-v4 - Going Deeper with Convolutions 引言 2016年2月，Google 的 Christian Szegedy 等人在 arXiv 上发表了一篇名为《Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning》的论文。这篇论文不仅是 Inception 系列发展的重要里程碑，更提出了一种革命性的思路：将 Inception 的多尺度特征提取能力与 ResNet 的残差连接相结合。
让我们先回顾一下当时的背景。2015年，ResNet 横空出世，用简单的跳跃连接解决了深层网络的退化问题，将网络深度推向了一百层甚至上千层。与此同时，Inception-v3 以其独特的多分支结构，在计算效率和准确率之间取得了优异的平衡。一个自然的问题浮现出来：**这两种看似迥异的设计哲学能否融合？**如果能将 Inception 的高效特征提取与残差连接的优化优势结合起来，会发生什么？
本文将系统性地解读这篇经典论文，从 Inception 系列的演进脉络出发，深入剖析 Inception-v4 的架构设计原理，探讨 Inception-ResNet 的创新之处，以及残差缩放这一关键技术的数学本质。
图：Inception 系列演进历程与 ImageNet 竞赛 Top-5 错误率变化趋势
第一章：Inception 的演进之路 1.1 Inception-v1：多尺度特征提取的开创 要理解 Inception-v4，我们需要先回到2014年的 Inception-v1（GoogLeNet）。当时，深度学习领域的主流思路是"越深越好"——AlexNet 有8层，VGGNet 堆到了19层。但 Google 的研究者们提出了一个不同的观点：与其简单地堆叠相同的层，不如让网络自己选择如何组合不同尺度的特征。
Inception 模块的核心思想可以用一个简单的问题来概括：当我们观察一张图像时，我们究竟需要多大的感受野？
识别一只猫的脸，可能只需要一个 $3 \times 3$ 的区域就能看清它的眼睛和鼻子 但要判断这是一只完整卧着的猫，可能需要一个 $5 \times 5$ 的区域来捕捉整体轮廓 而对于更宏观的场景理解，甚至需要更大的视野 Inception 模块的解决方案是并行使用不同大小的卷积核，让网络自己学习每种尺度的权重。一个典型的 Inception 模块包含四个分支：
...</p></div><footer class=entry-footer><span title='2026-01-30 12:30:00 +0800 CST'>January 30, 2026</span>&nbsp;·&nbsp;<span>7 min</span>&nbsp;·&nbsp;<span>1455 words</span>&nbsp;·&nbsp;<span>s-ai-unix</span></footer><a class=entry-link aria-label="post link to AI 论文解读系列：Inception-v4 - Going Deeper with Convolutions" href=https://s-ai-unix.github.io/posts/2026-01-30-ai-%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB%E7%B3%BB%E5%88%97-inception-v4-going-deeper-with-convolutions/></a></article><article class=post-entry><figure class=entry-cover><img loading=lazy src=https://s-ai-unix.github.io/images/covers/bert-cover.jpg alt="BERT 自然语言处理"></figure><header class=entry-header><h2 class=entry-hint-parent>AI 论文解读系列：BERT - 预训练深度双向 Transformer 的革命</h2></header><div class=entry-content><p>引言：语言理解的瓶颈 2018年10月，Google AI Language 团队发布了一篇名为"BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"的论文。这篇论文及其开源代码在 NLP 领域引发了一场革命。
在 BERT 出现之前，自然语言处理面临一个根本性难题：如何让机器真正理解语言的上下文含义？传统的语言模型只能从左到右（或从右到左）单向处理文本，就像阅读时只能看到当前词之前的所有词，却无法看到之后的词。这种"管中窥豹"的方式严重限制了模型的理解能力。
BERT 的核心突破在于它提出了深度双向表示的概念——通过一种新的预训练目标，让模型同时考虑词语的左右上下文，从而获得更丰富、更准确的语言理解能力。
本文将深入解读 BERT 的技术原理，从其核心思想出发，逐步揭示它如何改变了 NLP 的研究范式。
第一章：从上下文说起——为什么双向如此重要 1.1 一词多义的困境 自然语言的复杂性很大程度上源于一词多义。同一个词在不同的上下文中可能有完全不同的含义。考虑这两个句子：
“他在银行工作。"（金融机构） “河边的银行种满了柳树。"（河岸）
对于人类来说，区分这两个"银行"的含义轻而易举，因为我们能够同时看到这个词左右两侧的上下文。但对于单向语言模型来说，当它处理到"银行"这个词时，只能看到"他在"或"河边的”，无法获得足够的信息来做出准确判断。
1.2 传统语言模型的局限 传统的语言模型采用自回归（Autoregressive）方式建模，即基于前文预测下一个词：
$$ P(w_1, w_2, \ldots, w_n) = \prod_{i=1}^{n} P(w_i | w_1, \ldots, w_{i-1}) $$
GPT 等模型采用了这种从左到右的处理方式。虽然这种架构在生成任务（如机器翻译、文本摘要）中表现良好，但对于需要深度理解上下文的任务（如问答、情感分析）则存在天然的局限性。
另一种尝试是浅层双向，如 ELMo。它分别训练一个从左到右和一个从右到左的语言模型，然后将两者的表示拼接起来。这种方法虽然考虑了双向信息，但两个方向的表示是独立计算的，而非真正的深度交互。
图 1：语言模型架构对比。左图为单向模型只能看到左侧上下文，右图为 BERT 双向模型可以看到完整上下文
第二章：Transformer——BERT 的基石 在深入 BERT 之前，我们需要理解它的基础架构：Transformer。BERT 完全基于 Transformer 的 Encoder 部分构建。
2.1 注意力机制的魔力 Transformer 的核心是自注意力机制（Self-Attention）。与传统的循环神经网络（RNN）不同，自注意力允许模型直接建模序列中任意两个位置之间的关系，无论它们相距多远。
...</p></div><footer class=entry-footer><span title='2026-01-30 12:00:00 +0800 CST'>January 30, 2026</span>&nbsp;·&nbsp;<span>4 min</span>&nbsp;·&nbsp;<span>656 words</span>&nbsp;·&nbsp;<span>s-ai-unix</span></footer><a class=entry-link aria-label="post link to AI 论文解读系列：BERT - 预训练深度双向 Transformer 的革命" href=https://s-ai-unix.github.io/posts/2026-01-30-bert-paper-interpretation/></a></article><article class=post-entry><figure class=entry-cover><img loading=lazy src=https://s-ai-unix.github.io/images/covers/seq2seq-cover.jpg alt="Seq2Seq 神经网络抽象图"></figure><header class=entry-header><h2 class=entry-hint-parent>AI 论文解读系列：Seq2Seq--从序列到序列的革命</h2></header><div class=entry-content><p>引言：翻译的困境 想象一下，你正在学习一门外语。当你听到一句法语 “Bonjour le monde” 时，你的大脑是如何将其转化为英语 “Hello world” 的？
这不是简单的逐词替换。“Bonjour” 对应 “Hello”，但 “le monde” 是 “the world” 的倒序。词序不同，语法结构不同，甚至可能一个词对应多个词。传统的机器翻译系统使用基于规则的方法或统计模型，需要大量的人工特征工程和复杂的对齐算法。
2014年，Ilya Sutskever、Oriol Vinyals 和 Quoc Le 在 Google 发表了一篇改变游戏规则的论文：“Sequence to Sequence Learning with Neural Networks”。他们提出的 Seq2Seq 架构，用一个统一的神经网络模型取代了复杂的流水线，让机器翻译的准确率跃升到了新的高度。
但这篇论文的意义远不止于翻译。它开创了序列转导（Sequence Transduction）这一全新的学习范式，为后来的注意力机制、Transformer 乃至大语言模型奠定了基础。
第一章：序列转导问题 1.1 什么让序列数据特殊 在深入 Seq2Seq 之前，让我们先理解序列数据的本质。
传统的机器学习任务，比如图像分类或房价预测，输入和输出的维度是固定的。一张图片永远是 $224 \times 224 \times 3$ 的像素矩阵，一套房子的特征永远是卧室数、面积、位置等固定字段。
但序列数据不同：
一句话可能有 5 个词，也可能有 50 个词 源语言和目标语言的词序可能不同 一个概念可能用一个词表达，也可能用多个词 上图展示了一个典型的机器翻译场景。输入序列 “Hello world this is a test” 需要被转换为 “Bonjour monde ceci est un test”。注意两个关键挑战：
...</p></div><footer class=entry-footer><span title='2026-01-30 09:00:00 +0800 CST'>January 30, 2026</span>&nbsp;·&nbsp;<span>4 min</span>&nbsp;·&nbsp;<span>763 words</span>&nbsp;·&nbsp;<span>s-ai-unix</span></footer><a class=entry-link aria-label="post link to AI 论文解读系列：Seq2Seq--从序列到序列的革命" href=https://s-ai-unix.github.io/posts/2026-01-30-seq2seq-paper-explained/></a></article><footer class=page-footer><nav class=pagination><a class=next href=https://s-ai-unix.github.io/posts/page/2/>Next&nbsp;&nbsp;»</a></nav></footer></main><footer class=footer><span>&copy; 2026 <a href=https://s-ai-unix.github.io/>s-ai-unix's Blog</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
<a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script>(function(){"use strict";function e(){var e=document.querySelectorAll("p, li, td, div, span, h1, h2, h3, h4, h5, h6, ol, ul");e.forEach(function(e){if(e.classList.contains("classical-quote-container")||e.classList.contains("quote-text")||e.closest(".classical-quote-container"))return;var t,n=e.innerHTML,s=!1;for(n.indexOf("<em>")!==-1&&(t=n.replace(/\$([^$]*?)<em>([^<]+?)<\/em>([^$]*?)\$/g,function(e,t,n,s){return/^[\d.,]+$/.test((t+n+s).replace(/[.,]/g,""))?e:"$"+t+"_"+n+s+"$"}),t=t.replace(/\$\$([^$]*?)<em>([^<]+?)<\/em>([^$]*?)\$\$/g,function(e,t,n,s){return"$$"+t+"_"+n+s+"$$"}),t!==n&&(n=t,s=!0)),n.indexOf("</em>")!==-1&&(t=n.replace(/\$([^$]*?)<\/em>([^$]*?)\$/g,function(e,t,n){return"$"+t+"_{"+n+"$"}),t=t.replace(/\$\$([^$]*?)<\/em>([^$]*?)\$\$/g,function(e,t,n){return"$$"+t+"_{"+n+"$$"}),t!==n&&(n=t,s=!0)),n.indexOf("<em>$")!==-1&&(t=n.replace(/<em>\$/g,"$"),t!==n&&(n=t,s=!0)),n.indexOf("</em>$")!==-1&&(t=n.replace(/<\/em>\$/g,"$"),t!==n&&(n=t,s=!0));n.indexOf("<em>")!==-1&&n.indexOf("</em>")!==-1;){if(t=n.replace(/\$([^$]*?)<em>([^<]+?)<\/em>([^$]*?)\$/g,function(e,t,n,s){return/^[\d.,]+$/.test((t+n+s).replace(/[.,]/g,""))?e:"$"+t+"_"+n+s+"$"}),t=t.replace(/\$\$([^$]*?)<em>([^<]+?)<\/em>([^$]*?)\$\$/g,function(e,t,n,s){return"$$"+t+"_"+n+s+"$$"}),t===n)break;n=t,s=!0}n.indexOf("_{")!==-1&&(t=n.replace(/_{/g,"_{"),t!==n&&(n=t,s=!0)),n.indexOf("}_")!==-1&&(t=n.replace(/}_/g,"}"),t!==n&&(n=t,s=!0)),n.includes("</em>{")&&(t=n.replace(/\\mathbf\{(W|x|y|z)\}<\/em>\{\\mathrm\{([a-z]+)\}\}/g,"\\mathbf{$1}_{\\mathrm{$2}}"),t=t.replace(/([LHf])<\/em>\{\\mathrm\{([a-z]+)\}\}/g,"$1_{\\mathrm{$2}}"),t=t.replace(/\\nabla ([LHf])<\/em>\{\\mathrm\{([a-z]+)\}\}/g,`\\nabla $1_{\\mathrm{$2}}`),t=t.replace(/([A-Z])<\/em>\{\\mathrm\{([a-z]+)\}\}/g,"$1_{\\mathrm{$2}}"),t!==n&&(n=t,s=!0)),n.includes("<em>{\\mathrm{")&&(t=n.replace(/\\mathbf\{(W|x|y|z)\}<em>\{\\mathrm\{([a-z]+)\}\}/g,"\\mathbf{$1}_{\\mathrm{$2}}"),t=t.replace(/([LHf])<em>\{\\mathrm\{([a-z]+)\}\}/g,"$1_{\\mathrm{$2}}"),t=t.replace(/\\nabla ([LHf])<em>\{\\mathrm\{([a-z]+)\}\}/g,`\\nabla $1_{\\mathrm{$2}}`),t=t.replace(/([A-Z])<em>\{\\mathrm\{([a-z]+)\}\}/g,"$1_{\\mathrm{$2}}"),t!==n&&(n=t,s=!0)),(n.includes("</em>")||n.includes("<em>"))&&(t=n.replace(/(\$[^$]*?)<em>([^$]*?)<\/em>/g,"$1_{$2}"),t=t.replace(/(\$\$[^$]*?)<em>([^$]*?)<\/em>/g,"$1_{$2}"),t=t.replace(/(\$[^$]*?)<em>/g,"$1"),t=t.replace(/<em>([^$]*?\$)/g,"$1"),t=t.replace(/(\$[^$]*?)<\/em>/g,"$1"),t=t.replace(/<\/em>([^$]*?\$)/g,"$1"),t!==n&&(n=t,s=!0)),n.indexOf("\\\\")!==-1&&(t=n.replace(/(\$\{1,2\})([^$]*?)(\$\{1,2\})/g,function(e,t,n,s){for(;n.indexOf("\\\\")!==-1;)n=n.replace(/\\\\/g,"\\");return t+n+s}),t!==n&&(n=t,s=!0)),s&&(e.innerHTML=n)})}window.MathJax={tex:{inlineMath:[["$","$"]],displayMath:[["$$","$$"]],processEscapes:!0,processEnvironments:!0,tags:"ams",packages:{"[+]":["noerrors","noundefined","boldsymbol"]},macros:{oiint:"\\mathop{∯}",oiiint:"\\mathop{∰}"}},options:{skipHtmlTags:["script","noscript","style","textarea","pre","code"]},startup:{pageReady:function(){return e(),MathJax.startup.defaultPageReady().then(function(){console.log("MathJax formulas rendered successfully")})}}}})()</script><script src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script><link rel=stylesheet href=/css/mermaid-custom.css><script src=/js/mermaid-converter.js></script><script type=module>
  import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs';

  
  setTimeout(() => {
    mermaid.initialize({
      startOnLoad: true,
      theme: 'base',
      themeVariables: {
        primaryColor: '#e3f2fd',
        primaryTextColor: '#1565c0',
        primaryBorderColor: '#2196f3',
        lineColor: '#42a5f5',
        secondaryColor: '#f3e5f5',
        tertiaryColor: '#fff9c4',
        background: '#ffffff',
        mainBkg: '#ffffff',
        nodeBorder: '#2196f3',
        clusterBkg: '#ffffff',
        clusterBorder: '#e0e0e0',
        titleColor: '#1565c0',
        edgeLabelBackground: '#fafafa',
      },
      securityLevel: 'loose',
    });
  }, 100);
</script><script src=/js/toc.js></script><script>let menu=document.getElementById("menu");if(menu){const e=localStorage.getItem("menu-scroll-position");e&&(menu.scrollLeft=parseInt(e,10)),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}}document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{const e=document.querySelector("html");e.dataset.theme==="dark"?(e.dataset.theme="light",localStorage.setItem("pref-theme","light")):(e.dataset.theme="dark",localStorage.setItem("pref-theme","dark"))})</script><script>(function(){"use strict";function e(){var e=document.querySelectorAll("p, li, td, div, span, h1, h2, h3, h4, h5, h6, ol, ul");e.forEach(function(e){if(e.classList.contains("classical-quote-container")||e.classList.contains("quote-text")||e.closest(".classical-quote-container"))return;var t,n=e.innerHTML,s=!1;for(n.indexOf("<em>")!==-1&&(t=n.replace(/\$([^$]*?)<em>([^<]+?)<\/em>([^$]*?)\$/g,function(e,t,n,s){return/^[\d.,]+$/.test((t+n+s).replace(/[.,]/g,""))?e:"$"+t+"_"+n+s+"$"}),t=t.replace(/\$\$([^$]*?)<em>([^<]+?)<\/em>([^$]*?)\$\$/g,function(e,t,n,s){return"$$"+t+"_"+n+s+"$$"}),t!==n&&(n=t,s=!0)),n.indexOf("</em>")!==-1&&(t=n.replace(/\$([^$]*?)<\/em>([^$]*?)\$/g,function(e,t,n){return"$"+t+"_{"+n+"$"}),t=t.replace(/\$\$([^$]*?)<\/em>([^$]*?)\$\$/g,function(e,t,n){return"$$"+t+"_{"+n+"$$"}),t!==n&&(n=t,s=!0)),n.indexOf("<em>$")!==-1&&(t=n.replace(/<em>\$/g,"$"),t!==n&&(n=t,s=!0)),n.indexOf("</em>$")!==-1&&(t=n.replace(/<\/em>\$/g,"$"),t!==n&&(n=t,s=!0));n.indexOf("<em>")!==-1&&n.indexOf("</em>")!==-1;){if(t=n.replace(/\$([^$]*?)<em>([^<]+?)<\/em>([^$]*?)\$/g,function(e,t,n,s){return/^[\d.,]+$/.test((t+n+s).replace(/[.,]/g,""))?e:"$"+t+"_"+n+s+"$"}),t=t.replace(/\$\$([^$]*?)<em>([^<]+?)<\/em>([^$]*?)\$\$/g,function(e,t,n,s){return"$$"+t+"_"+n+s+"$$"}),t===n)break;n=t,s=!0}n.indexOf("_{")!==-1&&(t=n.replace(/_{/g,"_{"),t!==n&&(n=t,s=!0)),n.indexOf("}_")!==-1&&(t=n.replace(/}_/g,"}"),t!==n&&(n=t,s=!0)),n.includes("</em>{")&&(t=n.replace(/\\mathbf\{(W|x|y|z)\}<\/em>\{\\mathrm\{([a-z]+)\}\}/g,"\\mathbf{$1}_{\\mathrm{$2}}"),t=t.replace(/([LHf])<\/em>\{\\mathrm\{([a-z]+)\}\}/g,"$1_{\\mathrm{$2}}"),t=t.replace(/\\nabla ([LHf])<\/em>\{\\mathrm\{([a-z]+)\}\}/g,`\\nabla $1_{\\mathrm{$2}}`),t=t.replace(/([A-Z])<\/em>\{\\mathrm\{([a-z]+)\}\}/g,"$1_{\\mathrm{$2}}"),t!==n&&(n=t,s=!0)),n.includes("<em>{\\mathrm{")&&(t=n.replace(/\\mathbf\{(W|x|y|z)\}<em>\{\\mathrm\{([a-z]+)\}\}/g,"\\mathbf{$1}_{\\mathrm{$2}}"),t=t.replace(/([LHf])<em>\{\\mathrm\{([a-z]+)\}\}/g,"$1_{\\mathrm{$2}}"),t=t.replace(/\\nabla ([LHf])<em>\{\\mathrm\{([a-z]+)\}\}/g,`\\nabla $1_{\\mathrm{$2}}`),t=t.replace(/([A-Z])<em>\{\\mathrm\{([a-z]+)\}\}/g,"$1_{\\mathrm{$2}}"),t!==n&&(n=t,s=!0)),(n.includes("</em>")||n.includes("<em>"))&&(t=n.replace(/(\$[^$]*?)<em>([^$]*?)<\/em>/g,"$1_{$2}"),t=t.replace(/(\$\$[^$]*?)<em>([^$]*?)<\/em>/g,"$1_{$2}"),t=t.replace(/(\$[^$]*?)<em>/g,"$1"),t=t.replace(/<em>([^$]*?\$)/g,"$1"),t=t.replace(/(\$[^$]*?)<\/em>/g,"$1"),t=t.replace(/<\/em>([^$]*?\$)/g,"$1"),t!==n&&(n=t,s=!0)),n.indexOf("\\\\")!==-1&&(t=n.replace(/(\$\{1,2\})([^$]*?)(\$\{1,2\})/g,function(e,t,n,s){for(;n.indexOf("\\\\")!==-1;)n=n.replace(/\\\\/g,"\\");return t+n+s}),t!==n&&(n=t,s=!0)),s&&(e.innerHTML=n)})}window.MathJax={tex:{inlineMath:[["$","$"]],displayMath:[["$$","$$"]],processEscapes:!0,processEnvironments:!0,tags:"ams",packages:{"[+]":["noerrors","noundefined","boldsymbol"]},macros:{oiint:"\\mathop{∯}",oiiint:"\\mathop{∰}"}},options:{skipHtmlTags:["script","noscript","style","textarea","pre","code"]},startup:{pageReady:function(){return e(),MathJax.startup.defaultPageReady().then(function(){console.log("MathJax formulas rendered successfully")})}}}})()</script><script src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script><link rel=stylesheet href=/css/mermaid-custom.css><script src=/js/mermaid-converter.js></script><script type=module>
  import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs';

  
  setTimeout(() => {
    mermaid.initialize({
      startOnLoad: true,
      theme: 'base',
      themeVariables: {
        primaryColor: '#e3f2fd',
        primaryTextColor: '#1565c0',
        primaryBorderColor: '#2196f3',
        lineColor: '#42a5f5',
        secondaryColor: '#f3e5f5',
        tertiaryColor: '#fff9c4',
        background: '#ffffff',
        mainBkg: '#ffffff',
        nodeBorder: '#2196f3',
        clusterBkg: '#ffffff',
        clusterBorder: '#e0e0e0',
        titleColor: '#1565c0',
        edgeLabelBackground: '#fafafa',
      },
      securityLevel: 'loose',
    });
  }, 100);
</script><script src=/js/toc.js></script></body></html>
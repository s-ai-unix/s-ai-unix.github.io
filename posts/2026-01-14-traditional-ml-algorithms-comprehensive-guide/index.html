<!doctype html><html lang=en dir=auto data-theme=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>传统机器学习与统计学习算法：从理论到实践的完整指南 | s-ai-unix's Blog</title><meta name=keywords content="机器学习,算法,数学史,综述"><meta name=description content="本文全面回顾传统机器学习和统计学习算法的发展历程、数学原理、应用场景及未来前景，涵盖从线性回归到深度学习之前的关键算法。"><meta name=author content="s-ai-unix"><link rel=canonical href=https://s-ai-unix.github.io/posts/2026-01-14-traditional-ml-algorithms-comprehensive-guide/><link crossorigin=anonymous href=/assets/css/stylesheet.0833aff7e1cf567ecfb9755701ee95a80535f671e2e1a0a770c9bc20a0a7b5bb.css integrity="sha256-CDOv9+HPVn7PuXVXAe6VqAU19nHi4aCncMm8IKCntbs=" rel="preload stylesheet" as=style><link rel=icon href=https://s-ai-unix.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://s-ai-unix.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://s-ai-unix.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://s-ai-unix.github.io/apple-touch-icon.png><link rel=mask-icon href=https://s-ai-unix.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://s-ai-unix.github.io/posts/2026-01-14-traditional-ml-algorithms-comprehensive-guide/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51);color-scheme:dark}.list{background:var(--theme)}.toc{background:var(--entry)}}@media(prefers-color-scheme:light){.list::-webkit-scrollbar-thumb{border-color:var(--code-bg)}}</style></noscript><script>localStorage.getItem("pref-theme")==="dark"?document.querySelector("html").dataset.theme="dark":localStorage.getItem("pref-theme")==="light"?document.querySelector("html").dataset.theme="light":window.matchMedia("(prefers-color-scheme: dark)").matches?document.querySelector("html").dataset.theme="dark":document.querySelector("html").dataset.theme="light"</script><meta property="og:url" content="https://s-ai-unix.github.io/posts/2026-01-14-traditional-ml-algorithms-comprehensive-guide/"><meta property="og:site_name" content="s-ai-unix's Blog"><meta property="og:title" content="传统机器学习与统计学习算法：从理论到实践的完整指南"><meta property="og:description" content="本文全面回顾传统机器学习和统计学习算法的发展历程、数学原理、应用场景及未来前景，涵盖从线性回归到深度学习之前的关键算法。"><meta property="og:locale" content="zh-cn"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2026-01-14T08:18:25+08:00"><meta property="article:modified_time" content="2026-01-14T08:18:25+08:00"><meta property="article:tag" content="机器学习"><meta property="article:tag" content="算法"><meta property="article:tag" content="数学史"><meta property="article:tag" content="综述"><meta property="og:image" content="https://s-ai-unix.github.io/images/covers/photo-1509228468518-180dd4864904.jpg"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://s-ai-unix.github.io/images/covers/photo-1509228468518-180dd4864904.jpg"><meta name=twitter:title content="传统机器学习与统计学习算法：从理论到实践的完整指南"><meta name=twitter:description content="本文全面回顾传统机器学习和统计学习算法的发展历程、数学原理、应用场景及未来前景，涵盖从线性回归到深度学习之前的关键算法。"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://s-ai-unix.github.io/posts/"},{"@type":"ListItem","position":2,"name":"传统机器学习与统计学习算法：从理论到实践的完整指南","item":"https://s-ai-unix.github.io/posts/2026-01-14-traditional-ml-algorithms-comprehensive-guide/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"传统机器学习与统计学习算法：从理论到实践的完整指南","name":"传统机器学习与统计学习算法：从理论到实践的完整指南","description":"本文全面回顾传统机器学习和统计学习算法的发展历程、数学原理、应用场景及未来前景，涵盖从线性回归到深度学习之前的关键算法。","keywords":["机器学习","算法","数学史","综述"],"articleBody":"引言：从统计学到机器学习 1956年，达特茅斯会议上正式提出了\"人工智能\"这个词。但在那之前的一百年里，统计学家们已经在用数学工具从数据中提取规律。高斯在1809年就用最小二乘法解决了天文学中的观测数据拟合问题，这可以看作是最早的机器学习算法。\n机器学习和统计学习，本质上是一回事：从数据中学习规律，并用这些规律做出预测。只是出发点略有不同——统计学家关注估计的可靠性和显著性检验，而计算机科学家更关心算法的计算效率和泛化能力。\n当我们说\"传统机器学习\"时，指的是深度学习时代之前的那些经典算法。这些算法虽然不像神经网络那样\"万能\"，但在数据量有限、需要可解释性的场景下，依然发挥着不可替代的作用。\n第一章：统计学习的理论基础 1.1 学习问题的数学框架 假设我们有一个数据集 $D = {(x_1, y_1), (x_2, y_2), \\ldots, (x_n, y_n)}$，其中 $x_i \\in \\mathcal{X}$ 是输入（特征），$y_i \\in \\mathcal{Y}$ 是输出（标签）。我们的目标是找到一个函数 $f: \\mathcal{X} \\to \\mathcal{Y}$，使得对于新的输入 $x$，$f(x)$ 能准确预测对应的 $y$。\n但在统计学习的框架下，我们还需要引入概率论的概念。假设数据是按照某个未知的联合分布 $P(X,Y)$ 生成的，我们的目标是学习一个决策函数 $f$，使得期望风险最小化：\n$$R(f) = \\mathbb{E}_{(X,Y) \\sim P}[L(Y, f(X))]$$\n其中 $L$ 是损失函数。对于回归问题，常用平方损失；对于分类问题，常用0-1损失或交叉熵损失。\n问题在于：我们不知道 $P(X,Y)$，无法直接计算 $R(f)$。我们只能用经验风险（Empirical Risk）来近似：\n$$\\hat{R}(f) = \\frac{1}{n}\\sum_{i=1}^n L(y_i, f(x_i))$$\n这就是经验风险最小化（ERM）的基本思想。但直接最小化经验风险会导致过拟合（overfitting）。\n1.2 偏差-方差权衡 这是统计学习中最重要的概念之一。模型的预测误差可以分解为三个部分：\n$$\\mathbb{E}[(y - \\hat{f}(x))^2] = \\text{Bias}[\\hat{f}(x)]^2 + \\text{Var}[\\hat{f}(x)] + \\sigma^2$$\n其中：\n$\\text{Bias}[\\hat{f}(x)] = \\mathbb{E}[\\hat{f}(x)] - f^{\\ast}(x)$：模型预测的期望与真实值的差距 $\\text{Var}[\\hat{f}(x)] = \\mathbb{E}[(\\hat{f}(x) - \\mathbb{E}[\\hat{f}(x)])^2]$：模型预测的方差 $\\sigma^2$：不可约误差（数据本身的噪声） 偏差反映了模型的\"假设强度\"。如果模型过于简单（比如用线性模型拟合高度非线性的数据），会产生高偏差，导致欠拟合。\n方差反映了模型对数据波动的敏感程度。如果模型过于复杂（比如高阶多项式拟合），会记住训练数据的噪声，产生高方差，导致过拟合。\n偏差-方差权衡的核心思想是：我们需要在模型复杂度之间找到一个平衡点。\n1.3 正则化：控制模型复杂度的数学工具 为了防止过拟合，我们在目标函数中加入正则化项。最常见的形式是：\n$$\\min_f \\frac{1}{n}\\sum_{i=1}^n L(y_i, f(x_i)) + \\lambda \\Omega(f)$$\n其中 $\\Omega(f)$ 是正则化项，$\\lambda \\geq 0$ 是超参数。\nL2正则化（岭回归）： $$\\Omega(f) = |w|2^2 = \\sum{j=1}^d w_j^2$$\nL2正则化倾向于让权重变小但不为零，相当于对权重施加了高斯先验。\nL1正则化（Lasso）： $$\\Omega(f) = |w|1 = \\sum{j=1}^d |w_j|$$\nL1正则化倾向于产生稀疏解（很多权重为零），相当于对权重施加了拉普拉斯先验。\n1.4 泛化误差与PAC学习框架 一个关键问题是：经验风险最小化是否能保证泛化能力？PAC（Probably Approximately Correct）学习框架给出了理论保证。\n设 $\\mathcal{F}$ 是一个假设类，如果对于任意 $\\epsilon, \\delta \u003e 0$，存在样本量 $n(\\epsilon, \\delta)$，使得当 $n \\geq n(\\epsilon, \\delta)$ 时，经验风险最小化算法以至少 $1-\\delta$ 的概率找到一个假设 $f$，满足 $R(f) - R(f^{\\ast}) \\leq \\epsilon$，则称 $\\mathcal{F}$ 是PAC可学习的。\n根据VC维理论，经验风险与期望风险的差距有如下界限：\n$$R(f) \\leq \\hat{R}(f) + \\mathcal{O}\\left(\\sqrt{\\frac{d \\log(n/d) + \\log(1/\\delta)}{n}}\\right)$$\n其中 $d$ 是VC维。这告诉我们：模型复杂度越高，需要的样本量就越大。\n第二章：经典监督学习算法 2.1 线性回归：统计学习的起点 2.1.1 基本模型 线性回归是最简单的回归模型，假设输出 $y$ 是输入 $x$ 的线性函数：\n$$y = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\cdots + \\beta_p x_p + \\epsilon$$\n其中 $\\epsilon \\sim \\mathcal{N}(0, \\sigma^2)$ 是噪声项。用矩阵表示：\n$$Y = X\\beta + \\epsilon$$\n其中 $X$ 是 $n \\times (p+1)$ 的设计矩阵，$\\beta = (\\beta_0, \\beta_1, \\ldots, \\beta_p)^T$。\n2.1.2 最小二乘估计 最小二乘法的目标是最小化残差平方和：\n$$\\min_\\beta |Y - X\\beta|_2^2$$\n这是一个凸优化问题。对 $\\beta$ 求导并令导数为零：\n$$\\frac{\\partial}{\\partial \\beta} |Y - X\\beta|_2^2 = -2X^T(Y - X\\beta) = 0$$\n解这个方程，得到正规方程（Normal Equation）：\n$$X^TX\\beta = X^TY$$\n如果 $X^TX$ 可逆，则唯一解为：\n$$\\hat{\\beta} = (X^TX)^{-1}X^TY$$\n这就是普通最小二乘估计（OLS）。\n几何解释：$\\hat{Y} = X\\hat{\\beta}$ 是 $Y$ 在 $X$ 的列空间上的正交投影。残差 $e = Y - \\hat{Y}$ 与 $X$ 的每一列都正交，即 $X^Te = 0$。\n2.1.3 统计性质 如果误差项满足高斯-马尔可夫假设（$\\mathbb{E}[\\epsilon] = 0$，$\\text{Cov}(\\epsilon) = \\sigma^2 I_n$），那么OLS估计量具有以下性质：\n无偏性： $$\\mathbb{E}[\\hat{\\beta}] = \\beta$$\n证明： $$\\hat{\\beta} = (X^TX)^{-1}X^TY = (X^TX)^{-1}X^T(X\\beta + \\epsilon) = \\beta + (X^TX)^{-1}X^T\\epsilon$$ $$\\mathbb{E}[\\hat{\\beta}] = \\beta + (X^TX)^{-1}X^T\\mathbb{E}[\\epsilon] = \\beta$$\n有效性（BLUE）：在所有线性无偏估计中，OLS的方差最小。\n协方差矩阵： $$\\text{Cov}(\\hat{\\beta}) = \\sigma^2 (X^TX)^{-1}$$\n2.1.4 岭回归与Lasso 当 $X^TX$ 接近奇异矩阵时（多重共线性），OLS估计会变得不稳定。正则化是解决方案。\n岭回归（Ridge Regression）： $$\\min_\\beta |Y - X\\beta|_2^2 + \\lambda |\\beta|_2^2$$\n解为： $$\\hat{\\beta}_{\\text{ridge}} = (X^TX + \\lambda I)^{-1}X^TY$$\n添加 $\\lambda I$ 确保矩阵可逆。\nLasso： $$\\min_\\beta \\frac{1}{2n}|Y - X\\beta|_2^2 + \\lambda |\\beta|_1$$\nLasso的优化问题是非光滑的（由于L1范数的绝对值），没有解析解，需要用坐标下降法（Coordinate Descent）求解。\n重要差异：Lasso可以进行变量选择（稀疏性），而岭回归不能。这是因为L1范数的几何形状是菱形，更容易与等值线在坐标轴上相交。\n2.1.5 应用场景 房价预测：根据房屋面积、房间数、地段等特征预测房价 金融分析：根据公司财务指标预测股票收益率 医疗研究：根据患者生理指标预测疾病风险 案例：波士顿房价数据集\n特征： crim（犯罪率）, zn（住宅用地比例）, indus（非零售商业用地比例）, chas（是否临河）, nox（氮氧化物浓度）, rm（平均房间数）, age（房龄）, dis（到就业中心距离）, rad（高速可达性）, tax（房产税）, ptratio（师生比）, black（黑人比例）, lstat（低收入人群比例） 目标： medv（房屋中位价，单位千美元） 岭回归可以帮助处理多重共线性问题（比如zn和indus高度相关）。\n2.2 逻辑回归：分类问题的经典方法 2.2.1 从线性回归到逻辑回归 为什么不能直接用线性回归做分类？如果 $y \\in {0, 1}$，线性回归会预测任意实数，而我们需要概率输出。\n逻辑回归引入了Sigmoid函数（又称Logistic函数）： $$\\sigma(z) = \\frac{1}{1 + e^{-z}}$$\n模型假设： $$P(y=1|x) = \\sigma(w^Tx + b) = \\frac{1}{1 + e^{-(w^Tx + b)}}$$\n$$P(y=0|x) = 1 - P(y=1|x) = \\frac{e^{-(w^Tx + b)}}{1 + e^{-(w^Tx + b)}}$$\nSigmoid函数的性质：\n$\\sigma(0) = 0.5$ $\\sigma(+\\infty) \\to 1$，$\\sigma(-\\infty) \\to 0$ $\\sigma’(z) = \\sigma(z)(1 - \\sigma(z))$ 2.2.2 似然函数与极大似然估计 给定数据集 ${(x_i, y_i)}_{i=1}^n$，其中 $y_i \\in {0, 1}$，似然函数为：\n$$L(w, b) = \\prod_{i=1}^n P(y_i|x_i) = \\prod_{i=1}^n [\\sigma(w^Tx_i + b)]^{y_i} [1 - \\sigma(w^Tx_i + b)]^{1 - y_i}$$\n取对数，得到对数似然：\n$$\\ell(w, b) = \\sum_{i=1}^n [y_i \\log \\sigma(z_i) + (1 - y_i) \\log(1 - \\sigma(z_i))]$$\n其中 $z_i = w^Tx_i + b$。\n极大似然估计： $$\\max_{w, b} \\ell(w, b)$$\n等价于最小化负对数似然（也是交叉熵损失）： $$\\min_{w, b} J(w, b) = -\\sum_{i=1}^n [y_i \\log \\sigma(z_i) + (1 - y_i) \\log(1 - \\sigma(z_i))]$$\n2.2.3 梯度下降法 对 $J$ 求梯度： $$\\frac{\\partial J}{\\partial w_j} = -\\sum_{i=1}^n [y_i - \\sigma(z_i)] x_{i,j}$$\n$$\\frac{\\partial J}{\\partial b} = -\\sum_{i=1}^n [y_i - \\sigma(z_i)]$$\n梯度下降更新规则： $$w_j := w_j - \\eta \\frac{\\partial J}{\\partial w_j} = w_j + \\eta \\sum_{i=1}^n [y_i - \\sigma(z_i)] x_{i,j}$$\n$$b := b - \\eta \\frac{\\partial J}{\\partial b} = b + \\eta \\sum_{i=1}^n [y_i - \\sigma(z_i)]$$\n其中 $\\eta$ 是学习率。\n随机梯度下降（SGD）：每次只使用一个样本更新参数，计算更快但方差更大。\n小批量梯度下降（Mini-batch GD）：每次使用一批样本，介于全量和单个样本之间。\n2.2.4 正则化逻辑回归 为防止过拟合，加入L2正则化：\n$$J(w, b) = -\\sum_{i=1}^n [y_i \\log \\sigma(z_i) + (1 - y_i) \\log(1 - \\sigma(z_i))] + \\frac{\\lambda}{2} |w|_2^2$$\n梯度变为： $$\\frac{\\partial J}{\\partial w_j} = -\\sum_{i=1}^n [y_i - \\sigma(z_i)] x_{i,j} + \\lambda w_j$$\n这相当于在权重上施加了一个\"拉回\"的力，防止权重过大。\n2.2.5 应用场景 垃圾邮件检测：根据邮件内容、发件人等特征判断是否为垃圾邮件 信用评分：根据用户收入、信用历史等预测违约概率 医疗诊断：根据症状、检验结果预测疾病概率 广告点击率（CTR）预测：预测用户是否点击广告 2.3 支持向量机：最大间隔分类器 2.3.1 几何直觉：寻找最大间隔 支持向量机（SVM）的核心思想是：找到一个超平面，不仅能正确分类，而且离两类数据点的距离都尽可能大。\n在二维空间中，超平面就是一条直线：$w_1 x_1 + w_2 x_2 + b = 0$\n点 $(x_1, x_2)$ 到超平面的距离： $$d = \\frac{|w_1 x_1 + w_2 x_2 + b|}{\\sqrt{w_1^2 + w_2^2}}$$\nSVM的目标是：最大化最小距离。\n2.3.2 硬间隔SVM 对于线性可分的数据，假设分类标签 $y_i \\in {-1, +1}$，约束条件为：\n$$y_i (w^T x_i + b) \\geq 1, \\quad i = 1, \\ldots, n$$\n这个约束保证了所有分类正确的点距离超平面至少为 $1/|w|$。\n优化问题： $$\\min_{w, b} \\frac{1}{2} |w|_2^2$$ $$\\text{s.t. } y_i (w^T x_i + b) \\geq 1, \\quad i = 1, \\ldots, n$$\n为什么最小化 $|w|_2^2$？\n因为间隔大小为 $2/|w|$，最大化间隔等价于最小化 $|w|$。\n2.3.3 对偶问题与拉格朗日乘子法 引入拉格朗日乘子 $\\alpha_i \\geq 0$，构造拉格朗日函数：\n$$\\mathcal{L}(w, b, \\alpha) = \\frac{1}{2}|w|^2 - \\sum_{i=1}^n \\alpha_i [y_i (w^T x_i + b) - 1]$$\n原问题的对偶问题： $$\\max_{\\alpha \\geq 0} \\min_{w, b} \\mathcal{L}(w, b, \\alpha)$$\n先对 $w, b$ 求导并令导数为零： $$\\frac{\\partial \\mathcal{L}}{\\partial w} = w - \\sum_{i=1}^n \\alpha_i y_i x_i = 0 \\Rightarrow w = \\sum_{i=1}^n \\alpha_i y_i x_i$$\n$$\\frac{\\partial \\mathcal{L}}{\\partial b} = -\\sum_{i=1}^n \\alpha_i y_i = 0 \\Rightarrow \\sum_{i=1}^n \\alpha_i y_i = 0$$\n代回拉格朗日函数，得到对偶问题： $$\\max_\\alpha \\sum_{i=1}^n \\alpha_i - \\frac{1}{2}\\sum_{i=1}^n \\sum_{j=1}^n \\alpha_i \\alpha_j y_i y_j x_i^T x_j$$\n约束： $$\\alpha_i \\geq 0, \\quad \\sum_{i=1}^n \\alpha_i y_i = 0$$\n这是一个凸二次规划问题，可以用SMO（Sequential Minimal Optimization）算法高效求解。\n2.3.4 支持向量与核技巧 支持向量（Support Vectors）：$\\alpha_i \u003e 0$ 的样本点。这些点位于间隔边界上。\nKKT条件告诉我们： $$\\alpha_i [y_i (w^T x_i + b) - 1] = 0$$\n如果 $\\alpha_i \u003e 0$，则 $y_i (w^T x_i + b) = 1$，即该点在边界上。\n决策函数可以表示为： $$f(x) = \\text{sign}\\left(\\sum_{i=1}^n \\alpha_i y_i x_i^T x + b\\right)$$\n核技巧（Kernel Trick）：将特征映射到高维空间 $\\phi(x)$，使得线性不可分的问题变得可分。\n只关注内积 $x_i^T x_j$，替换为核函数 $K(x_i, x_j) = \\phi(x_i)^T \\phi(x_j)$。\n常用核函数：\n线性核：$K(x_i, x_j) = x_i^T x_j$ 多项式核：$K(x_i, x_j) = (x_i^T x_j + c)^d$ 高斯核（RBF）：$K(x_i, x_j) = \\exp\\left(-\\frac{|x_i - x_j|^2}{2\\sigma^2}\\right)$ Sigmoid核：$K(x_i, x_j) = \\tanh(\\gamma x_i^T x_j + r)$ 2.3.5 软间隔SVM 对于线性不可分的数据，引入松弛变量 $\\xi_i \\geq 0$，允许部分点被误分类：\n$$y_i (w^T x_i + b) \\geq 1 - \\xi_i, \\quad i = 1, \\ldots, n$$\n优化问题： $$\\min_{w, b, \\xi} \\frac{1}{2}|w|^2 + C \\sum_{i=1}^n \\xi_i$$ $$\\text{s.t. } y_i (w^T x_i + b) \\geq 1 - \\xi_i, \\quad \\xi_i \\geq 0$$\n$C$ 是正则化参数，控制间隔与误分类之间的权衡。$C \\to \\infty$ 时，退化为硬间隔SVM。\n2.3.6 应用场景 文本分类：文档分类、情感分析 图像识别：手写数字识别（MNIST） 生物信息学：蛋白质分类、基因表达数据分析 异常检测：利用单分类SVM检测异常数据 2.4 决策树：基于规则的分类与回归 2.4.1 基本思想 决策树通过一系列\"如果-那么\"规则进行预测。树由节点和边组成：\n根节点：整个数据集 内部节点：对某个特征进行测试 叶子节点：预测值（分类中的类别，回归中的数值） 2.4.2 ID3算法：基于信息增益 ID3算法（Iterative Dichotomiser 3）使用信息增益选择分裂特征。\n熵（Entropy）：衡量数据集的不纯度\n对于分类问题，假设有 $K$ 个类别，第 $k$ 类的比例为 $p_k$：\n$$H(D) = -\\sum_{k=1}^K p_k \\log_2 p_k$$\n当所有样本属于同一类时，$H(D) = 0$（最纯）；当各类均匀分布时，$H(D)$ 最大（最不纯）。\n条件熵：给定特征 $A$ 后的熵\n$$H(D|A) = \\sum_{v \\in \\text{Values}(A)} \\frac{|D_v|}{|D|} H(D_v)$$\n其中 $D_v$ 是特征 $A$ 取值为 $v$ 的子集。\n信息增益：分裂前后的熵减少量\n$$\\text{Gain}(D, A) = H(D) - H(D|A)$$\nID3选择使信息增益最大的特征进行分裂。\n2.4.3 C4.5算法：基于信息增益率 ID3的缺点：倾向于选择取值多的特征（如ID）。C4.5用**信息增益率（Information Gain Ratio）**修正：\n$$\\text{GainRatio}(D, A) = \\frac{\\text{Gain}(D, A)}{\\text{SplitInfo}(D, A)}$$\n其中分裂信息： $$\\text{SplitInfo}(D, A) = -\\sum_{v \\in \\text{Values}(A)} \\frac{|D_v|}{|D|} \\log_2 \\frac{|D_v|}{|D|}$$\n2.4.4 CART算法：基尼指数与回归树 CART（Classification and Regression Trees）可以处理分类和回归问题。\n分类树：使用基尼指数（Gini Index）\n$$\\text{Gini}(D) = 1 - \\sum_{k=1}^K p_k^2$$\n基尼指数越小，数据集越纯。选择使基尼指数下降最大的分裂。\n回归树：预测值是叶子节点中样本的均值\n假设叶子节点 $R_m$ 中有 $n_m$ 个样本，预测值为： $$\\hat{c}m = \\frac{1}{n_m}\\sum{x_i \\in R_m} y_i$$\n分裂准则：最小化平方误差 $$\\sum_{x_i \\in R_m} (y_i - \\hat{c}_m)^2$$\n2.4.5 剪枝：防止过拟合 决策树容易过拟合，需要剪枝。\n预剪枝（Pre-pruning）：\n限制树的最大深度 限制每个节点的最小样本数 如果信息增益小于阈值，停止分裂 后剪枝（Post-pruning）：\n从完全生长的树开始，自底向上剪枝 用验证集评估剪枝效果 代价复杂度剪枝（Cost-Complexity Pruning） 定义树 $T$ 的代价复杂度： $$C_\\alpha(T) = \\frac{1}{N} \\sum_{x_i \\in \\text{Training}} L(y_i, \\hat{y}_i) + \\alpha |T|$$\n其中 $|T|$ 是叶子节点数，$\\alpha$ 是正则化参数。选择使 $C_\\alpha(T)$ 最小的子树。\n2.4.6 特征重要性 决策树可以提供特征重要性（Feature Importance）：\n$$\\text{Importance}j = \\sum{t \\in \\text{Splits using } j} \\frac{n_t}{N} \\times \\Delta \\text{Impurity}(t)$$\n其中 $\\Delta \\text{Impurity}(t)$ 是节点 $t$ 分裂前后的不纯度减少量。\n2.4.7 应用场景 医疗诊断：根据症状和检查结果诊断疾病 金融风控：评估贷款申请人的信用风险 推荐系统：基于用户行为推荐商品 客户细分：根据消费行为对客户分类 第三章：集成学习：集众智之长 3.1 偏差-方差分解与集成学习 集成学习通过组合多个模型来提升性能。基本原理：\nBagging（Bootstrap Aggregating）：降低方差\n通过 bootstrap 采样创建多个训练集 每个模型独立训练 预测时取平均（回归）或投票（分类） 代表：随机森林 Boosting：降低偏差\n顺序训练模型，每个模型专注于前一个模型的错误 加权组合模型 代表：AdaBoost、Gradient Boosting、XGBoost、LightGBM Stacking：结合多个不同类型模型的预测\n基模型：不同算法（如逻辑回归、SVM、决策树） 元模型：学习如何组合基模型的预测 3.2 随机森林 3.2.1 算法原理 随机森林是Bagging与决策树的结合，通过引入随机性减少相关性。\n训练过程：\nBootstrap采样：从训练集有放回地抽取 $n$ 个样本，创建 $B$ 个训练集 对每个训练集训练一棵决策树 每次分裂时，从所有特征中随机选择 $m$ 个特征（通常 $m = \\sqrt{p}$） 从这 $m$ 个特征中选择最优分裂特征 预测：\n分类：多数投票 回归：平均 3.2.2 为什么有效？ Bagging的作用：减少方差\n单棵决策树方差大（易过拟合） 取平均后，方差降低为 $\\sigma^2/B$（假设独立） 特征随机性的作用：减少相关性\n如果使用全部特征，树之间高度相关 随机选择特征子集，增加多样性 不相关模型的平均更有效（根据方差公式：$\\text{Var}(\\bar{X}) = \\frac{\\sigma^2}{B} + \\frac{B-1}{B}\\rho\\sigma^2$，其中 $\\rho$ 是相关性） 3.2.3 超参数 n_estimators：树的数量（越多越好，但计算成本增加） max_depth：树的最大深度（控制过拟合） min_samples_split：节点分裂的最小样本数 min_samples_leaf：叶子节点的最小样本数 max_features：每次分裂考虑的特征数（\"sqrt\"、\"log2\"或整数） 3.2.4 特征重要性（Out-of-Bag） 随机森林的OOB（Out-of-Bag）样本（bootstrap中未被选中的样本）可以用于：\n估计泛化误差（无需验证集） 计算特征重要性 特征重要性的计算：打乱特征 $j$ 的值，观察OOB误差的增加量。\n3.3 梯度提升树（GBDT） 3.3.1 核心思想 梯度提升树通过拟合负梯度来逐步改进模型。\n给定损失函数 $L(y, F(x))$，目标是最小化期望损失：\n$$\\min_F \\mathbb{E}[L(y, F(x))]$$\n用贪心算法：逐步添加弱学习器 $h_m(x)$：\n$$F_m(x) = F_{m-1}(x) + h_m(x)$$\n选择 $h_m$ 使损失下降最大：\n$$h_m = \\arg\\min_h \\sum_{i=1}^n L(y_i, F_{m-1}(x_i) + h(x_i))$$\n3.3.2 负梯度拟合 对 $L$ 在 $F_{m-1}(x_i)$ 处做泰勒展开（一阶）：\n$$L(y_i, F_{m-1}(x_i) + h(x_i)) \\approx L(y_i, F_{m-1}(x_i)) + \\frac{\\partial L(y_i, F(x))}{\\partial F(x)}\\bigg|{F = F{m-1}} h(x_i)$$\n负梯度： $$r_{im} = -\\frac{\\partial L(y_i, F(x))}{\\partial F(x)}\\bigg|{F = F{m-1}}$$\n因此，$h_m(x)$ 应该拟合负梯度 $r_{im}$。\n平方损失：$L = \\frac{1}{2}(y - F)^2$ $$\\frac{\\partial L}{\\partial F} = -(y - F)$$ 负梯度：$r_{im} = y_i - F_{m-1}(x_i)$（残差）\n逻辑损失：$L = \\log(1 + e^{-yF})$，其中 $y \\in {-1, 1}$ $$\\frac{\\partial L}{\\partial F} = \\frac{-y e^{-yF}}{1 + e^{-yF}} = -\\frac{y}{1 + e^{yF}}$$ 负梯度：$r_{im} = \\frac{y_i}{1 + e^{y_i F_{m-1}(x_i)}}$\n3.3.3 算法流程 输入：训练集 ${(x_i, y_i)}_{i=1}^n$，损失函数 $L$，学习率 $\\eta$，树的数量 $M$\n步骤：\n初始化：$F_0(x) = \\arg\\min_c \\sum_{i=1}^n L(y_i, c)$（对回归，取均值；对分类，取对数几率） 对于 $m = 1, 2, \\ldots, M$： 计算负梯度：$r_{im} = -\\frac{\\partial L(y_i, F_{m-1}(x_i))}{\\partial F(x)}$ 用决策树拟合 $(x_i, r_{im})$，得到区域 $R_{jm}$（$j = 1, \\ldots, J_m$） 计算叶子节点预测值：$\\gamma_{jm} = \\arg\\min_\\gamma \\sum_{x_i \\in R_{jm}} L(y_i, F_{m-1}(x_i) + \\gamma)$ 更新模型：$F_m(x) = F_{m-1}(x) + \\eta \\sum_{j=1}^{J_m} \\gamma_{jm} I(x \\in R_{jm})$ 3.3.4 正则化 GBDT通过多种方式防止过拟合：\n学习率（Learning Rate）：$\\eta \\in (0, 1]$，控制每一步的步长 树的数量（n_estimators）：使用早停法（Early Stopping）选择最佳数量 树的复杂度： max_depth：限制树深度 min_samples_split、min_samples_leaf：控制叶子节点 子采样（Subsampling）：每棵树只使用部分数据（类似Bagging） 3.3.5 XGBoost与LightGBM **XGBoost（eXtreme Gradient Boosting）**的改进：\n二阶泰勒展开（同时使用一阶和二阶导数） 正则化项（叶子节点数和L2正则） 稀疏感知（处理缺失值） 并行化（特征级别） 列块设计（缓存优化） LightGBM的改进：\n基于直方图（Histogram）的算法（将连续值离散化） GOSS（Gradient-based One-Side Sampling）：只保留高梯度和随机低梯度样本 EFB（Exclusive Feature Bundling）：合并稀疏特征 Leaf-wise生长（优先分裂增益最大的叶子节点） 3.3.6 应用场景 搜索排名：LambdaMART（基于GBDT的学习排序算法） 欺诈检测：信用卡欺诈、税务欺诈 点击率预测：广告CTR预测 时间序列预测：销量预测、流量预测 3.4 AdaBoost：自适应提升 3.4.1 算法原理 AdaBoost（Adaptive Boosting）通过加权训练样本，逐步关注难以分类的样本。\n输入：训练集 ${(x_i, y_i)}_{i=1}^n$，$y_i \\in {-1, 1}$，迭代次数 $T$\n步骤：\n初始化样本权重：$w_i^{(1)} = 1/n$ 对于 $t = 1, 2, \\ldots, T$： 用权重 $w_i^{(t)}$ 训练弱分类器 $h_t(x)$ 计算分类误差：$\\epsilon_t = \\sum_{i=1}^n w_i^{(t)} I(y_i \\neq h_t(x_i))$ 计算分类器权重：$\\alpha_t = \\frac{1}{2}\\log\\frac{1 - \\epsilon_t}{\\epsilon_t}$ 更新样本权重：$w_i^{(t+1)} = w_i^{(t)} \\exp(-\\alpha_t y_i h_t(x_i))$ 归一化权重：$w_i^{(t+1)} = \\frac{w_i^{(t+1)}}{\\sum_{j=1}^n w_j^{(t+1)}}$ 最终分类器：$H(x) = \\text{sign}\\left(\\sum_{t=1}^T \\alpha_t h_t(x)\\right)$ 3.4.2 为什么有效？ AdaBoost通过指数损失最小化：\n$$L = \\sum_{i=1}^n \\exp(-y_i H(x_i))$$\n其中 $H(x) = \\sum_t \\alpha_t h_t(x)$。\n可以证明：每一步选择使误差最小的 $h_t$，等价于使指数损失下降最多。\n权重更新的含义：\n如果 $y_i = h_t(x_i)$（分类正确），权重减小 如果 $y_i \\neq h_t(x_i)$（分类错误），权重增大 难以分类的样本权重越来越大，模型更关注这些样本 3.4.3 理论保证 AdaBoost的泛化误差有如下界限：\n$$P[H(x) \\neq y] \\leq P\\left[\\sum_{t=1}^T \\alpha_t h_t(x) y \\leq 0\\right] \\leq \\prod_{t=1}^T \\sqrt{1 - 4\\gamma_t^2} \\leq \\exp\\left(-2\\sum_{t=1}^T \\gamma_t^2\\right)$$\n其中 $\\gamma_t = \\frac{1}{2} - \\epsilon_t$（边缘）。\n如果每个弱分类器比随机猜测好（$\\epsilon_t \u003c 0.5$），则AdaBoost会收敛到零训练误差。\n第四章：无监督学习：从数据中发现结构 4.1 主成分分析（PCA） 4.1.1 降维问题 给定数据 $X \\in \\mathbb{R}^{n \\times p}$，我们想找到一个低维表示 $Z \\in \\mathbb{R}^{n \\times k}$（$k \u003c p$），保留尽可能多的信息。\n4.1.2 几何视角：最大化投影方差 投影矩阵 $W \\in \\mathbb{R}^{p \\times k}$，满足 $W^TW = I_k$（正交矩阵）。\n投影后的数据：$Z = XW$\n最大化投影方差： $$\\max_W \\text{tr}(Z^TZ) = \\max_W \\text{tr}(W^TX^TXW)$$\n约束：$W^TW = I_k$\n4.1.3 求解：特征值分解 数据协方差矩阵：$\\Sigma = \\frac{1}{n-1}X^TX$\n优化问题等价于： $$\\max_W \\text{tr}(W^T\\Sigma W), \\quad W^TW = I_k$$\n根据瑞利商理论，最优解是 $\\Sigma$ 的前 $k$ 个最大特征值对应的特征向量。\n设 $\\Sigma$ 的特征值分解：$\\Sigma = U \\Lambda U^T$，其中 $\\Lambda = \\text{diag}(\\lambda_1, \\lambda_2, \\ldots, \\lambda_p)$，$\\lambda_1 \\geq \\lambda_2 \\geq \\ldots \\geq \\lambda_p \\geq 0$\n主成分：$W = [u_1, u_2, \\ldots, u_k]$\n方差解释比例： $$\\frac{\\sum_{i=1}^k \\lambda_i}{\\sum_{i=1}^p \\lambda_i}$$\n4.1.4 代数视角：最小化重构误差 重构：$\\hat{X} = ZW^T = XWW^T$\n最小化重构误差： $$\\min_W |X - XWW^T|_F^2, \\quad W^TW = I_k$$\n可以证明这与最大化方差等价。\n4.1.5 奇异值分解（SVD） 对于大数据，直接计算 $\\Sigma = \\frac{1}{n-1}X^TX$ 计算量大（$p^3$）。\n使用SVD：$X = U \\Sigma V^T$\n其中 $U \\in \\mathbb{R}^{n \\times n}$，$\\Sigma \\in \\mathbb{R}^{n \\times p}$，$V \\in \\mathbb{R}^{p \\times p}$\n主成分：$W = V_{:, 1:k}$\n投影：$Z = XW = U \\Sigma V^T V_{:, 1:k} = U \\Sigma_{:, 1:k}$\n4.1.6 应用场景 数据可视化：将高维数据投影到2D或3D进行可视化 图像压缩：Eigenfaces（人脸识别） 噪声减少：保留主成分，去除噪声 特征提取：为后续算法提供低维特征 4.2 聚类算法 4.2.1 K-means算法 目标：将 $n$ 个样本分成 $K$ 个簇，使簇内距离最小。\n算法流程：\n随机初始化 $K$ 个质心：$\\mu_1, \\mu_2, \\ldots, \\mu_K$ 重复直到收敛： 分配：$c_i = \\arg\\min_j |x_i - \\mu_j|^2$ 更新：$\\mu_j = \\frac{1}{|C_j|}\\sum_{i \\in C_j} x_i$ 目标函数（误差平方和，SSE）： $$J = \\sum_{j=1}^K \\sum_{i \\in C_j} |x_i - \\mu_j|^2$$\n4.2.2 收敛性 K-means单调下降目标函数 $J$：\n分配步骤：每个点分配到最近的质心，$J$ 不增 更新步骤：质心移动到簇内均值，$J$ 不减 但可能收敛到局部最优（依赖初始化）。\n4.2.3 K-means++：改进初始化 初始化质心：\n第一个质心：随机选择 对于 $k = 2, \\ldots, K$： 计算每个点到最近质心的距离：$d(x_i) = \\min_j |x_i - \\mu_j|$ 按概率 $\\frac{d(x_i)^2}{\\sum_{j=1}^n d(x_j)^2}$ 选择下一个质心 理论保证：$O(\\log K)$ 近似最优。\n4.2.4 层次聚类 层次聚类创建聚类树（Dendrogram），无需指定簇数。\n凝聚（Agglomerative）：自底向上，逐步合并最近的簇\n距离度量：\n单链接（Single Linkage）：$\\min_{x \\in C_i, y \\in C_j} |x - y|$ 完全链接（Complete Linkage）：$\\max_{x \\in C_i, y \\in C_j} |x - y|$ 平均链接（Average Linkage）：$\\frac{1}{|C_i||C_j|}\\sum_{x \\in C_i} \\sum_{y \\in C_j} |x - y|$ 分裂（Divisive）：自顶向下，逐步分裂簇\n4.2.5 DBSCAN：基于密度的聚类 K-means无法发现非凸簇和异常点。DBSCAN（Density-Based Spatial Clustering of Applications with Noise）基于密度聚类。\n定义：\n$\\epsilon$-邻域：$N_\\epsilon(x) = {y : |y - x| \\leq \\epsilon}$ 核心点：$|N_\\epsilon(x)| \\geq \\text{minPts}$ 边界点：邻域内点数少于minPts，但与某个核心点相邻 噪声点：既不是核心点也不是边界点 算法流程：\n标记所有点为未访问 对于每个未访问点 $x$： 标记为已访问 如果 $|N_\\epsilon(x)| \u003c \\text{minPts}$：标记为噪声 否则：创建新簇，通过密度连接添加点 优点：\n自动发现簇数 发现任意形状的簇 识别异常点 4.2.6 应用场景 客户细分：根据购买行为分群 文档聚类：主题发现 图像分割：像素聚类 异常检测：发现离群点 第五章：传统机器学习的应用场景 5.1 金融领域 5.1.1 信用评分 问题：根据借款人的历史数据，预测违约概率。\n常用算法：\n逻辑回归：可解释性强，易于满足监管要求 随机森林：处理非线性关系，特征重要性分析 XGBoost：在Kaggle竞赛中表现优异 特征：\n收入、负债收入比 信用历史（逾期次数、信用卡使用率） 贷款金额、期限 职业稳定性、教育程度 评估指标：\nAUC-ROC KS统计量 提升度（Lift） 5.1.2 欺诈检测 问题：识别信用卡交易、保险理赔中的欺诈行为。\n挑战：\n类别极度不平衡（欺诈样本极少） 欺诈模式不断变化 常用算法：\n异常检测：Isolation Forest、One-Class SVM 不平衡学习：SMOTE、代价敏感学习 集成方法：XGBoost（scale_pos_weight参数） 5.2 医疗健康 5.2.1 疾病诊断 问题：根据症状、检验结果诊断疾病。\n示例：\n乳腺癌检测：决策树、逻辑回归（可解释性重要） 糖尿病预测：SVM、随机森林 心脏病风险评估：逻辑回归（计算风险评分） 特征：\n患者年龄、性别、家族史 症状、检验指标（血压、血糖、胆固醇） 影像学特征（从医学图像提取） 5.2.2 药物发现 问题：预测化合物的生物活性、毒性。\n挑战：\n数据量有限（实验成本高） 分子表示复杂 常用算法：\n随机森林：处理分子描述符 深度学习：图神经网络（GNN）处理分子结构 迁移学习：从大规模数据预训练 5.3 推荐系统 5.3.1 协同过滤 问题：根据用户历史行为预测偏好。\n用户-物品矩阵：$R \\in \\mathbb{R}^{n \\times m}$，$R_{ij}$ 表示用户 $i$ 对物品 $j$ 的评分\n矩阵分解： $$R \\approx UV^T$$\n其中 $U \\in \\mathbb{R}^{n \\times k}$（用户隐因子），$V \\in \\mathbb{R}^{m \\times k}$（物品隐因子）\n优化： $$\\min_{U, V} \\sum_{(i,j) \\in \\Omega} (R_{ij} - u_i^T v_j)^2 + \\lambda (|U|_F^2 + |V|_F^2)$$\n$\\Omega$ 是已知评分的索引集合。\n5.3.2 内容推荐 问题：基于物品内容相似性推荐。\n方法：\nTF-IDF + 余弦相似度（文本） LSA（潜在语义分析）：降维后计算相似度 内容特征 + 协同过滤：混合模型 5.3.3 排序学习 问题：对搜索结果排序。\n算法：\nLambdaMART：基于GBDT的学习排序 ListNet、ListMLE：基于列表的学习排序 5.4 自然语言处理（NLP） 5.4.1 文本分类 传统方法：\n特征提取：TF-IDF、N-grams、Word2Vec 分类器：朴素贝叶斯、SVM、逻辑回归 示例：\n垃圾邮件分类：朴素贝叶斯 情感分析：SVM 新闻分类：逻辑回归 5.4.2 主题模型 LDA（Latent Dirichlet Allocation）：\n生成模型：每篇文档包含多个主题，每个主题包含多个词。\n推断：Gibbs采样、变分推断\n5.4.3 命名实体识别（NER） 传统方法：\nHMM（隐马尔可夫模型） CRF（条件随机场） 特征：词性标注、上下文窗口、词形特征\n5.5 计算机视觉 5.5.1 图像分类（传统方法） 特征提取：\nSIFT（尺度不变特征变换） HOG（方向梯度直方图） LBP（局部二值模式） 分类器：\nSVM：ImageNet竞赛中表现优异（2012年之前） 随机森林：处理高维特征 5.5.2 目标检测 传统方法：\nViola-Jones框架（Haar特征 + AdaBoost）：人脸检测 HOG + SVM：行人检测 DPM（可变形部件模型）：多类别目标检测 第六章：未来展望 6.1 传统机器学习的现状 尽管深度学习在图像、语音等感知任务上取得了巨大成功，传统机器学习依然在以下场景中不可替代：\n数据量有限：当样本量在几千到几万时，传统算法（特别是集成方法）往往表现更好 可解释性要求高：金融风控、医疗诊断等需要解释决策依据的场景 计算资源受限：传统算法计算量小，适合边缘计算、实时推理 结构化数据：表格数据是传统算法的主场，深度学习在这方面没有明显优势 6.2 未来发展趋势 6.2.1 自动机器学习（AutoML） 现状：传统机器学习模型调参复杂，需要大量领域知识。\n未来：\n自动特征工程：自动选择、构造特征 超参数优化：贝叶斯优化、进化算法 模型选择：自动选择最优算法 神经架构搜索（NAS）：为深度学习设计架构 工具：\nAuto-sklearn H2O AutoML Google AutoML Microsoft AutoML 6.2.2 可解释性AI（XAI） 挑战：传统算法（如随机森林、XGBoost）虽然可解释，但深度学习是黑箱。\n方法：\nLIME（Local Interpretable Model-agnostic Explanations）：局部解释 SHAP（SHapley Additive exPlanations）：基于博弈论的全局/局部解释 反事实解释：说明\"如果特征X改变，结果会如何变化\" 注意力机制：深度学习中的可解释性 应用：\n医疗诊断：解释为什么预测某种疾病 金融风控：解释为什么拒绝贷款申请 公平性：检测和消除算法偏见 6.2.3 因果推断 传统机器学习：关联性（Correlation）\n未来：因果性（Causality）\n方法：\n结构因果模型（SCM） do-算子（Pearl的因果演算） 双重机器学习（DML）：结合因果推断与机器学习 应用：\n营销：计算广告的因果效应（提升度） 政策评估：估计政策的因果影响 推荐系统：用户行为归因 6.2.4 迁移学习与小样本学习 挑战：传统机器学习需要大量标注数据。\n未来：\n预训练模型：从大规模无标注数据预训练 微调：在目标任务上少量标注数据微调 元学习（Meta-Learning）：学习如何学习 示例：\nNLP：BERT、GPT（预训练+微调） 表格数据：预训练的表格数据模型（如TabNet、SAINT） 跨领域迁移：从源域知识迁移到目标域 6.2.5 在线学习与强化学习 传统机器学习：离线训练，静态数据\n未来：\n在线学习：实时更新模型，适应数据分布变化 增量学习：增量式学习新任务，不遗忘旧知识 强化学习：通过与环境交互学习最优策略 应用：\n实时推荐：根据用户实时行为更新推荐 自适应系统：自动驾驶、机器人控制 序列决策：游戏AI、资源调度 6.2.6 传统算法与深度学习的融合 融合方向：\n深度嵌入传统算法\nDeep Forest：用深度森林替代神经网络 树神经网络（TreeNN）：决策树的神经网络化 传统算法作为组件\nGBDT的叶子编码作为特征，输入神经网络 注意力机制结合树模型 混合模型\n结构化数据：传统算法（XGBoost） 非结构化数据：深度学习（CNN、RNN、Transformer） 多模态融合：结合两种模型的输出 6.2.7 鲁棒性与安全性 挑战：传统算法和深度学习都易受对抗攻击。\n研究方向：\n对抗训练：提升模型鲁棒性 防御性蒸馏 神经网络验证 公平性：\n消除算法偏见（种族、性别等） 公平性约束优化 6.3 传统机器学习的长期价值 尽管深度学习风头正劲，传统机器学习算法在以下方面依然具有重要价值：\n理论基础扎实：统计学、凸优化等数学理论支撑，理论保证完善 工程实践成熟：Scikit-learn等工具库成熟，部署简单 计算效率高：适合实时应用、边缘计算 可解释性好：决策规则清晰，易于理解和调试 适用范围广：结构化数据分析的主场 6.4 结论 传统机器学习与统计学习算法经历了半个多世纪的发展，从高斯的线性回归到XGBoost的集成学习，形成了完整、成熟的理论体系和工程实践。\n在深度学习时代，传统算法并未过时。相反，它们在特定场景下依然不可替代。未来的发展方向不是相互替代，而是相互融合：传统算法提供坚实的理论基础和工程实践，深度学习拓展了感知能力的边界，AutoML、可解释性、因果推断等技术将进一步释放机器学习的潜力。\n正如统计学家George Box所说：“All models are wrong, but some are useful.\"（所有模型都是错的，但有些是有用的）。传统机器学习算法的价值在于它们在\"有用\"这个维度上做到了极致。\n参考文献 Hastie, T., Tibshirani, R., \u0026 Friedman, J. (2009). The Elements of Statistical Learning. Springer. Bishop, C. M. (2006). Pattern Recognition and Machine Learning. Springer. James, G., Witten, D., Hastie, T., \u0026 Tibshirani, R. (2013). An Introduction to Statistical Learning. Springer. Breiman, L. (2001). Random Forests. Machine Learning, 45(1), 5-32. Friedman, J. H. (2001). Greedy Function Approximation: A Gradient Boosting Machine. Annals of Statistics, 29(5), 1189-1232. Chen, T., \u0026 Guestrin, C. (2016). XGBoost: A Scalable Tree Boosting System. Proceedings of KDD. Vapnik, V. N. (1998). Statistical Learning Theory. Wiley. Schapire, R. E., \u0026 Freund, Y. (2012). Boosting: Foundations and Algorithms. MIT Press. Pearl, J., \u0026 Mackenzie, D. (2018). The Book of Why: The New Science of Cause and Effect. Basic Books. Murphy, K. P. (2012). Machine Learning: A Probabilistic Perspective. MIT Press. ","wordCount":"2161","inLanguage":"en","image":"https://s-ai-unix.github.io/images/covers/photo-1509228468518-180dd4864904.jpg","datePublished":"2026-01-14T08:18:25+08:00","dateModified":"2026-01-14T08:18:25+08:00","author":{"@type":"Person","name":"s-ai-unix"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://s-ai-unix.github.io/posts/2026-01-14-traditional-ml-algorithms-comprehensive-guide/"},"publisher":{"@type":"Organization","name":"s-ai-unix's Blog","logo":{"@type":"ImageObject","url":"https://s-ai-unix.github.io/favicon.ico"}}}</script><link rel=stylesheet href=https://s-ai-unix.github.io/css/classical-quote.css></head><body id=top><header class=header><nav class=nav><div class=logo><a href=https://s-ai-unix.github.io/ accesskey=h title="s-ai-unix's Blog (Alt + H)">s-ai-unix's Blog</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://s-ai-unix.github.io/ title="🏠 首页"><span>🏠 首页</span></a></li><li><a href=https://s-ai-unix.github.io/posts/ title="📚 文章"><span>📚 文章</span></a></li><li><a href=https://s-ai-unix.github.io/archives/ title="📁 归档"><span>📁 归档</span></a></li><li><a href=https://s-ai-unix.github.io/tags/ title="🏷️ 标签"><span>🏷️ 标签</span></a></li><li><a href=https://s-ai-unix.github.io/search/ title="🔍 搜索 (Alt + /)" accesskey=/><span>🔍 搜索</span></a></li><li><a href=https://s-ai-unix.github.io/about/ title="👤 关于"><span>👤 关于</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://s-ai-unix.github.io/>Home</a>&nbsp;»&nbsp;<a href=https://s-ai-unix.github.io/posts/>Posts</a></div><h1 class="post-title entry-hint-parent">传统机器学习与统计学习算法：从理论到实践的完整指南</h1><div class=post-description>本文全面回顾传统机器学习和统计学习算法的发展历程、数学原理、应用场景及未来前景，涵盖从线性回归到深度学习之前的关键算法。</div><div class=post-meta><span title='2026-01-14 08:18:25 +0800 CST'>January 14, 2026</span>&nbsp;·&nbsp;<span>11 min</span>&nbsp;·&nbsp;<span>2161 words</span>&nbsp;·&nbsp;<span>s-ai-unix</span></div></header><figure class=entry-cover><a href=https://s-ai-unix.github.io/images/covers/photo-1509228468518-180dd4864904.jpg target=_blank rel="noopener noreferrer"><img loading=eager src=https://s-ai-unix.github.io/images/covers/photo-1509228468518-180dd4864904.jpg alt=抽象几何图形></a><figcaption>数学之美</figcaption></figure><div class=toc><details open><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#%e5%bc%95%e8%a8%80%e4%bb%8e%e7%bb%9f%e8%ae%a1%e5%ad%a6%e5%88%b0%e6%9c%ba%e5%99%a8%e5%ad%a6%e4%b9%a0 aria-label=引言：从统计学到机器学习>引言：从统计学到机器学习</a></li><li><a href=#%e7%ac%ac%e4%b8%80%e7%ab%a0%e7%bb%9f%e8%ae%a1%e5%ad%a6%e4%b9%a0%e7%9a%84%e7%90%86%e8%ae%ba%e5%9f%ba%e7%a1%80 aria-label=第一章：统计学习的理论基础>第一章：统计学习的理论基础</a><ul><li><a href=#11-%e5%ad%a6%e4%b9%a0%e9%97%ae%e9%a2%98%e7%9a%84%e6%95%b0%e5%ad%a6%e6%a1%86%e6%9e%b6 aria-label="1.1 学习问题的数学框架">1.1 学习问题的数学框架</a></li><li><a href=#12-%e5%81%8f%e5%b7%ae-%e6%96%b9%e5%b7%ae%e6%9d%83%e8%a1%a1 aria-label="1.2 偏差-方差权衡">1.2 偏差-方差权衡</a></li><li><a href=#13-%e6%ad%a3%e5%88%99%e5%8c%96%e6%8e%a7%e5%88%b6%e6%a8%a1%e5%9e%8b%e5%a4%8d%e6%9d%82%e5%ba%a6%e7%9a%84%e6%95%b0%e5%ad%a6%e5%b7%a5%e5%85%b7 aria-label="1.3 正则化：控制模型复杂度的数学工具">1.3 正则化：控制模型复杂度的数学工具</a></li><li><a href=#14-%e6%b3%9b%e5%8c%96%e8%af%af%e5%b7%ae%e4%b8%8epac%e5%ad%a6%e4%b9%a0%e6%a1%86%e6%9e%b6 aria-label="1.4 泛化误差与PAC学习框架">1.4 泛化误差与PAC学习框架</a></li></ul></li><li><a href=#%e7%ac%ac%e4%ba%8c%e7%ab%a0%e7%bb%8f%e5%85%b8%e7%9b%91%e7%9d%a3%e5%ad%a6%e4%b9%a0%e7%ae%97%e6%b3%95 aria-label=第二章：经典监督学习算法>第二章：经典监督学习算法</a><ul><li><a href=#21-%e7%ba%bf%e6%80%a7%e5%9b%9e%e5%bd%92%e7%bb%9f%e8%ae%a1%e5%ad%a6%e4%b9%a0%e7%9a%84%e8%b5%b7%e7%82%b9 aria-label="2.1 线性回归：统计学习的起点">2.1 线性回归：统计学习的起点</a><ul><li><a href=#211-%e5%9f%ba%e6%9c%ac%e6%a8%a1%e5%9e%8b aria-label="2.1.1 基本模型">2.1.1 基本模型</a></li><li><a href=#212-%e6%9c%80%e5%b0%8f%e4%ba%8c%e4%b9%98%e4%bc%b0%e8%ae%a1 aria-label="2.1.2 最小二乘估计">2.1.2 最小二乘估计</a></li><li><a href=#213-%e7%bb%9f%e8%ae%a1%e6%80%a7%e8%b4%a8 aria-label="2.1.3 统计性质">2.1.3 统计性质</a></li><li><a href=#214-%e5%b2%ad%e5%9b%9e%e5%bd%92%e4%b8%8elasso aria-label="2.1.4 岭回归与Lasso">2.1.4 岭回归与Lasso</a></li><li><a href=#215-%e5%ba%94%e7%94%a8%e5%9c%ba%e6%99%af aria-label="2.1.5 应用场景">2.1.5 应用场景</a></li></ul></li><li><a href=#22-%e9%80%bb%e8%be%91%e5%9b%9e%e5%bd%92%e5%88%86%e7%b1%bb%e9%97%ae%e9%a2%98%e7%9a%84%e7%bb%8f%e5%85%b8%e6%96%b9%e6%b3%95 aria-label="2.2 逻辑回归：分类问题的经典方法">2.2 逻辑回归：分类问题的经典方法</a><ul><li><a href=#221-%e4%bb%8e%e7%ba%bf%e6%80%a7%e5%9b%9e%e5%bd%92%e5%88%b0%e9%80%bb%e8%be%91%e5%9b%9e%e5%bd%92 aria-label="2.2.1 从线性回归到逻辑回归">2.2.1 从线性回归到逻辑回归</a></li><li><a href=#222-%e4%bc%bc%e7%84%b6%e5%87%bd%e6%95%b0%e4%b8%8e%e6%9e%81%e5%a4%a7%e4%bc%bc%e7%84%b6%e4%bc%b0%e8%ae%a1 aria-label="2.2.2 似然函数与极大似然估计">2.2.2 似然函数与极大似然估计</a></li><li><a href=#223-%e6%a2%af%e5%ba%a6%e4%b8%8b%e9%99%8d%e6%b3%95 aria-label="2.2.3 梯度下降法">2.2.3 梯度下降法</a></li><li><a href=#224-%e6%ad%a3%e5%88%99%e5%8c%96%e9%80%bb%e8%be%91%e5%9b%9e%e5%bd%92 aria-label="2.2.4 正则化逻辑回归">2.2.4 正则化逻辑回归</a></li><li><a href=#225-%e5%ba%94%e7%94%a8%e5%9c%ba%e6%99%af aria-label="2.2.5 应用场景">2.2.5 应用场景</a></li></ul></li><li><a href=#23-%e6%94%af%e6%8c%81%e5%90%91%e9%87%8f%e6%9c%ba%e6%9c%80%e5%a4%a7%e9%97%b4%e9%9a%94%e5%88%86%e7%b1%bb%e5%99%a8 aria-label="2.3 支持向量机：最大间隔分类器">2.3 支持向量机：最大间隔分类器</a><ul><li><a href=#231-%e5%87%a0%e4%bd%95%e7%9b%b4%e8%a7%89%e5%af%bb%e6%89%be%e6%9c%80%e5%a4%a7%e9%97%b4%e9%9a%94 aria-label="2.3.1 几何直觉：寻找最大间隔">2.3.1 几何直觉：寻找最大间隔</a></li><li><a href=#232-%e7%a1%ac%e9%97%b4%e9%9a%94svm aria-label="2.3.2 硬间隔SVM">2.3.2 硬间隔SVM</a></li><li><a href=#233-%e5%af%b9%e5%81%b6%e9%97%ae%e9%a2%98%e4%b8%8e%e6%8b%89%e6%a0%bc%e6%9c%97%e6%97%a5%e4%b9%98%e5%ad%90%e6%b3%95 aria-label="2.3.3 对偶问题与拉格朗日乘子法">2.3.3 对偶问题与拉格朗日乘子法</a></li><li><a href=#234-%e6%94%af%e6%8c%81%e5%90%91%e9%87%8f%e4%b8%8e%e6%a0%b8%e6%8a%80%e5%b7%a7 aria-label="2.3.4 支持向量与核技巧">2.3.4 支持向量与核技巧</a></li><li><a href=#235-%e8%bd%af%e9%97%b4%e9%9a%94svm aria-label="2.3.5 软间隔SVM">2.3.5 软间隔SVM</a></li><li><a href=#236-%e5%ba%94%e7%94%a8%e5%9c%ba%e6%99%af aria-label="2.3.6 应用场景">2.3.6 应用场景</a></li></ul></li><li><a href=#24-%e5%86%b3%e7%ad%96%e6%a0%91%e5%9f%ba%e4%ba%8e%e8%a7%84%e5%88%99%e7%9a%84%e5%88%86%e7%b1%bb%e4%b8%8e%e5%9b%9e%e5%bd%92 aria-label="2.4 决策树：基于规则的分类与回归">2.4 决策树：基于规则的分类与回归</a><ul><li><a href=#241-%e5%9f%ba%e6%9c%ac%e6%80%9d%e6%83%b3 aria-label="2.4.1 基本思想">2.4.1 基本思想</a></li><li><a href=#242-id3%e7%ae%97%e6%b3%95%e5%9f%ba%e4%ba%8e%e4%bf%a1%e6%81%af%e5%a2%9e%e7%9b%8a aria-label="2.4.2 ID3算法：基于信息增益">2.4.2 ID3算法：基于信息增益</a></li><li><a href=#243-c45%e7%ae%97%e6%b3%95%e5%9f%ba%e4%ba%8e%e4%bf%a1%e6%81%af%e5%a2%9e%e7%9b%8a%e7%8e%87 aria-label="2.4.3 C4.5算法：基于信息增益率">2.4.3 C4.5算法：基于信息增益率</a></li><li><a href=#244-cart%e7%ae%97%e6%b3%95%e5%9f%ba%e5%b0%bc%e6%8c%87%e6%95%b0%e4%b8%8e%e5%9b%9e%e5%bd%92%e6%a0%91 aria-label="2.4.4 CART算法：基尼指数与回归树">2.4.4 CART算法：基尼指数与回归树</a></li><li><a href=#245-%e5%89%aa%e6%9e%9d%e9%98%b2%e6%ad%a2%e8%bf%87%e6%8b%9f%e5%90%88 aria-label="2.4.5 剪枝：防止过拟合">2.4.5 剪枝：防止过拟合</a></li><li><a href=#246-%e7%89%b9%e5%be%81%e9%87%8d%e8%a6%81%e6%80%a7 aria-label="2.4.6 特征重要性">2.4.6 特征重要性</a></li><li><a href=#247-%e5%ba%94%e7%94%a8%e5%9c%ba%e6%99%af aria-label="2.4.7 应用场景">2.4.7 应用场景</a></li></ul></li></ul></li><li><a href=#%e7%ac%ac%e4%b8%89%e7%ab%a0%e9%9b%86%e6%88%90%e5%ad%a6%e4%b9%a0%e9%9b%86%e4%bc%97%e6%99%ba%e4%b9%8b%e9%95%bf aria-label=第三章：集成学习：集众智之长>第三章：集成学习：集众智之长</a><ul><li><a href=#31-%e5%81%8f%e5%b7%ae-%e6%96%b9%e5%b7%ae%e5%88%86%e8%a7%a3%e4%b8%8e%e9%9b%86%e6%88%90%e5%ad%a6%e4%b9%a0 aria-label="3.1 偏差-方差分解与集成学习">3.1 偏差-方差分解与集成学习</a></li><li><a href=#32-%e9%9a%8f%e6%9c%ba%e6%a3%ae%e6%9e%97 aria-label="3.2 随机森林">3.2 随机森林</a><ul><li><a href=#321-%e7%ae%97%e6%b3%95%e5%8e%9f%e7%90%86 aria-label="3.2.1 算法原理">3.2.1 算法原理</a></li><li><a href=#322-%e4%b8%ba%e4%bb%80%e4%b9%88%e6%9c%89%e6%95%88 aria-label="3.2.2 为什么有效？">3.2.2 为什么有效？</a></li><li><a href=#323-%e8%b6%85%e5%8f%82%e6%95%b0 aria-label="3.2.3 超参数">3.2.3 超参数</a></li><li><a href=#324-%e7%89%b9%e5%be%81%e9%87%8d%e8%a6%81%e6%80%a7out-of-bag aria-label="3.2.4 特征重要性（Out-of-Bag）">3.2.4 特征重要性（Out-of-Bag）</a></li></ul></li><li><a href=#33-%e6%a2%af%e5%ba%a6%e6%8f%90%e5%8d%87%e6%a0%91gbdt aria-label="3.3 梯度提升树（GBDT）">3.3 梯度提升树（GBDT）</a><ul><li><a href=#331-%e6%a0%b8%e5%bf%83%e6%80%9d%e6%83%b3 aria-label="3.3.1 核心思想">3.3.1 核心思想</a></li><li><a href=#332-%e8%b4%9f%e6%a2%af%e5%ba%a6%e6%8b%9f%e5%90%88 aria-label="3.3.2 负梯度拟合">3.3.2 负梯度拟合</a></li><li><a href=#333-%e7%ae%97%e6%b3%95%e6%b5%81%e7%a8%8b aria-label="3.3.3 算法流程">3.3.3 算法流程</a></li><li><a href=#334-%e6%ad%a3%e5%88%99%e5%8c%96 aria-label="3.3.4 正则化">3.3.4 正则化</a></li><li><a href=#335-xgboost%e4%b8%8elightgbm aria-label="3.3.5 XGBoost与LightGBM">3.3.5 XGBoost与LightGBM</a></li><li><a href=#336-%e5%ba%94%e7%94%a8%e5%9c%ba%e6%99%af aria-label="3.3.6 应用场景">3.3.6 应用场景</a></li></ul></li><li><a href=#34-adaboost%e8%87%aa%e9%80%82%e5%ba%94%e6%8f%90%e5%8d%87 aria-label="3.4 AdaBoost：自适应提升">3.4 AdaBoost：自适应提升</a><ul><li><a href=#341-%e7%ae%97%e6%b3%95%e5%8e%9f%e7%90%86 aria-label="3.4.1 算法原理">3.4.1 算法原理</a></li><li><a href=#342-%e4%b8%ba%e4%bb%80%e4%b9%88%e6%9c%89%e6%95%88 aria-label="3.4.2 为什么有效？">3.4.2 为什么有效？</a></li><li><a href=#343-%e7%90%86%e8%ae%ba%e4%bf%9d%e8%af%81 aria-label="3.4.3 理论保证">3.4.3 理论保证</a></li></ul></li></ul></li><li><a href=#%e7%ac%ac%e5%9b%9b%e7%ab%a0%e6%97%a0%e7%9b%91%e7%9d%a3%e5%ad%a6%e4%b9%a0%e4%bb%8e%e6%95%b0%e6%8d%ae%e4%b8%ad%e5%8f%91%e7%8e%b0%e7%bb%93%e6%9e%84 aria-label=第四章：无监督学习：从数据中发现结构>第四章：无监督学习：从数据中发现结构</a><ul><li><a href=#41-%e4%b8%bb%e6%88%90%e5%88%86%e5%88%86%e6%9e%90pca aria-label="4.1 主成分分析（PCA）">4.1 主成分分析（PCA）</a><ul><li><a href=#411-%e9%99%8d%e7%bb%b4%e9%97%ae%e9%a2%98 aria-label="4.1.1 降维问题">4.1.1 降维问题</a></li><li><a href=#412-%e5%87%a0%e4%bd%95%e8%a7%86%e8%a7%92%e6%9c%80%e5%a4%a7%e5%8c%96%e6%8a%95%e5%bd%b1%e6%96%b9%e5%b7%ae aria-label="4.1.2 几何视角：最大化投影方差">4.1.2 几何视角：最大化投影方差</a></li><li><a href=#413-%e6%b1%82%e8%a7%a3%e7%89%b9%e5%be%81%e5%80%bc%e5%88%86%e8%a7%a3 aria-label="4.1.3 求解：特征值分解">4.1.3 求解：特征值分解</a></li><li><a href=#414-%e4%bb%a3%e6%95%b0%e8%a7%86%e8%a7%92%e6%9c%80%e5%b0%8f%e5%8c%96%e9%87%8d%e6%9e%84%e8%af%af%e5%b7%ae aria-label="4.1.4 代数视角：最小化重构误差">4.1.4 代数视角：最小化重构误差</a></li><li><a href=#415-%e5%a5%87%e5%bc%82%e5%80%bc%e5%88%86%e8%a7%a3svd aria-label="4.1.5 奇异值分解（SVD）">4.1.5 奇异值分解（SVD）</a></li><li><a href=#416-%e5%ba%94%e7%94%a8%e5%9c%ba%e6%99%af aria-label="4.1.6 应用场景">4.1.6 应用场景</a></li></ul></li><li><a href=#42-%e8%81%9a%e7%b1%bb%e7%ae%97%e6%b3%95 aria-label="4.2 聚类算法">4.2 聚类算法</a><ul><li><a href=#421-k-means%e7%ae%97%e6%b3%95 aria-label="4.2.1 K-means算法">4.2.1 K-means算法</a></li><li><a href=#422-%e6%94%b6%e6%95%9b%e6%80%a7 aria-label="4.2.2 收敛性">4.2.2 收敛性</a></li><li><a href=#423-k-means%e6%94%b9%e8%bf%9b%e5%88%9d%e5%a7%8b%e5%8c%96 aria-label="4.2.3 K-means++：改进初始化">4.2.3 K-means++：改进初始化</a></li><li><a href=#424-%e5%b1%82%e6%ac%a1%e8%81%9a%e7%b1%bb aria-label="4.2.4 层次聚类">4.2.4 层次聚类</a></li><li><a href=#425-dbscan%e5%9f%ba%e4%ba%8e%e5%af%86%e5%ba%a6%e7%9a%84%e8%81%9a%e7%b1%bb aria-label="4.2.5 DBSCAN：基于密度的聚类">4.2.5 DBSCAN：基于密度的聚类</a></li><li><a href=#426-%e5%ba%94%e7%94%a8%e5%9c%ba%e6%99%af aria-label="4.2.6 应用场景">4.2.6 应用场景</a></li></ul></li></ul></li><li><a href=#%e7%ac%ac%e4%ba%94%e7%ab%a0%e4%bc%a0%e7%bb%9f%e6%9c%ba%e5%99%a8%e5%ad%a6%e4%b9%a0%e7%9a%84%e5%ba%94%e7%94%a8%e5%9c%ba%e6%99%af aria-label=第五章：传统机器学习的应用场景>第五章：传统机器学习的应用场景</a><ul><li><a href=#51-%e9%87%91%e8%9e%8d%e9%a2%86%e5%9f%9f aria-label="5.1 金融领域">5.1 金融领域</a><ul><li><a href=#511-%e4%bf%a1%e7%94%a8%e8%af%84%e5%88%86 aria-label="5.1.1 信用评分">5.1.1 信用评分</a></li><li><a href=#512-%e6%ac%ba%e8%af%88%e6%a3%80%e6%b5%8b aria-label="5.1.2 欺诈检测">5.1.2 欺诈检测</a></li></ul></li><li><a href=#52-%e5%8c%bb%e7%96%97%e5%81%a5%e5%ba%b7 aria-label="5.2 医疗健康">5.2 医疗健康</a><ul><li><a href=#521-%e7%96%be%e7%97%85%e8%af%8a%e6%96%ad aria-label="5.2.1 疾病诊断">5.2.1 疾病诊断</a></li><li><a href=#522-%e8%8d%af%e7%89%a9%e5%8f%91%e7%8e%b0 aria-label="5.2.2 药物发现">5.2.2 药物发现</a></li></ul></li><li><a href=#53-%e6%8e%a8%e8%8d%90%e7%b3%bb%e7%bb%9f aria-label="5.3 推荐系统">5.3 推荐系统</a><ul><li><a href=#531-%e5%8d%8f%e5%90%8c%e8%bf%87%e6%bb%a4 aria-label="5.3.1 协同过滤">5.3.1 协同过滤</a></li><li><a href=#532-%e5%86%85%e5%ae%b9%e6%8e%a8%e8%8d%90 aria-label="5.3.2 内容推荐">5.3.2 内容推荐</a></li><li><a href=#533-%e6%8e%92%e5%ba%8f%e5%ad%a6%e4%b9%a0 aria-label="5.3.3 排序学习">5.3.3 排序学习</a></li></ul></li><li><a href=#54-%e8%87%aa%e7%84%b6%e8%af%ad%e8%a8%80%e5%a4%84%e7%90%86nlp aria-label="5.4 自然语言处理（NLP）">5.4 自然语言处理（NLP）</a><ul><li><a href=#541-%e6%96%87%e6%9c%ac%e5%88%86%e7%b1%bb aria-label="5.4.1 文本分类">5.4.1 文本分类</a></li><li><a href=#542-%e4%b8%bb%e9%a2%98%e6%a8%a1%e5%9e%8b aria-label="5.4.2 主题模型">5.4.2 主题模型</a></li><li><a href=#543-%e5%91%bd%e5%90%8d%e5%ae%9e%e4%bd%93%e8%af%86%e5%88%abner aria-label="5.4.3 命名实体识别（NER）">5.4.3 命名实体识别（NER）</a></li></ul></li><li><a href=#55-%e8%ae%a1%e7%ae%97%e6%9c%ba%e8%a7%86%e8%a7%89 aria-label="5.5 计算机视觉">5.5 计算机视觉</a><ul><li><a href=#551-%e5%9b%be%e5%83%8f%e5%88%86%e7%b1%bb%e4%bc%a0%e7%bb%9f%e6%96%b9%e6%b3%95 aria-label="5.5.1 图像分类（传统方法）">5.5.1 图像分类（传统方法）</a></li><li><a href=#552-%e7%9b%ae%e6%a0%87%e6%a3%80%e6%b5%8b aria-label="5.5.2 目标检测">5.5.2 目标检测</a></li></ul></li></ul></li><li><a href=#%e7%ac%ac%e5%85%ad%e7%ab%a0%e6%9c%aa%e6%9d%a5%e5%b1%95%e6%9c%9b aria-label=第六章：未来展望>第六章：未来展望</a><ul><li><a href=#61-%e4%bc%a0%e7%bb%9f%e6%9c%ba%e5%99%a8%e5%ad%a6%e4%b9%a0%e7%9a%84%e7%8e%b0%e7%8a%b6 aria-label="6.1 传统机器学习的现状">6.1 传统机器学习的现状</a></li><li><a href=#62-%e6%9c%aa%e6%9d%a5%e5%8f%91%e5%b1%95%e8%b6%8b%e5%8a%bf aria-label="6.2 未来发展趋势">6.2 未来发展趋势</a><ul><li><a href=#621-%e8%87%aa%e5%8a%a8%e6%9c%ba%e5%99%a8%e5%ad%a6%e4%b9%a0automl aria-label="6.2.1 自动机器学习（AutoML）">6.2.1 自动机器学习（AutoML）</a></li><li><a href=#622-%e5%8f%af%e8%a7%a3%e9%87%8a%e6%80%a7aixai aria-label="6.2.2 可解释性AI（XAI）">6.2.2 可解释性AI（XAI）</a></li><li><a href=#623-%e5%9b%a0%e6%9e%9c%e6%8e%a8%e6%96%ad aria-label="6.2.3 因果推断">6.2.3 因果推断</a></li><li><a href=#624-%e8%bf%81%e7%a7%bb%e5%ad%a6%e4%b9%a0%e4%b8%8e%e5%b0%8f%e6%a0%b7%e6%9c%ac%e5%ad%a6%e4%b9%a0 aria-label="6.2.4 迁移学习与小样本学习">6.2.4 迁移学习与小样本学习</a></li><li><a href=#625-%e5%9c%a8%e7%ba%bf%e5%ad%a6%e4%b9%a0%e4%b8%8e%e5%bc%ba%e5%8c%96%e5%ad%a6%e4%b9%a0 aria-label="6.2.5 在线学习与强化学习">6.2.5 在线学习与强化学习</a></li><li><a href=#626-%e4%bc%a0%e7%bb%9f%e7%ae%97%e6%b3%95%e4%b8%8e%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0%e7%9a%84%e8%9e%8d%e5%90%88 aria-label="6.2.6 传统算法与深度学习的融合">6.2.6 传统算法与深度学习的融合</a></li><li><a href=#627-%e9%b2%81%e6%a3%92%e6%80%a7%e4%b8%8e%e5%ae%89%e5%85%a8%e6%80%a7 aria-label="6.2.7 鲁棒性与安全性">6.2.7 鲁棒性与安全性</a></li></ul></li><li><a href=#63-%e4%bc%a0%e7%bb%9f%e6%9c%ba%e5%99%a8%e5%ad%a6%e4%b9%a0%e7%9a%84%e9%95%bf%e6%9c%9f%e4%bb%b7%e5%80%bc aria-label="6.3 传统机器学习的长期价值">6.3 传统机器学习的长期价值</a></li><li><a href=#64-%e7%bb%93%e8%ae%ba aria-label="6.4 结论">6.4 结论</a></li></ul></li><li><a href=#%e5%8f%82%e8%80%83%e6%96%87%e7%8c%ae aria-label=参考文献>参考文献</a></li></ul></div></details></div><div class=post-content><h2 id=引言从统计学到机器学习>引言：从统计学到机器学习<a hidden class=anchor aria-hidden=true href=#引言从统计学到机器学习>#</a></h2><p>1956年，达特茅斯会议上正式提出了"人工智能"这个词。但在那之前的一百年里，统计学家们已经在用数学工具从数据中提取规律。高斯在1809年就用最小二乘法解决了天文学中的观测数据拟合问题，这可以看作是最早的机器学习算法。</p><p>机器学习和统计学习，本质上是一回事：从数据中学习规律，并用这些规律做出预测。只是出发点略有不同——统计学家关注估计的可靠性和显著性检验，而计算机科学家更关心算法的计算效率和泛化能力。</p><p>当我们说"传统机器学习"时，指的是深度学习时代之前的那些经典算法。这些算法虽然不像神经网络那样"万能"，但在数据量有限、需要可解释性的场景下，依然发挥着不可替代的作用。</p><h2 id=第一章统计学习的理论基础>第一章：统计学习的理论基础<a hidden class=anchor aria-hidden=true href=#第一章统计学习的理论基础>#</a></h2><h3 id=11-学习问题的数学框架>1.1 学习问题的数学框架<a hidden class=anchor aria-hidden=true href=#11-学习问题的数学框架>#</a></h3><p>假设我们有一个数据集 $D = {(x_1, y_1), (x_2, y_2), \ldots, (x_n, y_n)}$，其中 $x_i \in \mathcal{X}$ 是输入（特征），$y_i \in \mathcal{Y}$ 是输出（标签）。我们的目标是找到一个函数 $f: \mathcal{X} \to \mathcal{Y}$，使得对于新的输入 $x$，$f(x)$ 能准确预测对应的 $y$。</p><p>但在统计学习的框架下，我们还需要引入概率论的概念。假设数据是按照某个未知的联合分布 $P(X,Y)$ 生成的，我们的目标是学习一个决策函数 $f$，使得期望风险最小化：</p><p>$$R(f) = \mathbb{E}_{(X,Y) \sim P}[L(Y, f(X))]$$</p><p>其中 $L$ 是损失函数。对于回归问题，常用平方损失；对于分类问题，常用0-1损失或交叉熵损失。</p><p>问题在于：我们不知道 $P(X,Y)$，无法直接计算 $R(f)$。我们只能用经验风险（Empirical Risk）来近似：</p><p>$$\hat{R}(f) = \frac{1}{n}\sum_{i=1}^n L(y_i, f(x_i))$$</p><p>这就是经验风险最小化（ERM）的基本思想。但直接最小化经验风险会导致过拟合（overfitting）。</p><h3 id=12-偏差-方差权衡>1.2 偏差-方差权衡<a hidden class=anchor aria-hidden=true href=#12-偏差-方差权衡>#</a></h3><p>这是统计学习中最重要的概念之一。模型的预测误差可以分解为三个部分：</p><p>$$\mathbb{E}[(y - \hat{f}(x))^2] = \text{Bias}[\hat{f}(x)]^2 + \text{Var}[\hat{f}(x)] + \sigma^2$$</p><p>其中：</p><ul><li>$\text{Bias}[\hat{f}(x)] = \mathbb{E}[\hat{f}(x)] - f^{\ast}(x)$：模型预测的期望与真实值的差距</li><li>$\text{Var}[\hat{f}(x)] = \mathbb{E}[(\hat{f}(x) - \mathbb{E}[\hat{f}(x)])^2]$：模型预测的方差</li><li>$\sigma^2$：不可约误差（数据本身的噪声）</li></ul><p><strong>偏差</strong>反映了模型的"假设强度"。如果模型过于简单（比如用线性模型拟合高度非线性的数据），会产生高偏差，导致欠拟合。</p><p><strong>方差</strong>反映了模型对数据波动的敏感程度。如果模型过于复杂（比如高阶多项式拟合），会记住训练数据的噪声，产生高方差，导致过拟合。</p><p>偏差-方差权衡的核心思想是：我们需要在模型复杂度之间找到一个平衡点。</p><h3 id=13-正则化控制模型复杂度的数学工具>1.3 正则化：控制模型复杂度的数学工具<a hidden class=anchor aria-hidden=true href=#13-正则化控制模型复杂度的数学工具>#</a></h3><p>为了防止过拟合，我们在目标函数中加入正则化项。最常见的形式是：</p><p>$$\min_f \frac{1}{n}\sum_{i=1}^n L(y_i, f(x_i)) + \lambda \Omega(f)$$</p><p>其中 $\Omega(f)$ 是正则化项，$\lambda \geq 0$ 是超参数。</p><p><strong>L2正则化</strong>（岭回归）：
$$\Omega(f) = |w|<em>2^2 = \sum</em>{j=1}^d w_j^2$$</p><p>L2正则化倾向于让权重变小但不为零，相当于对权重施加了高斯先验。</p><p><strong>L1正则化</strong>（Lasso）：
$$\Omega(f) = |w|<em>1 = \sum</em>{j=1}^d |w_j|$$</p><p>L1正则化倾向于产生稀疏解（很多权重为零），相当于对权重施加了拉普拉斯先验。</p><h3 id=14-泛化误差与pac学习框架>1.4 泛化误差与PAC学习框架<a hidden class=anchor aria-hidden=true href=#14-泛化误差与pac学习框架>#</a></h3><p>一个关键问题是：经验风险最小化是否能保证泛化能力？PAC（Probably Approximately Correct）学习框架给出了理论保证。</p><p>设 $\mathcal{F}$ 是一个假设类，如果对于任意 $\epsilon, \delta > 0$，存在样本量 $n(\epsilon, \delta)$，使得当 $n \geq n(\epsilon, \delta)$ 时，经验风险最小化算法以至少 $1-\delta$ 的概率找到一个假设 $f$，满足 $R(f) - R(f^{\ast}) \leq \epsilon$，则称 $\mathcal{F}$ 是PAC可学习的。</p><p>根据VC维理论，经验风险与期望风险的差距有如下界限：</p><p>$$R(f) \leq \hat{R}(f) + \mathcal{O}\left(\sqrt{\frac{d \log(n/d) + \log(1/\delta)}{n}}\right)$$</p><p>其中 $d$ 是VC维。这告诉我们：模型复杂度越高，需要的样本量就越大。</p><h2 id=第二章经典监督学习算法>第二章：经典监督学习算法<a hidden class=anchor aria-hidden=true href=#第二章经典监督学习算法>#</a></h2><h3 id=21-线性回归统计学习的起点>2.1 线性回归：统计学习的起点<a hidden class=anchor aria-hidden=true href=#21-线性回归统计学习的起点>#</a></h3><h4 id=211-基本模型>2.1.1 基本模型<a hidden class=anchor aria-hidden=true href=#211-基本模型>#</a></h4><p>线性回归是最简单的回归模型，假设输出 $y$ 是输入 $x$ 的线性函数：</p><p>$$y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \cdots + \beta_p x_p + \epsilon$$</p><p>其中 $\epsilon \sim \mathcal{N}(0, \sigma^2)$ 是噪声项。用矩阵表示：</p><p>$$Y = X\beta + \epsilon$$</p><p>其中 $X$ 是 $n \times (p+1)$ 的设计矩阵，$\beta = (\beta_0, \beta_1, \ldots, \beta_p)^T$。</p><h4 id=212-最小二乘估计>2.1.2 最小二乘估计<a hidden class=anchor aria-hidden=true href=#212-最小二乘估计>#</a></h4><p>最小二乘法的目标是最小化残差平方和：</p><p>$$\min_\beta |Y - X\beta|_2^2$$</p><p>这是一个凸优化问题。对 $\beta$ 求导并令导数为零：</p><p>$$\frac{\partial}{\partial \beta} |Y - X\beta|_2^2 = -2X^T(Y - X\beta) = 0$$</p><p>解这个方程，得到正规方程（Normal Equation）：</p><p>$$X^TX\beta = X^TY$$</p><p>如果 $X^TX$ 可逆，则唯一解为：</p><p>$$\hat{\beta} = (X^TX)^{-1}X^TY$$</p><p>这就是<strong>普通最小二乘估计（OLS）</strong>。</p><p><strong>几何解释</strong>：$\hat{Y} = X\hat{\beta}$ 是 $Y$ 在 $X$ 的列空间上的正交投影。残差 $e = Y - \hat{Y}$ 与 $X$ 的每一列都正交，即 $X^Te = 0$。</p><h4 id=213-统计性质>2.1.3 统计性质<a hidden class=anchor aria-hidden=true href=#213-统计性质>#</a></h4><p>如果误差项满足高斯-马尔可夫假设（$\mathbb{E}[\epsilon] = 0$，$\text{Cov}(\epsilon) = \sigma^2 I_n$），那么OLS估计量具有以下性质：</p><p><strong>无偏性</strong>：
$$\mathbb{E}[\hat{\beta}] = \beta$$</p><p>证明：
$$\hat{\beta} = (X^TX)^{-1}X^TY = (X^TX)^{-1}X^T(X\beta + \epsilon) = \beta + (X^TX)^{-1}X^T\epsilon$$
$$\mathbb{E}[\hat{\beta}] = \beta + (X^TX)^{-1}X^T\mathbb{E}[\epsilon] = \beta$$</p><p><strong>有效性（BLUE）</strong>：在所有线性无偏估计中，OLS的方差最小。</p><p><strong>协方差矩阵</strong>：
$$\text{Cov}(\hat{\beta}) = \sigma^2 (X^TX)^{-1}$$</p><h4 id=214-岭回归与lasso>2.1.4 岭回归与Lasso<a hidden class=anchor aria-hidden=true href=#214-岭回归与lasso>#</a></h4><p>当 $X^TX$ 接近奇异矩阵时（多重共线性），OLS估计会变得不稳定。正则化是解决方案。</p><p><strong>岭回归（Ridge Regression）</strong>：
$$\min_\beta |Y - X\beta|_2^2 + \lambda |\beta|_2^2$$</p><p>解为：
$$\hat{\beta}_{\text{ridge}} = (X^TX + \lambda I)^{-1}X^TY$$</p><p>添加 $\lambda I$ 确保矩阵可逆。</p><p><strong>Lasso</strong>：
$$\min_\beta \frac{1}{2n}|Y - X\beta|_2^2 + \lambda |\beta|_1$$</p><p>Lasso的优化问题是非光滑的（由于L1范数的绝对值），没有解析解，需要用坐标下降法（Coordinate Descent）求解。</p><p><strong>重要差异</strong>：Lasso可以进行变量选择（稀疏性），而岭回归不能。这是因为L1范数的几何形状是菱形，更容易与等值线在坐标轴上相交。</p><h4 id=215-应用场景>2.1.5 应用场景<a hidden class=anchor aria-hidden=true href=#215-应用场景>#</a></h4><ul><li><strong>房价预测</strong>：根据房屋面积、房间数、地段等特征预测房价</li><li><strong>金融分析</strong>：根据公司财务指标预测股票收益率</li><li><strong>医疗研究</strong>：根据患者生理指标预测疾病风险</li></ul><p><strong>案例</strong>：波士顿房价数据集</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>特征： crim（犯罪率）, zn（住宅用地比例）, indus（非零售商业用地比例）,
</span></span><span class=line><span class=cl>      chas（是否临河）, nox（氮氧化物浓度）, rm（平均房间数）, age（房龄）,
</span></span><span class=line><span class=cl>      dis（到就业中心距离）, rad（高速可达性）, tax（房产税）,
</span></span><span class=line><span class=cl>      ptratio（师生比）, black（黑人比例）, lstat（低收入人群比例）
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>目标： medv（房屋中位价，单位千美元）
</span></span></code></pre></div><p>岭回归可以帮助处理多重共线性问题（比如zn和indus高度相关）。</p><h3 id=22-逻辑回归分类问题的经典方法>2.2 逻辑回归：分类问题的经典方法<a hidden class=anchor aria-hidden=true href=#22-逻辑回归分类问题的经典方法>#</a></h3><h4 id=221-从线性回归到逻辑回归>2.2.1 从线性回归到逻辑回归<a hidden class=anchor aria-hidden=true href=#221-从线性回归到逻辑回归>#</a></h4><p>为什么不能直接用线性回归做分类？如果 $y \in {0, 1}$，线性回归会预测任意实数，而我们需要概率输出。</p><p>逻辑回归引入了Sigmoid函数（又称Logistic函数）：
$$\sigma(z) = \frac{1}{1 + e^{-z}}$$</p><p>模型假设：
$$P(y=1|x) = \sigma(w^Tx + b) = \frac{1}{1 + e^{-(w^Tx + b)}}$$</p><p>$$P(y=0|x) = 1 - P(y=1|x) = \frac{e^{-(w^Tx + b)}}{1 + e^{-(w^Tx + b)}}$$</p><p>Sigmoid函数的性质：</p><ul><li>$\sigma(0) = 0.5$</li><li>$\sigma(+\infty) \to 1$，$\sigma(-\infty) \to 0$</li><li>$\sigma&rsquo;(z) = \sigma(z)(1 - \sigma(z))$</li></ul><h4 id=222-似然函数与极大似然估计>2.2.2 似然函数与极大似然估计<a hidden class=anchor aria-hidden=true href=#222-似然函数与极大似然估计>#</a></h4><p>给定数据集 ${(x_i, y_i)}_{i=1}^n$，其中 $y_i \in {0, 1}$，似然函数为：</p><p>$$L(w, b) = \prod_{i=1}^n P(y_i|x_i) = \prod_{i=1}^n [\sigma(w^Tx_i + b)]^{y_i} [1 - \sigma(w^Tx_i + b)]^{1 - y_i}$$</p><p>取对数，得到对数似然：</p><p>$$\ell(w, b) = \sum_{i=1}^n [y_i \log \sigma(z_i) + (1 - y_i) \log(1 - \sigma(z_i))]$$</p><p>其中 $z_i = w^Tx_i + b$。</p><p>极大似然估计：
$$\max_{w, b} \ell(w, b)$$</p><p>等价于最小化负对数似然（也是交叉熵损失）：
$$\min_{w, b} J(w, b) = -\sum_{i=1}^n [y_i \log \sigma(z_i) + (1 - y_i) \log(1 - \sigma(z_i))]$$</p><h4 id=223-梯度下降法>2.2.3 梯度下降法<a hidden class=anchor aria-hidden=true href=#223-梯度下降法>#</a></h4><p>对 $J$ 求梯度：
$$\frac{\partial J}{\partial w_j} = -\sum_{i=1}^n [y_i - \sigma(z_i)] x_{i,j}$$</p><p>$$\frac{\partial J}{\partial b} = -\sum_{i=1}^n [y_i - \sigma(z_i)]$$</p><p>梯度下降更新规则：
$$w_j := w_j - \eta \frac{\partial J}{\partial w_j} = w_j + \eta \sum_{i=1}^n [y_i - \sigma(z_i)] x_{i,j}$$</p><p>$$b := b - \eta \frac{\partial J}{\partial b} = b + \eta \sum_{i=1}^n [y_i - \sigma(z_i)]$$</p><p>其中 $\eta$ 是学习率。</p><p><strong>随机梯度下降（SGD）</strong>：每次只使用一个样本更新参数，计算更快但方差更大。</p><p><strong>小批量梯度下降（Mini-batch GD）</strong>：每次使用一批样本，介于全量和单个样本之间。</p><h4 id=224-正则化逻辑回归>2.2.4 正则化逻辑回归<a hidden class=anchor aria-hidden=true href=#224-正则化逻辑回归>#</a></h4><p>为防止过拟合，加入L2正则化：</p><p>$$J(w, b) = -\sum_{i=1}^n [y_i \log \sigma(z_i) + (1 - y_i) \log(1 - \sigma(z_i))] + \frac{\lambda}{2} |w|_2^2$$</p><p>梯度变为：
$$\frac{\partial J}{\partial w_j} = -\sum_{i=1}^n [y_i - \sigma(z_i)] x_{i,j} + \lambda w_j$$</p><p>这相当于在权重上施加了一个"拉回"的力，防止权重过大。</p><h4 id=225-应用场景>2.2.5 应用场景<a hidden class=anchor aria-hidden=true href=#225-应用场景>#</a></h4><ul><li><strong>垃圾邮件检测</strong>：根据邮件内容、发件人等特征判断是否为垃圾邮件</li><li><strong>信用评分</strong>：根据用户收入、信用历史等预测违约概率</li><li><strong>医疗诊断</strong>：根据症状、检验结果预测疾病概率</li><li><strong>广告点击率（CTR）预测</strong>：预测用户是否点击广告</li></ul><h3 id=23-支持向量机最大间隔分类器>2.3 支持向量机：最大间隔分类器<a hidden class=anchor aria-hidden=true href=#23-支持向量机最大间隔分类器>#</a></h3><h4 id=231-几何直觉寻找最大间隔>2.3.1 几何直觉：寻找最大间隔<a hidden class=anchor aria-hidden=true href=#231-几何直觉寻找最大间隔>#</a></h4><p>支持向量机（SVM）的核心思想是：找到一个超平面，不仅能正确分类，而且离两类数据点的距离都尽可能大。</p><p>在二维空间中，超平面就是一条直线：$w_1 x_1 + w_2 x_2 + b = 0$</p><p>点 $(x_1, x_2)$ 到超平面的距离：
$$d = \frac{|w_1 x_1 + w_2 x_2 + b|}{\sqrt{w_1^2 + w_2^2}}$$</p><p>SVM的目标是：最大化最小距离。</p><h4 id=232-硬间隔svm>2.3.2 硬间隔SVM<a hidden class=anchor aria-hidden=true href=#232-硬间隔svm>#</a></h4><p>对于线性可分的数据，假设分类标签 $y_i \in {-1, +1}$，约束条件为：</p><p>$$y_i (w^T x_i + b) \geq 1, \quad i = 1, \ldots, n$$</p><p>这个约束保证了所有分类正确的点距离超平面至少为 $1/|w|$。</p><p>优化问题：
$$\min_{w, b} \frac{1}{2} |w|_2^2$$
$$\text{s.t. } y_i (w^T x_i + b) \geq 1, \quad i = 1, \ldots, n$$</p><p><strong>为什么最小化 $|w|_2^2$？</strong></p><p>因为间隔大小为 $2/|w|$，最大化间隔等价于最小化 $|w|$。</p><h4 id=233-对偶问题与拉格朗日乘子法>2.3.3 对偶问题与拉格朗日乘子法<a hidden class=anchor aria-hidden=true href=#233-对偶问题与拉格朗日乘子法>#</a></h4><p>引入拉格朗日乘子 $\alpha_i \geq 0$，构造拉格朗日函数：</p><p>$$\mathcal{L}(w, b, \alpha) = \frac{1}{2}|w|^2 - \sum_{i=1}^n \alpha_i [y_i (w^T x_i + b) - 1]$$</p><p>原问题的对偶问题：
$$\max_{\alpha \geq 0} \min_{w, b} \mathcal{L}(w, b, \alpha)$$</p><p>先对 $w, b$ 求导并令导数为零：
$$\frac{\partial \mathcal{L}}{\partial w} = w - \sum_{i=1}^n \alpha_i y_i x_i = 0 \Rightarrow w = \sum_{i=1}^n \alpha_i y_i x_i$$</p><p>$$\frac{\partial \mathcal{L}}{\partial b} = -\sum_{i=1}^n \alpha_i y_i = 0 \Rightarrow \sum_{i=1}^n \alpha_i y_i = 0$$</p><p>代回拉格朗日函数，得到对偶问题：
$$\max_\alpha \sum_{i=1}^n \alpha_i - \frac{1}{2}\sum_{i=1}^n \sum_{j=1}^n \alpha_i \alpha_j y_i y_j x_i^T x_j$$</p><p>约束：
$$\alpha_i \geq 0, \quad \sum_{i=1}^n \alpha_i y_i = 0$$</p><p>这是一个凸二次规划问题，可以用SMO（Sequential Minimal Optimization）算法高效求解。</p><h4 id=234-支持向量与核技巧>2.3.4 支持向量与核技巧<a hidden class=anchor aria-hidden=true href=#234-支持向量与核技巧>#</a></h4><p><strong>支持向量（Support Vectors）</strong>：$\alpha_i > 0$ 的样本点。这些点位于间隔边界上。</p><p>KKT条件告诉我们：
$$\alpha_i [y_i (w^T x_i + b) - 1] = 0$$</p><p>如果 $\alpha_i > 0$，则 $y_i (w^T x_i + b) = 1$，即该点在边界上。</p><p>决策函数可以表示为：
$$f(x) = \text{sign}\left(\sum_{i=1}^n \alpha_i y_i x_i^T x + b\right)$$</p><p><strong>核技巧（Kernel Trick）</strong>：将特征映射到高维空间 $\phi(x)$，使得线性不可分的问题变得可分。</p><p>只关注内积 $x_i^T x_j$，替换为核函数 $K(x_i, x_j) = \phi(x_i)^T \phi(x_j)$。</p><p>常用核函数：</p><ul><li><strong>线性核</strong>：$K(x_i, x_j) = x_i^T x_j$</li><li><strong>多项式核</strong>：$K(x_i, x_j) = (x_i^T x_j + c)^d$</li><li><strong>高斯核（RBF）</strong>：$K(x_i, x_j) = \exp\left(-\frac{|x_i - x_j|^2}{2\sigma^2}\right)$</li><li><strong>Sigmoid核</strong>：$K(x_i, x_j) = \tanh(\gamma x_i^T x_j + r)$</li></ul><h4 id=235-软间隔svm>2.3.5 软间隔SVM<a hidden class=anchor aria-hidden=true href=#235-软间隔svm>#</a></h4><p>对于线性不可分的数据，引入松弛变量 $\xi_i \geq 0$，允许部分点被误分类：</p><p>$$y_i (w^T x_i + b) \geq 1 - \xi_i, \quad i = 1, \ldots, n$$</p><p>优化问题：
$$\min_{w, b, \xi} \frac{1}{2}|w|^2 + C \sum_{i=1}^n \xi_i$$
$$\text{s.t. } y_i (w^T x_i + b) \geq 1 - \xi_i, \quad \xi_i \geq 0$$</p><p>$C$ 是正则化参数，控制间隔与误分类之间的权衡。$C \to \infty$ 时，退化为硬间隔SVM。</p><h4 id=236-应用场景>2.3.6 应用场景<a hidden class=anchor aria-hidden=true href=#236-应用场景>#</a></h4><ul><li><strong>文本分类</strong>：文档分类、情感分析</li><li><strong>图像识别</strong>：手写数字识别（MNIST）</li><li><strong>生物信息学</strong>：蛋白质分类、基因表达数据分析</li><li><strong>异常检测</strong>：利用单分类SVM检测异常数据</li></ul><h3 id=24-决策树基于规则的分类与回归>2.4 决策树：基于规则的分类与回归<a hidden class=anchor aria-hidden=true href=#24-决策树基于规则的分类与回归>#</a></h3><h4 id=241-基本思想>2.4.1 基本思想<a hidden class=anchor aria-hidden=true href=#241-基本思想>#</a></h4><p>决策树通过一系列"如果-那么"规则进行预测。树由节点和边组成：</p><ul><li><strong>根节点</strong>：整个数据集</li><li><strong>内部节点</strong>：对某个特征进行测试</li><li><strong>叶子节点</strong>：预测值（分类中的类别，回归中的数值）</li></ul><h4 id=242-id3算法基于信息增益>2.4.2 ID3算法：基于信息增益<a hidden class=anchor aria-hidden=true href=#242-id3算法基于信息增益>#</a></h4><p>ID3算法（Iterative Dichotomiser 3）使用信息增益选择分裂特征。</p><p><strong>熵（Entropy）</strong>：衡量数据集的不纯度</p><p>对于分类问题，假设有 $K$ 个类别，第 $k$ 类的比例为 $p_k$：</p><p>$$H(D) = -\sum_{k=1}^K p_k \log_2 p_k$$</p><p>当所有样本属于同一类时，$H(D) = 0$（最纯）；当各类均匀分布时，$H(D)$ 最大（最不纯）。</p><p><strong>条件熵</strong>：给定特征 $A$ 后的熵</p><p>$$H(D|A) = \sum_{v \in \text{Values}(A)} \frac{|D_v|}{|D|} H(D_v)$$</p><p>其中 $D_v$ 是特征 $A$ 取值为 $v$ 的子集。</p><p><strong>信息增益</strong>：分裂前后的熵减少量</p><p>$$\text{Gain}(D, A) = H(D) - H(D|A)$$</p><p>ID3选择使信息增益最大的特征进行分裂。</p><h4 id=243-c45算法基于信息增益率>2.4.3 C4.5算法：基于信息增益率<a hidden class=anchor aria-hidden=true href=#243-c45算法基于信息增益率>#</a></h4><p>ID3的缺点：倾向于选择取值多的特征（如ID）。C4.5用**信息增益率（Information Gain Ratio）**修正：</p><p>$$\text{GainRatio}(D, A) = \frac{\text{Gain}(D, A)}{\text{SplitInfo}(D, A)}$$</p><p>其中分裂信息：
$$\text{SplitInfo}(D, A) = -\sum_{v \in \text{Values}(A)} \frac{|D_v|}{|D|} \log_2 \frac{|D_v|}{|D|}$$</p><h4 id=244-cart算法基尼指数与回归树>2.4.4 CART算法：基尼指数与回归树<a hidden class=anchor aria-hidden=true href=#244-cart算法基尼指数与回归树>#</a></h4><p>CART（Classification and Regression Trees）可以处理分类和回归问题。</p><p><strong>分类树</strong>：使用基尼指数（Gini Index）</p><p>$$\text{Gini}(D) = 1 - \sum_{k=1}^K p_k^2$$</p><p>基尼指数越小，数据集越纯。选择使基尼指数下降最大的分裂。</p><p><strong>回归树</strong>：预测值是叶子节点中样本的均值</p><p>假设叶子节点 $R_m$ 中有 $n_m$ 个样本，预测值为：
$$\hat{c}<em>m = \frac{1}{n_m}\sum</em>{x_i \in R_m} y_i$$</p><p>分裂准则：最小化平方误差
$$\sum_{x_i \in R_m} (y_i - \hat{c}_m)^2$$</p><h4 id=245-剪枝防止过拟合>2.4.5 剪枝：防止过拟合<a hidden class=anchor aria-hidden=true href=#245-剪枝防止过拟合>#</a></h4><p>决策树容易过拟合，需要剪枝。</p><p><strong>预剪枝（Pre-pruning）</strong>：</p><ul><li>限制树的最大深度</li><li>限制每个节点的最小样本数</li><li>如果信息增益小于阈值，停止分裂</li></ul><p><strong>后剪枝（Post-pruning）</strong>：</p><ul><li>从完全生长的树开始，自底向上剪枝</li><li>用验证集评估剪枝效果</li><li>代价复杂度剪枝（Cost-Complexity Pruning）</li></ul><p>定义树 $T$ 的代价复杂度：
$$C_\alpha(T) = \frac{1}{N} \sum_{x_i \in \text{Training}} L(y_i, \hat{y}_i) + \alpha |T|$$</p><p>其中 $|T|$ 是叶子节点数，$\alpha$ 是正则化参数。选择使 $C_\alpha(T)$ 最小的子树。</p><h4 id=246-特征重要性>2.4.6 特征重要性<a hidden class=anchor aria-hidden=true href=#246-特征重要性>#</a></h4><p>决策树可以提供特征重要性（Feature Importance）：</p><p>$$\text{Importance}<em>j = \sum</em>{t \in \text{Splits using } j} \frac{n_t}{N} \times \Delta \text{Impurity}(t)$$</p><p>其中 $\Delta \text{Impurity}(t)$ 是节点 $t$ 分裂前后的不纯度减少量。</p><h4 id=247-应用场景>2.4.7 应用场景<a hidden class=anchor aria-hidden=true href=#247-应用场景>#</a></h4><ul><li><strong>医疗诊断</strong>：根据症状和检查结果诊断疾病</li><li><strong>金融风控</strong>：评估贷款申请人的信用风险</li><li><strong>推荐系统</strong>：基于用户行为推荐商品</li><li><strong>客户细分</strong>：根据消费行为对客户分类</li></ul><h2 id=第三章集成学习集众智之长>第三章：集成学习：集众智之长<a hidden class=anchor aria-hidden=true href=#第三章集成学习集众智之长>#</a></h2><h3 id=31-偏差-方差分解与集成学习>3.1 偏差-方差分解与集成学习<a hidden class=anchor aria-hidden=true href=#31-偏差-方差分解与集成学习>#</a></h3><p>集成学习通过组合多个模型来提升性能。基本原理：</p><ul><li><p><strong>Bagging（Bootstrap Aggregating）</strong>：降低方差</p><ul><li>通过 bootstrap 采样创建多个训练集</li><li>每个模型独立训练</li><li>预测时取平均（回归）或投票（分类）</li><li>代表：随机森林</li></ul></li><li><p><strong>Boosting</strong>：降低偏差</p><ul><li>顺序训练模型，每个模型专注于前一个模型的错误</li><li>加权组合模型</li><li>代表：AdaBoost、Gradient Boosting、XGBoost、LightGBM</li></ul></li><li><p><strong>Stacking</strong>：结合多个不同类型模型的预测</p><ul><li>基模型：不同算法（如逻辑回归、SVM、决策树）</li><li>元模型：学习如何组合基模型的预测</li></ul></li></ul><h3 id=32-随机森林>3.2 随机森林<a hidden class=anchor aria-hidden=true href=#32-随机森林>#</a></h3><h4 id=321-算法原理>3.2.1 算法原理<a hidden class=anchor aria-hidden=true href=#321-算法原理>#</a></h4><p>随机森林是Bagging与决策树的结合，通过引入随机性减少相关性。</p><p><strong>训练过程</strong>：</p><ol><li>Bootstrap采样：从训练集有放回地抽取 $n$ 个样本，创建 $B$ 个训练集</li><li>对每个训练集训练一棵决策树</li><li>每次分裂时，从所有特征中随机选择 $m$ 个特征（通常 $m = \sqrt{p}$）</li><li>从这 $m$ 个特征中选择最优分裂特征</li></ol><p><strong>预测</strong>：</p><ul><li>分类：多数投票</li><li>回归：平均</li></ul><h4 id=322-为什么有效>3.2.2 为什么有效？<a hidden class=anchor aria-hidden=true href=#322-为什么有效>#</a></h4><p><strong>Bagging的作用</strong>：减少方差</p><ul><li>单棵决策树方差大（易过拟合）</li><li>取平均后，方差降低为 $\sigma^2/B$（假设独立）</li></ul><p><strong>特征随机性的作用</strong>：减少相关性</p><ul><li>如果使用全部特征，树之间高度相关</li><li>随机选择特征子集，增加多样性</li><li>不相关模型的平均更有效（根据方差公式：$\text{Var}(\bar{X}) = \frac{\sigma^2}{B} + \frac{B-1}{B}\rho\sigma^2$，其中 $\rho$ 是相关性）</li></ul><h4 id=323-超参数>3.2.3 超参数<a hidden class=anchor aria-hidden=true href=#323-超参数>#</a></h4><ul><li><code>n_estimators</code>：树的数量（越多越好，但计算成本增加）</li><li><code>max_depth</code>：树的最大深度（控制过拟合）</li><li><code>min_samples_split</code>：节点分裂的最小样本数</li><li><code>min_samples_leaf</code>：叶子节点的最小样本数</li><li><code>max_features</code>：每次分裂考虑的特征数（<code>"sqrt"</code>、<code>"log2"</code>或整数）</li></ul><h4 id=324-特征重要性out-of-bag>3.2.4 特征重要性（Out-of-Bag）<a hidden class=anchor aria-hidden=true href=#324-特征重要性out-of-bag>#</a></h4><p>随机森林的OOB（Out-of-Bag）样本（bootstrap中未被选中的样本）可以用于：</p><ul><li>估计泛化误差（无需验证集）</li><li>计算特征重要性</li></ul><p>特征重要性的计算：打乱特征 $j$ 的值，观察OOB误差的增加量。</p><h3 id=33-梯度提升树gbdt>3.3 梯度提升树（GBDT）<a hidden class=anchor aria-hidden=true href=#33-梯度提升树gbdt>#</a></h3><h4 id=331-核心思想>3.3.1 核心思想<a hidden class=anchor aria-hidden=true href=#331-核心思想>#</a></h4><p>梯度提升树通过拟合负梯度来逐步改进模型。</p><p>给定损失函数 $L(y, F(x))$，目标是最小化期望损失：</p><p>$$\min_F \mathbb{E}[L(y, F(x))]$$</p><p>用贪心算法：逐步添加弱学习器 $h_m(x)$：</p><p>$$F_m(x) = F_{m-1}(x) + h_m(x)$$</p><p>选择 $h_m$ 使损失下降最大：</p><p>$$h_m = \arg\min_h \sum_{i=1}^n L(y_i, F_{m-1}(x_i) + h(x_i))$$</p><h4 id=332-负梯度拟合>3.3.2 负梯度拟合<a hidden class=anchor aria-hidden=true href=#332-负梯度拟合>#</a></h4><p>对 $L$ 在 $F_{m-1}(x_i)$ 处做泰勒展开（一阶）：</p><p>$$L(y_i, F_{m-1}(x_i) + h(x_i)) \approx L(y_i, F_{m-1}(x_i)) + \frac{\partial L(y_i, F(x))}{\partial F(x)}\bigg|<em>{F = F</em>{m-1}} h(x_i)$$</p><p>负梯度：
$$r_{im} = -\frac{\partial L(y_i, F(x))}{\partial F(x)}\bigg|<em>{F = F</em>{m-1}}$$</p><p>因此，$h_m(x)$ 应该拟合负梯度 $r_{im}$。</p><p><strong>平方损失</strong>：$L = \frac{1}{2}(y - F)^2$
$$\frac{\partial L}{\partial F} = -(y - F)$$
负梯度：$r_{im} = y_i - F_{m-1}(x_i)$（残差）</p><p><strong>逻辑损失</strong>：$L = \log(1 + e^{-yF})$，其中 $y \in {-1, 1}$
$$\frac{\partial L}{\partial F} = \frac{-y e^{-yF}}{1 + e^{-yF}} = -\frac{y}{1 + e^{yF}}$$
负梯度：$r_{im} = \frac{y_i}{1 + e^{y_i F_{m-1}(x_i)}}$</p><h4 id=333-算法流程>3.3.3 算法流程<a hidden class=anchor aria-hidden=true href=#333-算法流程>#</a></h4><p><strong>输入</strong>：训练集 ${(x_i, y_i)}_{i=1}^n$，损失函数 $L$，学习率 $\eta$，树的数量 $M$</p><p><strong>步骤</strong>：</p><ol><li>初始化：$F_0(x) = \arg\min_c \sum_{i=1}^n L(y_i, c)$（对回归，取均值；对分类，取对数几率）</li><li>对于 $m = 1, 2, \ldots, M$：<ul><li>计算负梯度：$r_{im} = -\frac{\partial L(y_i, F_{m-1}(x_i))}{\partial F(x)}$</li><li>用决策树拟合 $(x_i, r_{im})$，得到区域 $R_{jm}$（$j = 1, \ldots, J_m$）</li><li>计算叶子节点预测值：$\gamma_{jm} = \arg\min_\gamma \sum_{x_i \in R_{jm}} L(y_i, F_{m-1}(x_i) + \gamma)$</li><li>更新模型：$F_m(x) = F_{m-1}(x) + \eta \sum_{j=1}^{J_m} \gamma_{jm} I(x \in R_{jm})$</li></ul></li></ol><h4 id=334-正则化>3.3.4 正则化<a hidden class=anchor aria-hidden=true href=#334-正则化>#</a></h4><p>GBDT通过多种方式防止过拟合：</p><ol><li><strong>学习率（Learning Rate）</strong>：$\eta \in (0, 1]$，控制每一步的步长</li><li><strong>树的数量（n_estimators）</strong>：使用早停法（Early Stopping）选择最佳数量</li><li><strong>树的复杂度</strong>：<ul><li><code>max_depth</code>：限制树深度</li><li><code>min_samples_split</code>、<code>min_samples_leaf</code>：控制叶子节点</li></ul></li><li><strong>子采样（Subsampling）</strong>：每棵树只使用部分数据（类似Bagging）</li></ol><h4 id=335-xgboost与lightgbm>3.3.5 XGBoost与LightGBM<a hidden class=anchor aria-hidden=true href=#335-xgboost与lightgbm>#</a></h4><p>**XGBoost（eXtreme Gradient Boosting）**的改进：</p><ul><li>二阶泰勒展开（同时使用一阶和二阶导数）</li><li>正则化项（叶子节点数和L2正则）</li><li>稀疏感知（处理缺失值）</li><li>并行化（特征级别）</li><li>列块设计（缓存优化）</li></ul><p><strong>LightGBM</strong>的改进：</p><ul><li>基于直方图（Histogram）的算法（将连续值离散化）</li><li>GOSS（Gradient-based One-Side Sampling）：只保留高梯度和随机低梯度样本</li><li>EFB（Exclusive Feature Bundling）：合并稀疏特征</li><li>Leaf-wise生长（优先分裂增益最大的叶子节点）</li></ul><h4 id=336-应用场景>3.3.6 应用场景<a hidden class=anchor aria-hidden=true href=#336-应用场景>#</a></h4><ul><li><strong>搜索排名</strong>：LambdaMART（基于GBDT的学习排序算法）</li><li><strong>欺诈检测</strong>：信用卡欺诈、税务欺诈</li><li><strong>点击率预测</strong>：广告CTR预测</li><li><strong>时间序列预测</strong>：销量预测、流量预测</li></ul><h3 id=34-adaboost自适应提升>3.4 AdaBoost：自适应提升<a hidden class=anchor aria-hidden=true href=#34-adaboost自适应提升>#</a></h3><h4 id=341-算法原理>3.4.1 算法原理<a hidden class=anchor aria-hidden=true href=#341-算法原理>#</a></h4><p>AdaBoost（Adaptive Boosting）通过加权训练样本，逐步关注难以分类的样本。</p><p><strong>输入</strong>：训练集 ${(x_i, y_i)}_{i=1}^n$，$y_i \in {-1, 1}$，迭代次数 $T$</p><p><strong>步骤</strong>：</p><ol><li>初始化样本权重：$w_i^{(1)} = 1/n$</li><li>对于 $t = 1, 2, \ldots, T$：<ul><li>用权重 $w_i^{(t)}$ 训练弱分类器 $h_t(x)$</li><li>计算分类误差：$\epsilon_t = \sum_{i=1}^n w_i^{(t)} I(y_i \neq h_t(x_i))$</li><li>计算分类器权重：$\alpha_t = \frac{1}{2}\log\frac{1 - \epsilon_t}{\epsilon_t}$</li><li>更新样本权重：$w_i^{(t+1)} = w_i^{(t)} \exp(-\alpha_t y_i h_t(x_i))$</li><li>归一化权重：$w_i^{(t+1)} = \frac{w_i^{(t+1)}}{\sum_{j=1}^n w_j^{(t+1)}}$</li></ul></li><li>最终分类器：$H(x) = \text{sign}\left(\sum_{t=1}^T \alpha_t h_t(x)\right)$</li></ol><h4 id=342-为什么有效>3.4.2 为什么有效？<a hidden class=anchor aria-hidden=true href=#342-为什么有效>#</a></h4><p>AdaBoost通过指数损失最小化：</p><p>$$L = \sum_{i=1}^n \exp(-y_i H(x_i))$$</p><p>其中 $H(x) = \sum_t \alpha_t h_t(x)$。</p><p>可以证明：每一步选择使误差最小的 $h_t$，等价于使指数损失下降最多。</p><p><strong>权重更新的含义</strong>：</p><ul><li>如果 $y_i = h_t(x_i)$（分类正确），权重减小</li><li>如果 $y_i \neq h_t(x_i)$（分类错误），权重增大</li><li>难以分类的样本权重越来越大，模型更关注这些样本</li></ul><h4 id=343-理论保证>3.4.3 理论保证<a hidden class=anchor aria-hidden=true href=#343-理论保证>#</a></h4><p>AdaBoost的泛化误差有如下界限：</p><p>$$P[H(x) \neq y] \leq P\left[\sum_{t=1}^T \alpha_t h_t(x) y \leq 0\right] \leq \prod_{t=1}^T \sqrt{1 - 4\gamma_t^2} \leq \exp\left(-2\sum_{t=1}^T \gamma_t^2\right)$$</p><p>其中 $\gamma_t = \frac{1}{2} - \epsilon_t$（边缘）。</p><p>如果每个弱分类器比随机猜测好（$\epsilon_t &lt; 0.5$），则AdaBoost会收敛到零训练误差。</p><h2 id=第四章无监督学习从数据中发现结构>第四章：无监督学习：从数据中发现结构<a hidden class=anchor aria-hidden=true href=#第四章无监督学习从数据中发现结构>#</a></h2><h3 id=41-主成分分析pca>4.1 主成分分析（PCA）<a hidden class=anchor aria-hidden=true href=#41-主成分分析pca>#</a></h3><h4 id=411-降维问题>4.1.1 降维问题<a hidden class=anchor aria-hidden=true href=#411-降维问题>#</a></h4><p>给定数据 $X \in \mathbb{R}^{n \times p}$，我们想找到一个低维表示 $Z \in \mathbb{R}^{n \times k}$（$k &lt; p$），保留尽可能多的信息。</p><h4 id=412-几何视角最大化投影方差>4.1.2 几何视角：最大化投影方差<a hidden class=anchor aria-hidden=true href=#412-几何视角最大化投影方差>#</a></h4><p>投影矩阵 $W \in \mathbb{R}^{p \times k}$，满足 $W^TW = I_k$（正交矩阵）。</p><p>投影后的数据：$Z = XW$</p><p>最大化投影方差：
$$\max_W \text{tr}(Z^TZ) = \max_W \text{tr}(W^TX^TXW)$$</p><p>约束：$W^TW = I_k$</p><h4 id=413-求解特征值分解>4.1.3 求解：特征值分解<a hidden class=anchor aria-hidden=true href=#413-求解特征值分解>#</a></h4><p>数据协方差矩阵：$\Sigma = \frac{1}{n-1}X^TX$</p><p>优化问题等价于：
$$\max_W \text{tr}(W^T\Sigma W), \quad W^TW = I_k$$</p><p>根据瑞利商理论，最优解是 $\Sigma$ 的前 $k$ 个最大特征值对应的特征向量。</p><p>设 $\Sigma$ 的特征值分解：$\Sigma = U \Lambda U^T$，其中 $\Lambda = \text{diag}(\lambda_1, \lambda_2, \ldots, \lambda_p)$，$\lambda_1 \geq \lambda_2 \geq \ldots \geq \lambda_p \geq 0$</p><p>主成分：$W = [u_1, u_2, \ldots, u_k]$</p><p><strong>方差解释比例</strong>：
$$\frac{\sum_{i=1}^k \lambda_i}{\sum_{i=1}^p \lambda_i}$$</p><h4 id=414-代数视角最小化重构误差>4.1.4 代数视角：最小化重构误差<a hidden class=anchor aria-hidden=true href=#414-代数视角最小化重构误差>#</a></h4><p>重构：$\hat{X} = ZW^T = XWW^T$</p><p>最小化重构误差：
$$\min_W |X - XWW^T|_F^2, \quad W^TW = I_k$$</p><p>可以证明这与最大化方差等价。</p><h4 id=415-奇异值分解svd>4.1.5 奇异值分解（SVD）<a hidden class=anchor aria-hidden=true href=#415-奇异值分解svd>#</a></h4><p>对于大数据，直接计算 $\Sigma = \frac{1}{n-1}X^TX$ 计算量大（$p^3$）。</p><p>使用SVD：$X = U \Sigma V^T$</p><p>其中 $U \in \mathbb{R}^{n \times n}$，$\Sigma \in \mathbb{R}^{n \times p}$，$V \in \mathbb{R}^{p \times p}$</p><p>主成分：$W = V_{:, 1:k}$</p><p>投影：$Z = XW = U \Sigma V^T V_{:, 1:k} = U \Sigma_{:, 1:k}$</p><h4 id=416-应用场景>4.1.6 应用场景<a hidden class=anchor aria-hidden=true href=#416-应用场景>#</a></h4><ul><li><strong>数据可视化</strong>：将高维数据投影到2D或3D进行可视化</li><li><strong>图像压缩</strong>：Eigenfaces（人脸识别）</li><li><strong>噪声减少</strong>：保留主成分，去除噪声</li><li><strong>特征提取</strong>：为后续算法提供低维特征</li></ul><h3 id=42-聚类算法>4.2 聚类算法<a hidden class=anchor aria-hidden=true href=#42-聚类算法>#</a></h3><h4 id=421-k-means算法>4.2.1 K-means算法<a hidden class=anchor aria-hidden=true href=#421-k-means算法>#</a></h4><p><strong>目标</strong>：将 $n$ 个样本分成 $K$ 个簇，使簇内距离最小。</p><p><strong>算法流程</strong>：</p><ol><li>随机初始化 $K$ 个质心：$\mu_1, \mu_2, \ldots, \mu_K$</li><li>重复直到收敛：<ul><li>分配：$c_i = \arg\min_j |x_i - \mu_j|^2$</li><li>更新：$\mu_j = \frac{1}{|C_j|}\sum_{i \in C_j} x_i$</li></ul></li></ol><p><strong>目标函数（误差平方和，SSE）</strong>：
$$J = \sum_{j=1}^K \sum_{i \in C_j} |x_i - \mu_j|^2$$</p><h4 id=422-收敛性>4.2.2 收敛性<a hidden class=anchor aria-hidden=true href=#422-收敛性>#</a></h4><p>K-means单调下降目标函数 $J$：</p><ul><li>分配步骤：每个点分配到最近的质心，$J$ 不增</li><li>更新步骤：质心移动到簇内均值，$J$ 不减</li></ul><p>但可能收敛到局部最优（依赖初始化）。</p><h4 id=423-k-means改进初始化>4.2.3 K-means++：改进初始化<a hidden class=anchor aria-hidden=true href=#423-k-means改进初始化>#</a></h4><p>初始化质心：</p><ol><li>第一个质心：随机选择</li><li>对于 $k = 2, \ldots, K$：<ul><li>计算每个点到最近质心的距离：$d(x_i) = \min_j |x_i - \mu_j|$</li><li>按概率 $\frac{d(x_i)^2}{\sum_{j=1}^n d(x_j)^2}$ 选择下一个质心</li></ul></li></ol><p>理论保证：$O(\log K)$ 近似最优。</p><h4 id=424-层次聚类>4.2.4 层次聚类<a hidden class=anchor aria-hidden=true href=#424-层次聚类>#</a></h4><p>层次聚类创建聚类树（Dendrogram），无需指定簇数。</p><p><strong>凝聚（Agglomerative）</strong>：自底向上，逐步合并最近的簇</p><p>距离度量：</p><ul><li>单链接（Single Linkage）：$\min_{x \in C_i, y \in C_j} |x - y|$</li><li>完全链接（Complete Linkage）：$\max_{x \in C_i, y \in C_j} |x - y|$</li><li>平均链接（Average Linkage）：$\frac{1}{|C_i||C_j|}\sum_{x \in C_i} \sum_{y \in C_j} |x - y|$</li></ul><p><strong>分裂（Divisive）</strong>：自顶向下，逐步分裂簇</p><h4 id=425-dbscan基于密度的聚类>4.2.5 DBSCAN：基于密度的聚类<a hidden class=anchor aria-hidden=true href=#425-dbscan基于密度的聚类>#</a></h4><p>K-means无法发现非凸簇和异常点。DBSCAN（Density-Based Spatial Clustering of Applications with Noise）基于密度聚类。</p><p><strong>定义</strong>：</p><ul><li>$\epsilon$-邻域：$N_\epsilon(x) = {y : |y - x| \leq \epsilon}$</li><li>核心点：$|N_\epsilon(x)| \geq \text{minPts}$</li><li>边界点：邻域内点数少于minPts，但与某个核心点相邻</li><li>噪声点：既不是核心点也不是边界点</li></ul><p><strong>算法流程</strong>：</p><ol><li>标记所有点为未访问</li><li>对于每个未访问点 $x$：<ul><li>标记为已访问</li><li>如果 $|N_\epsilon(x)| &lt; \text{minPts}$：标记为噪声</li><li>否则：创建新簇，通过密度连接添加点</li></ul></li></ol><p><strong>优点</strong>：</p><ul><li>自动发现簇数</li><li>发现任意形状的簇</li><li>识别异常点</li></ul><h4 id=426-应用场景>4.2.6 应用场景<a hidden class=anchor aria-hidden=true href=#426-应用场景>#</a></h4><ul><li><strong>客户细分</strong>：根据购买行为分群</li><li><strong>文档聚类</strong>：主题发现</li><li><strong>图像分割</strong>：像素聚类</li><li><strong>异常检测</strong>：发现离群点</li></ul><h2 id=第五章传统机器学习的应用场景>第五章：传统机器学习的应用场景<a hidden class=anchor aria-hidden=true href=#第五章传统机器学习的应用场景>#</a></h2><h3 id=51-金融领域>5.1 金融领域<a hidden class=anchor aria-hidden=true href=#51-金融领域>#</a></h3><h4 id=511-信用评分>5.1.1 信用评分<a hidden class=anchor aria-hidden=true href=#511-信用评分>#</a></h4><p><strong>问题</strong>：根据借款人的历史数据，预测违约概率。</p><p><strong>常用算法</strong>：</p><ul><li>逻辑回归：可解释性强，易于满足监管要求</li><li>随机森林：处理非线性关系，特征重要性分析</li><li>XGBoost：在Kaggle竞赛中表现优异</li></ul><p><strong>特征</strong>：</p><ul><li>收入、负债收入比</li><li>信用历史（逾期次数、信用卡使用率）</li><li>贷款金额、期限</li><li>职业稳定性、教育程度</li></ul><p><strong>评估指标</strong>：</p><ul><li>AUC-ROC</li><li>KS统计量</li><li>提升度（Lift）</li></ul><h4 id=512-欺诈检测>5.1.2 欺诈检测<a hidden class=anchor aria-hidden=true href=#512-欺诈检测>#</a></h4><p><strong>问题</strong>：识别信用卡交易、保险理赔中的欺诈行为。</p><p><strong>挑战</strong>：</p><ul><li>类别极度不平衡（欺诈样本极少）</li><li>欺诈模式不断变化</li></ul><p><strong>常用算法</strong>：</p><ul><li>异常检测：Isolation Forest、One-Class SVM</li><li>不平衡学习：SMOTE、代价敏感学习</li><li>集成方法：XGBoost（scale_pos_weight参数）</li></ul><h3 id=52-医疗健康>5.2 医疗健康<a hidden class=anchor aria-hidden=true href=#52-医疗健康>#</a></h3><h4 id=521-疾病诊断>5.2.1 疾病诊断<a hidden class=anchor aria-hidden=true href=#521-疾病诊断>#</a></h4><p><strong>问题</strong>：根据症状、检验结果诊断疾病。</p><p><strong>示例</strong>：</p><ul><li>乳腺癌检测：决策树、逻辑回归（可解释性重要）</li><li>糖尿病预测：SVM、随机森林</li><li>心脏病风险评估：逻辑回归（计算风险评分）</li></ul><p><strong>特征</strong>：</p><ul><li>患者年龄、性别、家族史</li><li>症状、检验指标（血压、血糖、胆固醇）</li><li>影像学特征（从医学图像提取）</li></ul><h4 id=522-药物发现>5.2.2 药物发现<a hidden class=anchor aria-hidden=true href=#522-药物发现>#</a></h4><p><strong>问题</strong>：预测化合物的生物活性、毒性。</p><p><strong>挑战</strong>：</p><ul><li>数据量有限（实验成本高）</li><li>分子表示复杂</li></ul><p><strong>常用算法</strong>：</p><ul><li>随机森林：处理分子描述符</li><li>深度学习：图神经网络（GNN）处理分子结构</li><li>迁移学习：从大规模数据预训练</li></ul><h3 id=53-推荐系统>5.3 推荐系统<a hidden class=anchor aria-hidden=true href=#53-推荐系统>#</a></h3><h4 id=531-协同过滤>5.3.1 协同过滤<a hidden class=anchor aria-hidden=true href=#531-协同过滤>#</a></h4><p><strong>问题</strong>：根据用户历史行为预测偏好。</p><p><strong>用户-物品矩阵</strong>：$R \in \mathbb{R}^{n \times m}$，$R_{ij}$ 表示用户 $i$ 对物品 $j$ 的评分</p><p><strong>矩阵分解</strong>：
$$R \approx UV^T$$</p><p>其中 $U \in \mathbb{R}^{n \times k}$（用户隐因子），$V \in \mathbb{R}^{m \times k}$（物品隐因子）</p><p><strong>优化</strong>：
$$\min_{U, V} \sum_{(i,j) \in \Omega} (R_{ij} - u_i^T v_j)^2 + \lambda (|U|_F^2 + |V|_F^2)$$</p><p>$\Omega$ 是已知评分的索引集合。</p><h4 id=532-内容推荐>5.3.2 内容推荐<a hidden class=anchor aria-hidden=true href=#532-内容推荐>#</a></h4><p><strong>问题</strong>：基于物品内容相似性推荐。</p><p><strong>方法</strong>：</p><ul><li>TF-IDF + 余弦相似度（文本）</li><li>LSA（潜在语义分析）：降维后计算相似度</li><li>内容特征 + 协同过滤：混合模型</li></ul><h4 id=533-排序学习>5.3.3 排序学习<a hidden class=anchor aria-hidden=true href=#533-排序学习>#</a></h4><p><strong>问题</strong>：对搜索结果排序。</p><p><strong>算法</strong>：</p><ul><li>LambdaMART：基于GBDT的学习排序</li><li>ListNet、ListMLE：基于列表的学习排序</li></ul><h3 id=54-自然语言处理nlp>5.4 自然语言处理（NLP）<a hidden class=anchor aria-hidden=true href=#54-自然语言处理nlp>#</a></h3><h4 id=541-文本分类>5.4.1 文本分类<a hidden class=anchor aria-hidden=true href=#541-文本分类>#</a></h4><p><strong>传统方法</strong>：</p><ul><li>特征提取：TF-IDF、N-grams、Word2Vec</li><li>分类器：朴素贝叶斯、SVM、逻辑回归</li></ul><p><strong>示例</strong>：</p><ul><li>垃圾邮件分类：朴素贝叶斯</li><li>情感分析：SVM</li><li>新闻分类：逻辑回归</li></ul><h4 id=542-主题模型>5.4.2 主题模型<a hidden class=anchor aria-hidden=true href=#542-主题模型>#</a></h4><p><strong>LDA（Latent Dirichlet Allocation）</strong>：</p><p>生成模型：每篇文档包含多个主题，每个主题包含多个词。</p><p>推断：Gibbs采样、变分推断</p><h4 id=543-命名实体识别ner>5.4.3 命名实体识别（NER）<a hidden class=anchor aria-hidden=true href=#543-命名实体识别ner>#</a></h4><p><strong>传统方法</strong>：</p><ul><li>HMM（隐马尔可夫模型）</li><li>CRF（条件随机场）</li></ul><p>特征：词性标注、上下文窗口、词形特征</p><h3 id=55-计算机视觉>5.5 计算机视觉<a hidden class=anchor aria-hidden=true href=#55-计算机视觉>#</a></h3><h4 id=551-图像分类传统方法>5.5.1 图像分类（传统方法）<a hidden class=anchor aria-hidden=true href=#551-图像分类传统方法>#</a></h4><p><strong>特征提取</strong>：</p><ul><li>SIFT（尺度不变特征变换）</li><li>HOG（方向梯度直方图）</li><li>LBP（局部二值模式）</li></ul><p><strong>分类器</strong>：</p><ul><li>SVM：ImageNet竞赛中表现优异（2012年之前）</li><li>随机森林：处理高维特征</li></ul><h4 id=552-目标检测>5.5.2 目标检测<a hidden class=anchor aria-hidden=true href=#552-目标检测>#</a></h4><p><strong>传统方法</strong>：</p><ul><li>Viola-Jones框架（Haar特征 + AdaBoost）：人脸检测</li><li>HOG + SVM：行人检测</li><li>DPM（可变形部件模型）：多类别目标检测</li></ul><h2 id=第六章未来展望>第六章：未来展望<a hidden class=anchor aria-hidden=true href=#第六章未来展望>#</a></h2><h3 id=61-传统机器学习的现状>6.1 传统机器学习的现状<a hidden class=anchor aria-hidden=true href=#61-传统机器学习的现状>#</a></h3><p>尽管深度学习在图像、语音等感知任务上取得了巨大成功，传统机器学习依然在以下场景中不可替代：</p><ol><li><strong>数据量有限</strong>：当样本量在几千到几万时，传统算法（特别是集成方法）往往表现更好</li><li><strong>可解释性要求高</strong>：金融风控、医疗诊断等需要解释决策依据的场景</li><li><strong>计算资源受限</strong>：传统算法计算量小，适合边缘计算、实时推理</li><li><strong>结构化数据</strong>：表格数据是传统算法的主场，深度学习在这方面没有明显优势</li></ol><h3 id=62-未来发展趋势>6.2 未来发展趋势<a hidden class=anchor aria-hidden=true href=#62-未来发展趋势>#</a></h3><h4 id=621-自动机器学习automl>6.2.1 自动机器学习（AutoML）<a hidden class=anchor aria-hidden=true href=#621-自动机器学习automl>#</a></h4><p><strong>现状</strong>：传统机器学习模型调参复杂，需要大量领域知识。</p><p><strong>未来</strong>：</p><ul><li>自动特征工程：自动选择、构造特征</li><li>超参数优化：贝叶斯优化、进化算法</li><li>模型选择：自动选择最优算法</li><li>神经架构搜索（NAS）：为深度学习设计架构</li></ul><p><strong>工具</strong>：</p><ul><li>Auto-sklearn</li><li>H2O AutoML</li><li>Google AutoML</li><li>Microsoft AutoML</li></ul><h4 id=622-可解释性aixai>6.2.2 可解释性AI（XAI）<a hidden class=anchor aria-hidden=true href=#622-可解释性aixai>#</a></h4><p><strong>挑战</strong>：传统算法（如随机森林、XGBoost）虽然可解释，但深度学习是黑箱。</p><p><strong>方法</strong>：</p><ul><li>LIME（Local Interpretable Model-agnostic Explanations）：局部解释</li><li>SHAP（SHapley Additive exPlanations）：基于博弈论的全局/局部解释</li><li>反事实解释：说明"如果特征X改变，结果会如何变化"</li><li>注意力机制：深度学习中的可解释性</li></ul><p><strong>应用</strong>：</p><ul><li>医疗诊断：解释为什么预测某种疾病</li><li>金融风控：解释为什么拒绝贷款申请</li><li>公平性：检测和消除算法偏见</li></ul><h4 id=623-因果推断>6.2.3 因果推断<a hidden class=anchor aria-hidden=true href=#623-因果推断>#</a></h4><p><strong>传统机器学习</strong>：关联性（Correlation）</p><p><strong>未来</strong>：因果性（Causality）</p><p><strong>方法</strong>：</p><ul><li>结构因果模型（SCM）</li><li>do-算子（Pearl的因果演算）</li><li>双重机器学习（DML）：结合因果推断与机器学习</li></ul><p><strong>应用</strong>：</p><ul><li>营销：计算广告的因果效应（提升度）</li><li>政策评估：估计政策的因果影响</li><li>推荐系统：用户行为归因</li></ul><h4 id=624-迁移学习与小样本学习>6.2.4 迁移学习与小样本学习<a hidden class=anchor aria-hidden=true href=#624-迁移学习与小样本学习>#</a></h4><p><strong>挑战</strong>：传统机器学习需要大量标注数据。</p><p><strong>未来</strong>：</p><ul><li>预训练模型：从大规模无标注数据预训练</li><li>微调：在目标任务上少量标注数据微调</li><li>元学习（Meta-Learning）：学习如何学习</li></ul><p><strong>示例</strong>：</p><ul><li>NLP：BERT、GPT（预训练+微调）</li><li>表格数据：预训练的表格数据模型（如TabNet、SAINT）</li><li>跨领域迁移：从源域知识迁移到目标域</li></ul><h4 id=625-在线学习与强化学习>6.2.5 在线学习与强化学习<a hidden class=anchor aria-hidden=true href=#625-在线学习与强化学习>#</a></h4><p><strong>传统机器学习</strong>：离线训练，静态数据</p><p><strong>未来</strong>：</p><ul><li>在线学习：实时更新模型，适应数据分布变化</li><li>增量学习：增量式学习新任务，不遗忘旧知识</li><li>强化学习：通过与环境交互学习最优策略</li></ul><p><strong>应用</strong>：</p><ul><li>实时推荐：根据用户实时行为更新推荐</li><li>自适应系统：自动驾驶、机器人控制</li><li>序列决策：游戏AI、资源调度</li></ul><h4 id=626-传统算法与深度学习的融合>6.2.6 传统算法与深度学习的融合<a hidden class=anchor aria-hidden=true href=#626-传统算法与深度学习的融合>#</a></h4><p><strong>融合方向</strong>：</p><ol><li><p><strong>深度嵌入传统算法</strong></p><ul><li>Deep Forest：用深度森林替代神经网络</li><li>树神经网络（TreeNN）：决策树的神经网络化</li></ul></li><li><p><strong>传统算法作为组件</strong></p><ul><li>GBDT的叶子编码作为特征，输入神经网络</li><li>注意力机制结合树模型</li></ul></li><li><p><strong>混合模型</strong></p><ul><li>结构化数据：传统算法（XGBoost）</li><li>非结构化数据：深度学习（CNN、RNN、Transformer）</li><li>多模态融合：结合两种模型的输出</li></ul></li></ol><h4 id=627-鲁棒性与安全性>6.2.7 鲁棒性与安全性<a hidden class=anchor aria-hidden=true href=#627-鲁棒性与安全性>#</a></h4><p><strong>挑战</strong>：传统算法和深度学习都易受对抗攻击。</p><p><strong>研究方向</strong>：</p><ul><li>对抗训练：提升模型鲁棒性</li><li>防御性蒸馏</li><li>神经网络验证</li></ul><p><strong>公平性</strong>：</p><ul><li>消除算法偏见（种族、性别等）</li><li>公平性约束优化</li></ul><h3 id=63-传统机器学习的长期价值>6.3 传统机器学习的长期价值<a hidden class=anchor aria-hidden=true href=#63-传统机器学习的长期价值>#</a></h3><p>尽管深度学习风头正劲，传统机器学习算法在以下方面依然具有重要价值：</p><ol><li><strong>理论基础扎实</strong>：统计学、凸优化等数学理论支撑，理论保证完善</li><li><strong>工程实践成熟</strong>：Scikit-learn等工具库成熟，部署简单</li><li><strong>计算效率高</strong>：适合实时应用、边缘计算</li><li><strong>可解释性好</strong>：决策规则清晰，易于理解和调试</li><li><strong>适用范围广</strong>：结构化数据分析的主场</li></ol><h3 id=64-结论>6.4 结论<a hidden class=anchor aria-hidden=true href=#64-结论>#</a></h3><p>传统机器学习与统计学习算法经历了半个多世纪的发展，从高斯的线性回归到XGBoost的集成学习，形成了完整、成熟的理论体系和工程实践。</p><p>在深度学习时代，传统算法并未过时。相反，它们在特定场景下依然不可替代。未来的发展方向不是相互替代，而是相互融合：传统算法提供坚实的理论基础和工程实践，深度学习拓展了感知能力的边界，AutoML、可解释性、因果推断等技术将进一步释放机器学习的潜力。</p><p>正如统计学家George Box所说：&ldquo;All models are wrong, but some are useful."（所有模型都是错的，但有些是有用的）。传统机器学习算法的价值在于它们在"有用"这个维度上做到了极致。</p><h2 id=参考文献>参考文献<a hidden class=anchor aria-hidden=true href=#参考文献>#</a></h2><ol><li>Hastie, T., Tibshirani, R., & Friedman, J. (2009). <em>The Elements of Statistical Learning</em>. Springer.</li><li>Bishop, C. M. (2006). <em>Pattern Recognition and Machine Learning</em>. Springer.</li><li>James, G., Witten, D., Hastie, T., & Tibshirani, R. (2013). <em>An Introduction to Statistical Learning</em>. Springer.</li><li>Breiman, L. (2001). Random Forests. <em>Machine Learning</em>, 45(1), 5-32.</li><li>Friedman, J. H. (2001). Greedy Function Approximation: A Gradient Boosting Machine. <em>Annals of Statistics</em>, 29(5), 1189-1232.</li><li>Chen, T., & Guestrin, C. (2016). XGBoost: A Scalable Tree Boosting System. <em>Proceedings of KDD</em>.</li><li>Vapnik, V. N. (1998). <em>Statistical Learning Theory</em>. Wiley.</li><li>Schapire, R. E., & Freund, Y. (2012). <em>Boosting: Foundations and Algorithms</em>. MIT Press.</li><li>Pearl, J., & Mackenzie, D. (2018). <em>The Book of Why: The New Science of Cause and Effect</em>. Basic Books.</li><li>Murphy, K. P. (2012). <em>Machine Learning: A Probabilistic Perspective</em>. MIT Press.</li></ol></div><footer class=post-footer><ul class=post-tags><li><a href=https://s-ai-unix.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/>机器学习</a></li><li><a href=https://s-ai-unix.github.io/tags/%E7%AE%97%E6%B3%95/>算法</a></li><li><a href=https://s-ai-unix.github.io/tags/%E6%95%B0%E5%AD%A6%E5%8F%B2/>数学史</a></li><li><a href=https://s-ai-unix.github.io/tags/%E7%BB%BC%E8%BF%B0/>综述</a></li></ul><nav class=paginav><a class=prev href=https://s-ai-unix.github.io/posts/2026-01-14-reinforcement-learning-comprehensive-guide/><span class=title>« Prev</span><br><span>强化学习：从试错到智能的数学之旅</span>
</a><a class=next href=https://s-ai-unix.github.io/posts/2026-01-13-christoffel-symbols-guide/><span class=title>Next »</span><br><span>克里斯托费尔符号：弯曲空间的导航系统</span></a></nav><ul class=share-buttons><li><a target=_blank rel="noopener noreferrer" aria-label="share 传统机器学习与统计学习算法：从理论到实践的完整指南 on x" href="https://x.com/intent/tweet/?text=%e4%bc%a0%e7%bb%9f%e6%9c%ba%e5%99%a8%e5%ad%a6%e4%b9%a0%e4%b8%8e%e7%bb%9f%e8%ae%a1%e5%ad%a6%e4%b9%a0%e7%ae%97%e6%b3%95%ef%bc%9a%e4%bb%8e%e7%90%86%e8%ae%ba%e5%88%b0%e5%ae%9e%e8%b7%b5%e7%9a%84%e5%ae%8c%e6%95%b4%e6%8c%87%e5%8d%97&amp;url=https%3a%2f%2fs-ai-unix.github.io%2fposts%2f2026-01-14-traditional-ml-algorithms-comprehensive-guide%2f&amp;hashtags=%e6%9c%ba%e5%99%a8%e5%ad%a6%e4%b9%a0%2c%e7%ae%97%e6%b3%95%2c%e6%95%b0%e5%ad%a6%e5%8f%b2%2c%e7%bb%bc%e8%bf%b0"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446C483.971.0 512 28.03 512 62.554zM269.951 190.75 182.567 75.216H56L207.216 272.95 63.9 436.783h61.366L235.9 310.383l96.667 126.4H456L298.367 228.367l134-153.151H371.033zM127.633 110h36.468l219.38 290.065H349.5z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share 传统机器学习与统计学习算法：从理论到实践的完整指南 on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fs-ai-unix.github.io%2fposts%2f2026-01-14-traditional-ml-algorithms-comprehensive-guide%2f&amp;title=%e4%bc%a0%e7%bb%9f%e6%9c%ba%e5%99%a8%e5%ad%a6%e4%b9%a0%e4%b8%8e%e7%bb%9f%e8%ae%a1%e5%ad%a6%e4%b9%a0%e7%ae%97%e6%b3%95%ef%bc%9a%e4%bb%8e%e7%90%86%e8%ae%ba%e5%88%b0%e5%ae%9e%e8%b7%b5%e7%9a%84%e5%ae%8c%e6%95%b4%e6%8c%87%e5%8d%97&amp;summary=%e4%bc%a0%e7%bb%9f%e6%9c%ba%e5%99%a8%e5%ad%a6%e4%b9%a0%e4%b8%8e%e7%bb%9f%e8%ae%a1%e5%ad%a6%e4%b9%a0%e7%ae%97%e6%b3%95%ef%bc%9a%e4%bb%8e%e7%90%86%e8%ae%ba%e5%88%b0%e5%ae%9e%e8%b7%b5%e7%9a%84%e5%ae%8c%e6%95%b4%e6%8c%87%e5%8d%97&amp;source=https%3a%2f%2fs-ai-unix.github.io%2fposts%2f2026-01-14-traditional-ml-algorithms-comprehensive-guide%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share 传统机器学习与统计学习算法：从理论到实践的完整指南 on reddit" href="https://reddit.com/submit?url=https%3a%2f%2fs-ai-unix.github.io%2fposts%2f2026-01-14-traditional-ml-algorithms-comprehensive-guide%2f&title=%e4%bc%a0%e7%bb%9f%e6%9c%ba%e5%99%a8%e5%ad%a6%e4%b9%a0%e4%b8%8e%e7%bb%9f%e8%ae%a1%e5%ad%a6%e4%b9%a0%e7%ae%97%e6%b3%95%ef%bc%9a%e4%bb%8e%e7%90%86%e8%ae%ba%e5%88%b0%e5%ae%9e%e8%b7%b5%e7%9a%84%e5%ae%8c%e6%95%b4%e6%8c%87%e5%8d%97"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share 传统机器学习与统计学习算法：从理论到实践的完整指南 on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fs-ai-unix.github.io%2fposts%2f2026-01-14-traditional-ml-algorithms-comprehensive-guide%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a></li></ul></footer><script src=https://giscus.app/client.js data-repo=s-ai-unix/blog data-repo-id=R_kgDOQ3Njaw data-category=General data-category-id=DIC_kwDOQ3Nja84C0yve data-mapping=pathname data-strict=0 data-reactions-enabled=1 data-emit-metadata=0 data-input-position=bottom data-theme=preferred_color_scheme data-lang=zh-CN data-loading=lazy crossorigin=anonymous async></script></article></main><footer class=footer><span>&copy; 2026 <a href=https://s-ai-unix.github.io/>s-ai-unix's Blog</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
<a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script>(function(){"use strict";function e(){var e=document.querySelectorAll("p, li, td, div, span, h1, h2, h3, h4, h5, h6, ol, ul");e.forEach(function(e){if(e.classList.contains("classical-quote-container")||e.classList.contains("quote-text")||e.closest(".classical-quote-container"))return;var t,n=e.innerHTML,s=!1;for(n.indexOf("<em>")!==-1&&(t=n.replace(/\$([^$]*?)<em>([^<]+?)<\/em>([^$]*?)\$/g,function(e,t,n,s){return/^[\d.,]+$/.test((t+n+s).replace(/[.,]/g,""))?e:"$"+t+"_"+n+s+"$"}),t=t.replace(/\$\$([^$]*?)<em>([^<]+?)<\/em>([^$]*?)\$\$/g,function(e,t,n,s){return"$$"+t+"_"+n+s+"$$"}),t!==n&&(n=t,s=!0)),n.indexOf("</em>")!==-1&&(t=n.replace(/\$([^$]*?)<\/em>([^$]*?)\$/g,function(e,t,n){return"$"+t+"_{"+n+"$"}),t=t.replace(/\$\$([^$]*?)<\/em>([^$]*?)\$\$/g,function(e,t,n){return"$$"+t+"_{"+n+"$$"}),t!==n&&(n=t,s=!0)),n.indexOf("<em>$")!==-1&&(t=n.replace(/<em>\$/g,"$"),t!==n&&(n=t,s=!0)),n.indexOf("</em>$")!==-1&&(t=n.replace(/<\/em>\$/g,"$"),t!==n&&(n=t,s=!0));n.indexOf("<em>")!==-1&&n.indexOf("</em>")!==-1;){if(t=n.replace(/\$([^$]*?)<em>([^<]+?)<\/em>([^$]*?)\$/g,function(e,t,n,s){return/^[\d.,]+$/.test((t+n+s).replace(/[.,]/g,""))?e:"$"+t+"_"+n+s+"$"}),t=t.replace(/\$\$([^$]*?)<em>([^<]+?)<\/em>([^$]*?)\$\$/g,function(e,t,n,s){return"$$"+t+"_"+n+s+"$$"}),t===n)break;n=t,s=!0}n.indexOf("_{")!==-1&&(t=n.replace(/_{/g,"_{"),t!==n&&(n=t,s=!0)),n.indexOf("}_")!==-1&&(t=n.replace(/}_/g,"}"),t!==n&&(n=t,s=!0)),n.includes("</em>{")&&(t=n.replace(/\\mathbf\{(W|x|y|z)\}<\/em>\{\\mathrm\{([a-z]+)\}\}/g,"\\mathbf{$1}_{\\mathrm{$2}}"),t=t.replace(/([LHf])<\/em>\{\\mathrm\{([a-z]+)\}\}/g,"$1_{\\mathrm{$2}}"),t=t.replace(/\\nabla ([LHf])<\/em>\{\\mathrm\{([a-z]+)\}\}/g,`\\nabla $1_{\\mathrm{$2}}`),t=t.replace(/([A-Z])<\/em>\{\\mathrm\{([a-z]+)\}\}/g,"$1_{\\mathrm{$2}}"),t!==n&&(n=t,s=!0)),n.includes("<em>{\\mathrm{")&&(t=n.replace(/\\mathbf\{(W|x|y|z)\}<em>\{\\mathrm\{([a-z]+)\}\}/g,"\\mathbf{$1}_{\\mathrm{$2}}"),t=t.replace(/([LHf])<em>\{\\mathrm\{([a-z]+)\}\}/g,"$1_{\\mathrm{$2}}"),t=t.replace(/\\nabla ([LHf])<em>\{\\mathrm\{([a-z]+)\}\}/g,`\\nabla $1_{\\mathrm{$2}}`),t=t.replace(/([A-Z])<em>\{\\mathrm\{([a-z]+)\}\}/g,"$1_{\\mathrm{$2}}"),t!==n&&(n=t,s=!0)),(n.includes("</em>")||n.includes("<em>"))&&(t=n.replace(/(\$[^$]*?)<em>([^$]*?)<\/em>/g,"$1_{$2}"),t=t.replace(/(\$\$[^$]*?)<em>([^$]*?)<\/em>/g,"$1_{$2}"),t=t.replace(/(\$[^$]*?)<em>/g,"$1"),t=t.replace(/<em>([^$]*?\$)/g,"$1"),t=t.replace(/(\$[^$]*?)<\/em>/g,"$1"),t=t.replace(/<\/em>([^$]*?\$)/g,"$1"),t!==n&&(n=t,s=!0)),n.indexOf("\\\\")!==-1&&(t=n.replace(/(\$\{1,2\})([^$]*?)(\$\{1,2\})/g,function(e,t,n,s){for(;n.indexOf("\\\\")!==-1;)n=n.replace(/\\\\/g,"\\");return t+n+s}),t!==n&&(n=t,s=!0)),s&&(e.innerHTML=n)})}window.MathJax={tex:{inlineMath:[["$","$"]],displayMath:[["$$","$$"]],processEscapes:!0,processEnvironments:!0,tags:"ams",packages:{"[+]":["noerrors","noundefined","boldsymbol"]},macros:{oiint:"\\mathop{∯}",oiiint:"\\mathop{∰}"}},options:{skipHtmlTags:["script","noscript","style","textarea","pre","code"]},startup:{pageReady:function(){return e(),MathJax.startup.defaultPageReady().then(function(){console.log("MathJax formulas rendered successfully")})}}}})()</script><script src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script><link rel=stylesheet href=/css/mermaid-custom.css><script src=/js/mermaid-converter.js></script><script type=module>
  import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs';

  
  setTimeout(() => {
    mermaid.initialize({
      startOnLoad: true,
      theme: 'base',
      themeVariables: {
        primaryColor: '#e3f2fd',
        primaryTextColor: '#1565c0',
        primaryBorderColor: '#2196f3',
        lineColor: '#42a5f5',
        secondaryColor: '#f3e5f5',
        tertiaryColor: '#fff9c4',
        background: '#ffffff',
        mainBkg: '#ffffff',
        nodeBorder: '#2196f3',
        clusterBkg: '#ffffff',
        clusterBorder: '#e0e0e0',
        titleColor: '#1565c0',
        edgeLabelBackground: '#fafafa',
      },
      securityLevel: 'loose',
    });
  }, 100);
</script><script src=/js/toc.js></script><script>let menu=document.getElementById("menu");if(menu){const e=localStorage.getItem("menu-scroll-position");e&&(menu.scrollLeft=parseInt(e,10)),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}}document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{const e=document.querySelector("html");e.dataset.theme==="dark"?(e.dataset.theme="light",localStorage.setItem("pref-theme","light")):(e.dataset.theme="dark",localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script><script>(function(){"use strict";function e(){var e=document.querySelectorAll("p, li, td, div, span, h1, h2, h3, h4, h5, h6, ol, ul");e.forEach(function(e){if(e.classList.contains("classical-quote-container")||e.classList.contains("quote-text")||e.closest(".classical-quote-container"))return;var t,n=e.innerHTML,s=!1;for(n.indexOf("<em>")!==-1&&(t=n.replace(/\$([^$]*?)<em>([^<]+?)<\/em>([^$]*?)\$/g,function(e,t,n,s){return/^[\d.,]+$/.test((t+n+s).replace(/[.,]/g,""))?e:"$"+t+"_"+n+s+"$"}),t=t.replace(/\$\$([^$]*?)<em>([^<]+?)<\/em>([^$]*?)\$\$/g,function(e,t,n,s){return"$$"+t+"_"+n+s+"$$"}),t!==n&&(n=t,s=!0)),n.indexOf("</em>")!==-1&&(t=n.replace(/\$([^$]*?)<\/em>([^$]*?)\$/g,function(e,t,n){return"$"+t+"_{"+n+"$"}),t=t.replace(/\$\$([^$]*?)<\/em>([^$]*?)\$\$/g,function(e,t,n){return"$$"+t+"_{"+n+"$$"}),t!==n&&(n=t,s=!0)),n.indexOf("<em>$")!==-1&&(t=n.replace(/<em>\$/g,"$"),t!==n&&(n=t,s=!0)),n.indexOf("</em>$")!==-1&&(t=n.replace(/<\/em>\$/g,"$"),t!==n&&(n=t,s=!0));n.indexOf("<em>")!==-1&&n.indexOf("</em>")!==-1;){if(t=n.replace(/\$([^$]*?)<em>([^<]+?)<\/em>([^$]*?)\$/g,function(e,t,n,s){return/^[\d.,]+$/.test((t+n+s).replace(/[.,]/g,""))?e:"$"+t+"_"+n+s+"$"}),t=t.replace(/\$\$([^$]*?)<em>([^<]+?)<\/em>([^$]*?)\$\$/g,function(e,t,n,s){return"$$"+t+"_"+n+s+"$$"}),t===n)break;n=t,s=!0}n.indexOf("_{")!==-1&&(t=n.replace(/_{/g,"_{"),t!==n&&(n=t,s=!0)),n.indexOf("}_")!==-1&&(t=n.replace(/}_/g,"}"),t!==n&&(n=t,s=!0)),n.includes("</em>{")&&(t=n.replace(/\\mathbf\{(W|x|y|z)\}<\/em>\{\\mathrm\{([a-z]+)\}\}/g,"\\mathbf{$1}_{\\mathrm{$2}}"),t=t.replace(/([LHf])<\/em>\{\\mathrm\{([a-z]+)\}\}/g,"$1_{\\mathrm{$2}}"),t=t.replace(/\\nabla ([LHf])<\/em>\{\\mathrm\{([a-z]+)\}\}/g,`\\nabla $1_{\\mathrm{$2}}`),t=t.replace(/([A-Z])<\/em>\{\\mathrm\{([a-z]+)\}\}/g,"$1_{\\mathrm{$2}}"),t!==n&&(n=t,s=!0)),n.includes("<em>{\\mathrm{")&&(t=n.replace(/\\mathbf\{(W|x|y|z)\}<em>\{\\mathrm\{([a-z]+)\}\}/g,"\\mathbf{$1}_{\\mathrm{$2}}"),t=t.replace(/([LHf])<em>\{\\mathrm\{([a-z]+)\}\}/g,"$1_{\\mathrm{$2}}"),t=t.replace(/\\nabla ([LHf])<em>\{\\mathrm\{([a-z]+)\}\}/g,`\\nabla $1_{\\mathrm{$2}}`),t=t.replace(/([A-Z])<em>\{\\mathrm\{([a-z]+)\}\}/g,"$1_{\\mathrm{$2}}"),t!==n&&(n=t,s=!0)),(n.includes("</em>")||n.includes("<em>"))&&(t=n.replace(/(\$[^$]*?)<em>([^$]*?)<\/em>/g,"$1_{$2}"),t=t.replace(/(\$\$[^$]*?)<em>([^$]*?)<\/em>/g,"$1_{$2}"),t=t.replace(/(\$[^$]*?)<em>/g,"$1"),t=t.replace(/<em>([^$]*?\$)/g,"$1"),t=t.replace(/(\$[^$]*?)<\/em>/g,"$1"),t=t.replace(/<\/em>([^$]*?\$)/g,"$1"),t!==n&&(n=t,s=!0)),n.indexOf("\\\\")!==-1&&(t=n.replace(/(\$\{1,2\})([^$]*?)(\$\{1,2\})/g,function(e,t,n,s){for(;n.indexOf("\\\\")!==-1;)n=n.replace(/\\\\/g,"\\");return t+n+s}),t!==n&&(n=t,s=!0)),s&&(e.innerHTML=n)})}window.MathJax={tex:{inlineMath:[["$","$"]],displayMath:[["$$","$$"]],processEscapes:!0,processEnvironments:!0,tags:"ams",packages:{"[+]":["noerrors","noundefined","boldsymbol"]},macros:{oiint:"\\mathop{∯}",oiiint:"\\mathop{∰}"}},options:{skipHtmlTags:["script","noscript","style","textarea","pre","code"]},startup:{pageReady:function(){return e(),MathJax.startup.defaultPageReady().then(function(){console.log("MathJax formulas rendered successfully")})}}}})()</script><script src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script><link rel=stylesheet href=/css/mermaid-custom.css><script src=/js/mermaid-converter.js></script><script type=module>
  import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs';

  
  setTimeout(() => {
    mermaid.initialize({
      startOnLoad: true,
      theme: 'base',
      themeVariables: {
        primaryColor: '#e3f2fd',
        primaryTextColor: '#1565c0',
        primaryBorderColor: '#2196f3',
        lineColor: '#42a5f5',
        secondaryColor: '#f3e5f5',
        tertiaryColor: '#fff9c4',
        background: '#ffffff',
        mainBkg: '#ffffff',
        nodeBorder: '#2196f3',
        clusterBkg: '#ffffff',
        clusterBorder: '#e0e0e0',
        titleColor: '#1565c0',
        edgeLabelBackground: '#fafafa',
      },
      securityLevel: 'loose',
    });
  }, 100);
</script><script src=/js/toc.js></script></body></html>
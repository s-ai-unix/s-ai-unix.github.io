<!doctype html><html lang=en dir=auto data-theme=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>AI 论文解读系列：ResNet 深度残差学习 | s-ai-unix's Blog</title><meta name=keywords content="深度学习,神经网络,机器学习,综述"><meta name=description content="深入解读何恺明等人的 ResNet 论文，从深度网络的退化问题出发，剖析残差学习的核心思想、数学原理和架构设计，揭示为何简单的跳跃连接能够训练出超深层神经网络。"><meta name=author content="s-ai-unix"><link rel=canonical href=https://s-ai-unix.github.io/posts/2026-01-30-ai-%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB%E7%B3%BB%E5%88%97%E4%B9%8Bresnet-%E6%B7%B1%E5%BA%A6%E6%AE%8B%E5%B7%AE%E5%AD%A6%E4%B9%A0/><link crossorigin=anonymous href=/assets/css/stylesheet.0833aff7e1cf567ecfb9755701ee95a80535f671e2e1a0a770c9bc20a0a7b5bb.css integrity="sha256-CDOv9+HPVn7PuXVXAe6VqAU19nHi4aCncMm8IKCntbs=" rel="preload stylesheet" as=style><link rel=icon href=https://s-ai-unix.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://s-ai-unix.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://s-ai-unix.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://s-ai-unix.github.io/apple-touch-icon.png><link rel=mask-icon href=https://s-ai-unix.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://s-ai-unix.github.io/posts/2026-01-30-ai-%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB%E7%B3%BB%E5%88%97%E4%B9%8Bresnet-%E6%B7%B1%E5%BA%A6%E6%AE%8B%E5%B7%AE%E5%AD%A6%E4%B9%A0/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51);color-scheme:dark}.list{background:var(--theme)}.toc{background:var(--entry)}}@media(prefers-color-scheme:light){.list::-webkit-scrollbar-thumb{border-color:var(--code-bg)}}</style></noscript><script>localStorage.getItem("pref-theme")==="dark"?document.querySelector("html").dataset.theme="dark":localStorage.getItem("pref-theme")==="light"?document.querySelector("html").dataset.theme="light":window.matchMedia("(prefers-color-scheme: dark)").matches?document.querySelector("html").dataset.theme="dark":document.querySelector("html").dataset.theme="light"</script><meta property="og:url" content="https://s-ai-unix.github.io/posts/2026-01-30-ai-%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB%E7%B3%BB%E5%88%97%E4%B9%8Bresnet-%E6%B7%B1%E5%BA%A6%E6%AE%8B%E5%B7%AE%E5%AD%A6%E4%B9%A0/"><meta property="og:site_name" content="s-ai-unix's Blog"><meta property="og:title" content="AI 论文解读系列：ResNet 深度残差学习"><meta property="og:description" content="深入解读何恺明等人的 ResNet 论文，从深度网络的退化问题出发，剖析残差学习的核心思想、数学原理和架构设计，揭示为何简单的跳跃连接能够训练出超深层神经网络。"><meta property="og:locale" content="zh-cn"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2026-01-30T08:38:11+08:00"><meta property="article:modified_time" content="2026-01-30T08:38:11+08:00"><meta property="article:tag" content="深度学习"><meta property="article:tag" content="神经网络"><meta property="article:tag" content="机器学习"><meta property="article:tag" content="综述"><meta property="og:image" content="https://s-ai-unix.github.io/images/covers/resnet-cover.jpg"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://s-ai-unix.github.io/images/covers/resnet-cover.jpg"><meta name=twitter:title content="AI 论文解读系列：ResNet 深度残差学习"><meta name=twitter:description content="深入解读何恺明等人的 ResNet 论文，从深度网络的退化问题出发，剖析残差学习的核心思想、数学原理和架构设计，揭示为何简单的跳跃连接能够训练出超深层神经网络。"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://s-ai-unix.github.io/posts/"},{"@type":"ListItem","position":2,"name":"AI 论文解读系列：ResNet 深度残差学习","item":"https://s-ai-unix.github.io/posts/2026-01-30-ai-%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB%E7%B3%BB%E5%88%97%E4%B9%8Bresnet-%E6%B7%B1%E5%BA%A6%E6%AE%8B%E5%B7%AE%E5%AD%A6%E4%B9%A0/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"AI 论文解读系列：ResNet 深度残差学习","name":"AI 论文解读系列：ResNet 深度残差学习","description":"深入解读何恺明等人的 ResNet 论文，从深度网络的退化问题出发，剖析残差学习的核心思想、数学原理和架构设计，揭示为何简单的跳跃连接能够训练出超深层神经网络。","keywords":["深度学习","神经网络","机器学习","综述"],"articleBody":"AI 论文解读系列：ResNet 深度残差学习 引言 2015 年，微软研究院的何恺明等人在 ImageNet 竞赛中提出了一个看似简单却极具革命性的想法：如果神经网络学习的是残差而非直接的映射，会发生什么？这个想法催生了 ResNet（Residual Network），一个拥有 152 层甚至 1000 多层的深度网络，不仅赢得了 ImageNet 2015 的冠军，更重要的是，它解决了困扰深度学习领域多年的一个核心问题——深层网络的退化。\n在 ResNet 出现之前，人们普遍认为更深的网络应该具有更强的表达能力。然而实践却给出了反直觉的结果：当网络层数增加到一定程度后，训练准确率反而下降。这不是过拟合，因为在训练集上的表现同样变差了。ResNet 的巧妙之处在于，它通过一个极其简单的跳跃连接（skip connection），让网络可以选择学习残差映射 $\\mathcal{F}(\\mathbf{x}) = \\mathcal{H}(\\mathbf{x}) - \\mathbf{x}$，而非直接学习 $\\mathcal{H}(\\mathbf{x})$。\n本文将系统性地解读这篇经典论文，从问题背景、核心思想、数学推导、架构设计到实验验证，循序渐进地揭示 ResNet 为何如此有效。\n第一章：深层网络的困境 1.1 从浅层到深层：一个自然的假设 深度学习的成功在很大程度上归功于深层神经网络强大的表示能力。从 LeNet-5 的 5 层，到 AlexNet 的 8 层，再到 VGGNet 的 16-19 层，网络深度的增加似乎与性能提升正相关。这种趋势背后的直觉很简单：更深的网络可以学习更复杂的特征层次结构。\n让我们形式化地思考这个问题。假设我们有一个浅层网络，它能够学习某个映射 $\\mathcal{H}(\\mathbf{x})$。如果我们在其后面添加更多层，直觉上，这些额外的层可以学习恒等映射（identity mapping），即直接输出输入：$\\mathbf{y} = \\mathbf{x}$。这样，深层网络至少应该和浅层网络表现一样好。\n然而，实践观察到的却是另一番景象。\n1.2 退化问题：理论与现实的鸿沟 2015 年之前的研究者发现，当网络层数超过 20 层后，出现了一个令人困惑的现象：随着网络加深，训练误差不降反升。\n上图展示了在 CIFAR-10 数据集上的典型实验结果。20 层网络的训练误差约为 8%，而 56 层网络的训练误差却上升到了 20%。请注意，这是在训练集上的表现，因此这不是过拟合问题，而是优化问题。\n这个现象被称为退化问题（Degradation Problem）。它的存在表明：\n深层网络更难优化，尽管它拥有更多的参数 恒等映射并非那么容易学习 简单的堆叠层数并不能保证更好的性能 1.3 梯度消失与退化问题的区别 有人可能会问：这是否是梯度消失（vanishing gradient）问题？毕竟，梯度消失也是深层网络的常见问题。\n梯度消失指的是在反向传播过程中，梯度逐层衰减，导致浅层参数几乎得不到更新。这个问题可以通过以下技术缓解：\n更好的初始化方法（如 Xavier、He 初始化） 批归一化（Batch Normalization） ReLU 激活函数 然而，即使使用了这些技术，退化问题依然存在。VGGNet 使用 ReLU 和小心初始化，也只能有效训练到 19 层。这说明退化问题有其独特的根源：\n多个非线性层很难学习恒等映射。考虑一个两层的非线性网络：\n$$\\mathbf{y} = \\sigma(W_2 \\cdot \\sigma(W_1 \\cdot \\mathbf{x}))$$\n要让 $\\mathbf{y} = \\mathbf{x}$，需要 $W_1$ 和 $W_2$ 满足特定的约束，而这种约束在随机初始化和高维空间中很难满足。优化器可能会陷入局部最优，或者需要极长时间才能找到合适的参数。\n第二章：残差学习的核心思想 2.1 重新定义学习目标 ResNet 的核心洞察是：与其让网络学习从输入到输出的直接映射，不如让它学习输入与输出之间的差异。这就是\"残差\"一词的由来。\n形式化地，假设我们希望学习一个映射 $\\mathcal{H}(\\mathbf{x})$。传统网络直接拟合这个映射：\n$$\\mathbf{y} = \\mathcal{H}(\\mathbf{x})$$\nResNet 则引入一个残差映射：\n$$\\mathcal{F}(\\mathbf{x}) = \\mathcal{H}(\\mathbf{x}) - \\mathbf{x}$$\n于是，原始映射可以重写为：\n$$\\mathbf{y} = \\mathcal{F}(\\mathbf{x}) + \\mathbf{x}$$\n这被称为残差学习框架。\n2.2 为什么残差更容易学习？ 现在问题来了：为什么学习 $\\mathcal{F}(\\mathbf{x})$ 比学习 $\\mathcal{H}(\\mathbf{x})$ 更容易？\n考虑退化问题的极端情况：如果最优映射就是恒等映射（即 $\\mathcal{H}(\\mathbf{x}) = \\mathbf{x}$），那么：\n传统网络需要学习 $\\mathcal{H}(\\mathbf{x}) = \\mathbf{x}$ 残差网络只需要学习 $\\mathcal{F}(\\mathbf{x}) = \\mathbf{0}$ 将参数推向零比学习恒等映射要容易得多。在所有可能的参数配置中，零是一个特殊的、容易达到的点。通过 L2 正则化或权重衰减，优化器实际上被鼓励向零靠近。\n更一般地，如果最优映射接近恒等映射，残差网络只需要学习一个\"小\"的扰动，而传统网络需要学习完整的映射。\n2.3 跳跃连接的实现 残差学习的实现通过一个极其简单的结构——跳跃连接（skip connection）或快捷连接（shortcut connection）：\n如上图所示，输入 $\\mathbf{x}$ 经过几个卷积层（以及 BN、ReLU）产生 $\\mathcal{F}(\\mathbf{x})$，然后与原始输入 $\\mathbf{x}$ 相加，再通过激活函数。\n数学上，一个基本的残差块（Residual Block）可以表示为：\n$$\\mathbf{y} = \\mathcal{F}(\\mathbf{x}, {W_i}) + \\mathbf{x}$$\n其中 $\\mathcal{F}$ 表示要学习的残差映射。对于图中的两层残差块：\n$$\\mathcal{F}(\\mathbf{x}) = W_2 \\cdot \\sigma(W_1 \\cdot \\mathbf{x})$$\n注意这里的 $\\sigma$ 表示 ReLU，而 $W_1$ 和 $W_2$ 是卷积层的权重。\n2.4 维度匹配问题 在实际实现中，还有一个细节需要考虑：当残差路径改变特征图尺寸（如通过步长为 2 的卷积下采样）或通道数时，直接相加 $\\mathcal{F}(\\mathbf{x}) + \\mathbf{x}$ 可能会有维度不匹配的问题。\nResNet 提供了两种解决方案：\n方案 A：零填充（Zero-padding）\n通过零填充增加通道数，不使用额外参数：\n$$\\mathbf{y} = \\mathcal{F}(\\mathbf{x}) + [\\mathbf{x}, \\mathbf{0}]$$\n方案 B：投影 shortcut（Projection shortcut）\n使用 $1 \\times 1$ 卷积进行投影：\n$$\\mathbf{y} = \\mathcal{F}(\\mathbf{x}) + W_s \\cdot \\mathbf{x}$$\n其中 $W_s$ 是 $1 \\times 1$ 卷积的权重矩阵。这种方法引入少量额外参数，但性能稍好。\n第三章：残差网络的数学分析 3.1 前向传播的动力学 让我们更深入地分析残差连接对前向传播的影响。考虑一个由 $L$ 个残差块组成的网络：\n$$\\mathbf{x}_{l+1} = \\mathbf{x}_l + \\mathcal{F}(\\mathbf{x}_l, W_l)$$\n通过递归展开，第 $L$ 层的输出可以表示为：\n$$\\mathbf{x}_L = \\mathbf{x}l + \\sum{i=l}^{L-1} \\mathcal{F}(\\mathbf{x}_i, W_i)$$\n这个公式揭示了一个重要性质：任何一层的特征都可以表示为之前任意一层特征加上一个残差之和。这与传统网络形成鲜明对比——在传统网络中，特征是一系列非线性变换的复合。\n3.2 反向传播的梯度流动 残差连接对梯度反向传播的影响更为关键。考虑损失函数 $\\mathcal{L}$ 对第 $l$ 层输入的梯度：\n$$\\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{x}_l} = \\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{x}_L} \\cdot \\frac{\\partial \\mathbf{x}_L}{\\partial \\mathbf{x}_l}$$\n由于 $\\mathbf{x}_L = \\mathbf{x}l + \\sum{i=l}^{L-1} \\mathcal{F}(\\mathbf{x}_i, W_i)$，我们有：\n$$\\frac{\\partial \\mathbf{x}_L}{\\partial \\mathbf{x}_l} = I + \\frac{\\partial}{\\partial \\mathbf{x}l} \\sum{i=l}^{L-1} \\mathcal{F}(\\mathbf{x}_i, W_i)$$\n因此：\n$$\\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{x}_l} = \\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{x}_L} + \\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{x}_L} \\cdot \\frac{\\partial}{\\partial \\mathbf{x}l} \\sum{i=l}^{L-1} \\mathcal{F}(\\mathbf{x}_i, W_i)$$\n这个分解显示了残差连接的关键作用：梯度可以直接从深层流向浅层，而不经过中间层的变换。第一项 $\\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{x}_L}$ 是梯度的\"高速公路\"，第二项则包含通过残差路径的梯度。\n上图展示了传统网络与残差网络的梯度流动对比。在传统网络中，梯度需要经过每一层的链式法则乘法，容易导致梯度消失；而在残差网络中，梯度可以通过跳跃连接直接传播。\n3.3 层响应分析 论文中还进行了有趣的层响应分析，即测量每层输出相对于输入的变化程度。结果表明：\n残差网络通常具有比传统网络更小的层响应 随着网络加深，残差函数变得更小 这证实了残差学习的假设：网络确实倾向于学习更小的扰动，而非完全的映射。\n第四章：ResNet 架构详解 4.1 基本构建块 ResNet 使用两种基本构建块：\nBasic Block（用于 ResNet-18/34）：\n包含两个 $3 \\times 3$ 卷积层：\n$$\\mathbf{y} = \\sigma(W_2 \\cdot \\sigma(W_1 \\cdot \\mathbf{x} + b_1) + b_2) + \\mathbf{x}$$\nBottleneck Block（用于 ResNet-50/101/152）：\n包含三个卷积层（$1 \\times 1$、$3 \\times 3$、$1 \\times 1$）：\n$$\\mathbf{y} = W_3 \\cdot \\sigma(W_2 \\cdot \\sigma(W_1 \\cdot \\mathbf{x})) + \\mathbf{x}$$\n其中 $W_1$ 和 $W_3$ 是 $1 \\times 1$ 卷积，分别用于降维和升维。这种设计减少了计算量，同时保持了表达能力。\n4.2 网络架构概览 以下是不同深度 ResNet 的架构配置：\n层名称 输出尺寸 ResNet-18 ResNet-34 ResNet-50 ResNet-101 ResNet-152 conv1 $112 \\times 112$ $7 \\times 7$, 64, stride 2 同上 同上 同上 同上 pool $56 \\times 56$ $3 \\times 3$ max pool, stride 2 同上 同上 同上 同上 conv2$_\\text{x}$ $56 \\times 56$ $\\begin{bmatrix} 3 \\times 3, 64 \\ 3 \\times 3, 64 \\end{bmatrix} \\times 2$ $\\times 3$ $\\begin{bmatrix} 1 \\times 1, 64 \\ 3 \\times 3, 64 \\ 1 \\times 1, 256 \\end{bmatrix} \\times 3$ $\\times 3$ $\\times 3$ conv3$_\\text{x}$ $28 \\times 28$ $\\begin{bmatrix} 3 \\times 3, 128 \\ 3 \\times 3, 128 \\end{bmatrix} \\times 2$ $\\times 4$ $\\begin{bmatrix} 1 \\times 1, 128 \\ 3 \\times 3, 128 \\ 1 \\times 1, 512 \\end{bmatrix} \\times 4$ $\\times 4$ $\\times 8$ conv4$_\\text{x}$ $14 \\times 14$ $\\begin{bmatrix} 3 \\times 3, 256 \\ 3 \\times 3, 256 \\end{bmatrix} \\times 2$ $\\times 6$ $\\begin{bmatrix} 1 \\times 1, 256 \\ 3 \\times 3, 256 \\ 1 \\times 1, 1024 \\end{bmatrix} \\times 6$ $\\times 23$ $\\times 36$ conv5$_\\text{x}$ $7 \\times 7$ $\\begin{bmatrix} 3 \\times 3, 512 \\ 3 \\times 3, 512 \\end{bmatrix} \\times 2$ $\\times 3$ $\\begin{bmatrix} 1 \\times 1, 512 \\ 3 \\times 3, 512 \\ 1 \\times 1, 2048 \\end{bmatrix} \\times 3$ $\\times 3$ $\\times 3$ 全局平均池化 $1 \\times 1$ 全局平均池化 同上 同上 同上 同上 全连接层 1000 1000-d fc, softmax 同上 同上 同上 同上 4.3 架构设计的关键决策 1. 步长设计\n每个阶段的第一个残差块使用步长为 2 的卷积进行下采样，将空间维度减半，通道数加倍。\n2. 批归一化位置\n原始 ResNet 在每个卷积层后、激活函数前使用批归一化。后续改进（Identity Mappings in Deep Residual Networks）建议将 BN 和 ReLU 移到残差路径内部，形成\"预激活\"结构。\n3. 初始卷积层\n使用 $7 \\times 7$ 的大卷积核和步长 2 快速降低空间维度，提取低级特征。\n第五章：实验与结果分析 5.1 ImageNet 分类结果 ResNet 在 ImageNet 2012 分类数据集上取得了突破性成果：\n从图中可以看到：\nResNet-34（使用投影 shortcut）的错误率比 34 层普通网络低约 3.5% ResNet-152 的错误率比 VGG-16/19 低约 3.2% 更深层的 ResNet-152（60.2M 参数）比 VGG-16（138M 参数）参数量更少但性能更好 5.2 退化问题的解决验证 为了验证残差学习确实解决了退化问题，论文对比了 18 层和 34 层网络：\n普通网络：34 层比 18 层训练误差更高（退化问题） ResNet：34 层比 18 层训练误差更低，验证误差也更好 这直接证明了残差连接的有效性。\n5.3 不同 Shortcut 策略的比较 论文比较了三种 shortcut 策略：\nA）零填充：增加维度时使用零填充，无额外参数 B）投影 shortcut：增加维度时使用 $1 \\times 1$ 卷积 **C）所有 shortcut 都使用投影\n结果：B 略优于 A，C 略优于 B，但差距不大。这说明投影 shortcut 并非关键，恒等 shortcut 才是性能提升的主要来源。\n5.4 超过 1000 层的网络 论文还尝试了超过 1000 层的极深网络（1202 层）：\n训练误差仍然可以降低 但由于参数量过大（19.4M），出现了过拟合 使用 maxout 或 dropout 等正则化技术可能进一步改善 第六章：残差网络的影响与拓展 6.1 对其他视觉任务的迁移 ResNet 的成功迅速扩展到其他计算机视觉任务：\n目标检测：Faster R-CNN、Mask R-CNN 等使用 ResNet 作为骨干网络\n语义分割：FCN、U-Net、DeepLab 等采用 ResNet 提取特征\n人体姿态估计：Hourglass、SimpleBaseline 等基于残差思想\n6.2 残差思想的变体 ResNet 启发了大量后续研究：\nDenseNet：不仅与输入相加，还与之前所有层进行通道拼接\n$$\\mathbf{x}_l = H_l([\\mathbf{x}_0, \\mathbf{x}1, \\ldots, \\mathbf{x}{l-1}])$$\nResNeXt：引入\"基数\"（cardinality）维度，使用分组卷积：\n$$\\mathbf{y} = \\mathbf{x} + \\sum_{i=1}^{C} T_i(\\mathbf{x})$$\nSENet：在残差块中加入通道注意力机制\nEfficientNet：结合残差连接和复合缩放策略\n6.3 ResNet 的理论解释 后续研究从理论上解释了 ResNet 的成功：\n动态网络视角：残差网络可以看作是一种集成学习，每一层决定是否使用残差路径\n常微分方程（ODE）视角：残差块的迭代公式与 Euler 离散化相似：\n$$\\mathbf{x}_{t+1} = \\mathbf{x}_t + f(\\mathbf{x}_t, t)$$\n这启发了 Neural ODE，将残差网络推广到连续深度。\n信息流视角：残差连接创造了信息高速公路，改善了梯度流和特征复用\n第七章：深入理解残差学习 7.1 集成学习的视角 2016 年，一项有趣的研究揭示了 ResNet 的另一种解释：一个 ResNet 实际上是一个指数级大小的隐式集成模型。\n考虑一个 3 块残差网络，通过递归展开：\n$$\\mathbf{x}_3 = \\mathbf{x}_0 + \\mathcal{F}_1(\\mathbf{x}_0) + \\mathcal{F}_2(\\mathbf{x}_1) + \\mathcal{F}_3(\\mathbf{x}_2)$$\n如果每个残差块可以选择\"使用\"或\"不使用\"，那么 $n$ 个残差块可以产生 $2^n$ 条不同的路径。这解释了为什么删除 ResNet 中的某些层对性能影响很小——网络有其他路径可以补偿。\n7.2 动态深度的适应性 残差网络的另一个有趣特性是动态深度。在测试时，网络可以根据输入的复杂度选择\"使用\"多少层。简单样本可能只需要前几层，复杂样本则会利用深层特征。\n这与 Dropout 有相似之处——都是某种形式的模型平均，但 ResNet 的结构化路径选择更加高效。\n7.3 与 Highway Networks 的关系 在 ResNet 之前，Highway Networks 也提出了类似的门控机制：\n$$\\mathbf{y} = T(\\mathbf{x}) \\cdot \\mathcal{F}(\\mathbf{x}) + (1 - T(\\mathbf{x})) \\cdot \\mathbf{x}$$\n其中 $T(\\mathbf{x})$ 是一个门控函数（通常用 sigmoid）。ResNet 可以看作 Highway Network 的特例，其中 $T(\\mathbf{x}) = 0.5$（固定不变）。\n这种简化带来了两个好处：\n参数量减半（不需要门控参数） 恒等连接始终畅通，梯度流动更直接 结语 ResNet 的提出是深度学习发展史上的一个里程碑。它通过一个简单而优雅的跳跃连接，解决了深层网络的退化问题，使得训练数百层甚至上千层的网络成为可能。\n回顾这篇论文的核心贡献：\n问题识别：明确指出深层网络的退化问题，并区分于梯度消失 核心思想：提出残差学习框架，让网络学习残差而非直接映射 简洁实现：通过恒等 shortcut 实现，几乎不增加额外计算 实验验证：在 ImageNet 等数据集上验证了超深网络的有效性 ResNet 的成功告诉我们：有时候，解决问题的最佳方式不是设计更复杂的模块，而是重新思考问题的本质。学习\"差异\"比学习\"全部\"更容易，这个简单却深刻的洞见，至今仍在影响着深度学习的发展。\n从 2015 年至今，ResNet 已经成为计算机视觉领域的标准组件。无论是图像分类、目标检测、语义分割还是其他视觉任务，残差连接都是不可或缺的元素。它证明了好的架构设计可以跨越时间和任务，产生持久的影响力。\n参考文献 He, K., Zhang, X., Ren, S., \u0026 Sun, J. (2016). “Deep Residual Learning for Image Recognition.” Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 770-778.\nHe, K., Zhang, X., Ren, S., \u0026 Sun, J. (2016). “Identity Mappings in Deep Residual Networks.” European Conference on Computer Vision (ECCV), 630-645.\nVeit, A., Wilber, M. J., \u0026 Belongie, S. (2016). “Residual Networks Behave Like Ensembles of Relatively Shallow Networks.” Advances in Neural Information Processing Systems (NeurIPS), 29.\nSrivastava, R. K., Greff, K., \u0026 Schmidhuber, J. (2015). “Highway Networks.” arXiv preprint arXiv:1505.00387.\nHuang, G., Liu, Z., Van Der Maaten, L., \u0026 Weinberger, K. Q. (2017). “Densely Connected Convolutional Networks.” Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 4700-4708.\nChen, R. T., Rubanova, Y., Bettencourt, J., \u0026 Duvenaud, D. (2018). “Neural Ordinary Differential Equations.” Advances in Neural Information Processing Systems (NeurIPS), 31.\n","wordCount":"1008","inLanguage":"en","image":"https://s-ai-unix.github.io/images/covers/resnet-cover.jpg","datePublished":"2026-01-30T08:38:11+08:00","dateModified":"2026-01-30T08:38:11+08:00","author":{"@type":"Person","name":"s-ai-unix"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://s-ai-unix.github.io/posts/2026-01-30-ai-%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB%E7%B3%BB%E5%88%97%E4%B9%8Bresnet-%E6%B7%B1%E5%BA%A6%E6%AE%8B%E5%B7%AE%E5%AD%A6%E4%B9%A0/"},"publisher":{"@type":"Organization","name":"s-ai-unix's Blog","logo":{"@type":"ImageObject","url":"https://s-ai-unix.github.io/favicon.ico"}}}</script><link rel=stylesheet href=https://s-ai-unix.github.io/css/classical-quote.css></head><body id=top><header class=header><nav class=nav><div class=logo><a href=https://s-ai-unix.github.io/ accesskey=h title="s-ai-unix's Blog (Alt + H)">s-ai-unix's Blog</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://s-ai-unix.github.io/ title="🏠 首页"><span>🏠 首页</span></a></li><li><a href=https://s-ai-unix.github.io/posts/ title="📚 文章"><span>📚 文章</span></a></li><li><a href=https://s-ai-unix.github.io/archives/ title="📁 归档"><span>📁 归档</span></a></li><li><a href=https://s-ai-unix.github.io/tags/ title="🏷️ 标签"><span>🏷️ 标签</span></a></li><li><a href=https://s-ai-unix.github.io/search/ title="🔍 搜索 (Alt + /)" accesskey=/><span>🔍 搜索</span></a></li><li><a href=https://s-ai-unix.github.io/about/ title="👤 关于"><span>👤 关于</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://s-ai-unix.github.io/>Home</a>&nbsp;»&nbsp;<a href=https://s-ai-unix.github.io/posts/>Posts</a></div><h1 class="post-title entry-hint-parent">AI 论文解读系列：ResNet 深度残差学习</h1><div class=post-description>深入解读何恺明等人的 ResNet 论文，从深度网络的退化问题出发，剖析残差学习的核心思想、数学原理和架构设计，揭示为何简单的跳跃连接能够训练出超深层神经网络。</div><div class=post-meta><span title='2026-01-30 08:38:11 +0800 CST'>January 30, 2026</span>&nbsp;·&nbsp;<span>5 min</span>&nbsp;·&nbsp;<span>1008 words</span>&nbsp;·&nbsp;<span>s-ai-unix</span></div></header><figure class=entry-cover><a href=https://s-ai-unix.github.io/images/covers/resnet-cover.jpg target=_blank rel="noopener noreferrer"><img loading=eager src=https://s-ai-unix.github.io/images/covers/resnet-cover.jpg alt="AI 论文解读系列 ResNet 深度残差学习 cover image"></a><figcaption>AI 论文解读系列 ResNet 深度残差学习 - Cover Image</figcaption></figure><div class=toc><details open><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#ai-%e8%ae%ba%e6%96%87%e8%a7%a3%e8%af%bb%e7%b3%bb%e5%88%97resnet-%e6%b7%b1%e5%ba%a6%e6%ae%8b%e5%b7%ae%e5%ad%a6%e4%b9%a0 aria-label="AI 论文解读系列：ResNet 深度残差学习">AI 论文解读系列：ResNet 深度残差学习</a><ul><li><a href=#%e5%bc%95%e8%a8%80 aria-label=引言>引言</a></li><li><a href=#%e7%ac%ac%e4%b8%80%e7%ab%a0%e6%b7%b1%e5%b1%82%e7%bd%91%e7%bb%9c%e7%9a%84%e5%9b%b0%e5%a2%83 aria-label=第一章：深层网络的困境>第一章：深层网络的困境</a><ul><li><a href=#11-%e4%bb%8e%e6%b5%85%e5%b1%82%e5%88%b0%e6%b7%b1%e5%b1%82%e4%b8%80%e4%b8%aa%e8%87%aa%e7%84%b6%e7%9a%84%e5%81%87%e8%ae%be aria-label="1.1 从浅层到深层：一个自然的假设">1.1 从浅层到深层：一个自然的假设</a></li><li><a href=#12-%e9%80%80%e5%8c%96%e9%97%ae%e9%a2%98%e7%90%86%e8%ae%ba%e4%b8%8e%e7%8e%b0%e5%ae%9e%e7%9a%84%e9%b8%bf%e6%b2%9f aria-label="1.2 退化问题：理论与现实的鸿沟">1.2 退化问题：理论与现实的鸿沟</a></li><li><a href=#13-%e6%a2%af%e5%ba%a6%e6%b6%88%e5%a4%b1%e4%b8%8e%e9%80%80%e5%8c%96%e9%97%ae%e9%a2%98%e7%9a%84%e5%8c%ba%e5%88%ab aria-label="1.3 梯度消失与退化问题的区别">1.3 梯度消失与退化问题的区别</a></li></ul></li><li><a href=#%e7%ac%ac%e4%ba%8c%e7%ab%a0%e6%ae%8b%e5%b7%ae%e5%ad%a6%e4%b9%a0%e7%9a%84%e6%a0%b8%e5%bf%83%e6%80%9d%e6%83%b3 aria-label=第二章：残差学习的核心思想>第二章：残差学习的核心思想</a><ul><li><a href=#21-%e9%87%8d%e6%96%b0%e5%ae%9a%e4%b9%89%e5%ad%a6%e4%b9%a0%e7%9b%ae%e6%a0%87 aria-label="2.1 重新定义学习目标">2.1 重新定义学习目标</a></li><li><a href=#22-%e4%b8%ba%e4%bb%80%e4%b9%88%e6%ae%8b%e5%b7%ae%e6%9b%b4%e5%ae%b9%e6%98%93%e5%ad%a6%e4%b9%a0 aria-label="2.2 为什么残差更容易学习？">2.2 为什么残差更容易学习？</a></li><li><a href=#23-%e8%b7%b3%e8%b7%83%e8%bf%9e%e6%8e%a5%e7%9a%84%e5%ae%9e%e7%8e%b0 aria-label="2.3 跳跃连接的实现">2.3 跳跃连接的实现</a></li><li><a href=#24-%e7%bb%b4%e5%ba%a6%e5%8c%b9%e9%85%8d%e9%97%ae%e9%a2%98 aria-label="2.4 维度匹配问题">2.4 维度匹配问题</a></li></ul></li><li><a href=#%e7%ac%ac%e4%b8%89%e7%ab%a0%e6%ae%8b%e5%b7%ae%e7%bd%91%e7%bb%9c%e7%9a%84%e6%95%b0%e5%ad%a6%e5%88%86%e6%9e%90 aria-label=第三章：残差网络的数学分析>第三章：残差网络的数学分析</a><ul><li><a href=#31-%e5%89%8d%e5%90%91%e4%bc%a0%e6%92%ad%e7%9a%84%e5%8a%a8%e5%8a%9b%e5%ad%a6 aria-label="3.1 前向传播的动力学">3.1 前向传播的动力学</a></li><li><a href=#32-%e5%8f%8d%e5%90%91%e4%bc%a0%e6%92%ad%e7%9a%84%e6%a2%af%e5%ba%a6%e6%b5%81%e5%8a%a8 aria-label="3.2 反向传播的梯度流动">3.2 反向传播的梯度流动</a></li><li><a href=#33-%e5%b1%82%e5%93%8d%e5%ba%94%e5%88%86%e6%9e%90 aria-label="3.3 层响应分析">3.3 层响应分析</a></li></ul></li><li><a href=#%e7%ac%ac%e5%9b%9b%e7%ab%a0resnet-%e6%9e%b6%e6%9e%84%e8%af%a6%e8%a7%a3 aria-label="第四章：ResNet 架构详解">第四章：ResNet 架构详解</a><ul><li><a href=#41-%e5%9f%ba%e6%9c%ac%e6%9e%84%e5%bb%ba%e5%9d%97 aria-label="4.1 基本构建块">4.1 基本构建块</a></li><li><a href=#42-%e7%bd%91%e7%bb%9c%e6%9e%b6%e6%9e%84%e6%a6%82%e8%a7%88 aria-label="4.2 网络架构概览">4.2 网络架构概览</a></li><li><a href=#43-%e6%9e%b6%e6%9e%84%e8%ae%be%e8%ae%a1%e7%9a%84%e5%85%b3%e9%94%ae%e5%86%b3%e7%ad%96 aria-label="4.3 架构设计的关键决策">4.3 架构设计的关键决策</a></li></ul></li><li><a href=#%e7%ac%ac%e4%ba%94%e7%ab%a0%e5%ae%9e%e9%aa%8c%e4%b8%8e%e7%bb%93%e6%9e%9c%e5%88%86%e6%9e%90 aria-label=第五章：实验与结果分析>第五章：实验与结果分析</a><ul><li><a href=#51-imagenet-%e5%88%86%e7%b1%bb%e7%bb%93%e6%9e%9c aria-label="5.1 ImageNet 分类结果">5.1 ImageNet 分类结果</a></li><li><a href=#52-%e9%80%80%e5%8c%96%e9%97%ae%e9%a2%98%e7%9a%84%e8%a7%a3%e5%86%b3%e9%aa%8c%e8%af%81 aria-label="5.2 退化问题的解决验证">5.2 退化问题的解决验证</a></li><li><a href=#53-%e4%b8%8d%e5%90%8c-shortcut-%e7%ad%96%e7%95%a5%e7%9a%84%e6%af%94%e8%be%83 aria-label="5.3 不同 Shortcut 策略的比较">5.3 不同 Shortcut 策略的比较</a></li><li><a href=#54-%e8%b6%85%e8%bf%87-1000-%e5%b1%82%e7%9a%84%e7%bd%91%e7%bb%9c aria-label="5.4 超过 1000 层的网络">5.4 超过 1000 层的网络</a></li></ul></li><li><a href=#%e7%ac%ac%e5%85%ad%e7%ab%a0%e6%ae%8b%e5%b7%ae%e7%bd%91%e7%bb%9c%e7%9a%84%e5%bd%b1%e5%93%8d%e4%b8%8e%e6%8b%93%e5%b1%95 aria-label=第六章：残差网络的影响与拓展>第六章：残差网络的影响与拓展</a><ul><li><a href=#61-%e5%af%b9%e5%85%b6%e4%bb%96%e8%a7%86%e8%a7%89%e4%bb%bb%e5%8a%a1%e7%9a%84%e8%bf%81%e7%a7%bb aria-label="6.1 对其他视觉任务的迁移">6.1 对其他视觉任务的迁移</a></li><li><a href=#62-%e6%ae%8b%e5%b7%ae%e6%80%9d%e6%83%b3%e7%9a%84%e5%8f%98%e4%bd%93 aria-label="6.2 残差思想的变体">6.2 残差思想的变体</a></li><li><a href=#63-resnet-%e7%9a%84%e7%90%86%e8%ae%ba%e8%a7%a3%e9%87%8a aria-label="6.3 ResNet 的理论解释">6.3 ResNet 的理论解释</a></li></ul></li><li><a href=#%e7%ac%ac%e4%b8%83%e7%ab%a0%e6%b7%b1%e5%85%a5%e7%90%86%e8%a7%a3%e6%ae%8b%e5%b7%ae%e5%ad%a6%e4%b9%a0 aria-label=第七章：深入理解残差学习>第七章：深入理解残差学习</a><ul><li><a href=#71-%e9%9b%86%e6%88%90%e5%ad%a6%e4%b9%a0%e7%9a%84%e8%a7%86%e8%a7%92 aria-label="7.1 集成学习的视角">7.1 集成学习的视角</a></li><li><a href=#72-%e5%8a%a8%e6%80%81%e6%b7%b1%e5%ba%a6%e7%9a%84%e9%80%82%e5%ba%94%e6%80%a7 aria-label="7.2 动态深度的适应性">7.2 动态深度的适应性</a></li><li><a href=#73-%e4%b8%8e-highway-networks-%e7%9a%84%e5%85%b3%e7%b3%bb aria-label="7.3 与 Highway Networks 的关系">7.3 与 Highway Networks 的关系</a></li></ul></li><li><a href=#%e7%bb%93%e8%af%ad aria-label=结语>结语</a></li><li><a href=#%e5%8f%82%e8%80%83%e6%96%87%e7%8c%ae aria-label=参考文献>参考文献</a></li></ul></li></ul></div></details></div><div class=post-content><h1 id=ai-论文解读系列resnet-深度残差学习>AI 论文解读系列：ResNet 深度残差学习<a hidden class=anchor aria-hidden=true href=#ai-论文解读系列resnet-深度残差学习>#</a></h1><h2 id=引言>引言<a hidden class=anchor aria-hidden=true href=#引言>#</a></h2><p>2015 年，微软研究院的何恺明等人在 ImageNet 竞赛中提出了一个看似简单却极具革命性的想法：如果神经网络学习的是<strong>残差</strong>而非直接的映射，会发生什么？这个想法催生了 ResNet（Residual Network），一个拥有 152 层甚至 1000 多层的深度网络，不仅赢得了 ImageNet 2015 的冠军，更重要的是，它解决了困扰深度学习领域多年的一个核心问题——<strong>深层网络的退化</strong>。</p><p>在 ResNet 出现之前，人们普遍认为更深的网络应该具有更强的表达能力。然而实践却给出了反直觉的结果：当网络层数增加到一定程度后，训练准确率反而下降。这不是过拟合，因为在训练集上的表现同样变差了。ResNet 的巧妙之处在于，它通过一个极其简单的<strong>跳跃连接</strong>（skip connection），让网络可以选择学习残差映射 $\mathcal{F}(\mathbf{x}) = \mathcal{H}(\mathbf{x}) - \mathbf{x}$，而非直接学习 $\mathcal{H}(\mathbf{x})$。</p><p>本文将系统性地解读这篇经典论文，从问题背景、核心思想、数学推导、架构设计到实验验证，循序渐进地揭示 ResNet 为何如此有效。</p><h2 id=第一章深层网络的困境>第一章：深层网络的困境<a hidden class=anchor aria-hidden=true href=#第一章深层网络的困境>#</a></h2><h3 id=11-从浅层到深层一个自然的假设>1.1 从浅层到深层：一个自然的假设<a hidden class=anchor aria-hidden=true href=#11-从浅层到深层一个自然的假设>#</a></h3><p>深度学习的成功在很大程度上归功于深层神经网络强大的表示能力。从 LeNet-5 的 5 层，到 AlexNet 的 8 层，再到 VGGNet 的 16-19 层，网络深度的增加似乎与性能提升正相关。这种趋势背后的直觉很简单：更深的网络可以学习更复杂的特征层次结构。</p><p>让我们形式化地思考这个问题。假设我们有一个浅层网络，它能够学习某个映射 $\mathcal{H}(\mathbf{x})$。如果我们在其后面添加更多层，直觉上，这些额外的层可以学习<strong>恒等映射</strong>（identity mapping），即直接输出输入：$\mathbf{y} = \mathbf{x}$。这样，深层网络至少应该和浅层网络表现一样好。</p><p>然而，实践观察到的却是另一番景象。</p><h3 id=12-退化问题理论与现实的鸿沟>1.2 退化问题：理论与现实的鸿沟<a hidden class=anchor aria-hidden=true href=#12-退化问题理论与现实的鸿沟>#</a></h3><p>2015 年之前的研究者发现，当网络层数超过 20 层后，出现了一个令人困惑的现象：<strong>随着网络加深，训练误差不降反升</strong>。</p><p><img alt=退化问题 loading=lazy src=/images/plots/resnet-degradation.png></p><p>上图展示了在 CIFAR-10 数据集上的典型实验结果。20 层网络的训练误差约为 8%，而 56 层网络的训练误差却上升到了 20%。请注意，这是在训练集上的表现，因此这不是过拟合问题，而是<strong>优化问题</strong>。</p><p>这个现象被称为<strong>退化问题</strong>（Degradation Problem）。它的存在表明：</p><ol><li>深层网络更难优化，尽管它拥有更多的参数</li><li>恒等映射并非那么容易学习</li><li>简单的堆叠层数并不能保证更好的性能</li></ol><h3 id=13-梯度消失与退化问题的区别>1.3 梯度消失与退化问题的区别<a hidden class=anchor aria-hidden=true href=#13-梯度消失与退化问题的区别>#</a></h3><p>有人可能会问：这是否是梯度消失（vanishing gradient）问题？毕竟，梯度消失也是深层网络的常见问题。</p><p>梯度消失指的是在反向传播过程中，梯度逐层衰减，导致浅层参数几乎得不到更新。这个问题可以通过以下技术缓解：</p><ul><li>更好的初始化方法（如 Xavier、He 初始化）</li><li>批归一化（Batch Normalization）</li><li>ReLU 激活函数</li></ul><p>然而，即使使用了这些技术，退化问题依然存在。VGGNet 使用 ReLU 和小心初始化，也只能有效训练到 19 层。这说明退化问题有其独特的根源：</p><p><strong>多个非线性层很难学习恒等映射</strong>。考虑一个两层的非线性网络：</p><p>$$\mathbf{y} = \sigma(W_2 \cdot \sigma(W_1 \cdot \mathbf{x}))$$</p><p>要让 $\mathbf{y} = \mathbf{x}$，需要 $W_1$ 和 $W_2$ 满足特定的约束，而这种约束在随机初始化和高维空间中很难满足。优化器可能会陷入局部最优，或者需要极长时间才能找到合适的参数。</p><h2 id=第二章残差学习的核心思想>第二章：残差学习的核心思想<a hidden class=anchor aria-hidden=true href=#第二章残差学习的核心思想>#</a></h2><h3 id=21-重新定义学习目标>2.1 重新定义学习目标<a hidden class=anchor aria-hidden=true href=#21-重新定义学习目标>#</a></h3><p>ResNet 的核心洞察是：<strong>与其让网络学习从输入到输出的直接映射，不如让它学习输入与输出之间的差异</strong>。这就是"残差"一词的由来。</p><p>形式化地，假设我们希望学习一个映射 $\mathcal{H}(\mathbf{x})$。传统网络直接拟合这个映射：</p><p>$$\mathbf{y} = \mathcal{H}(\mathbf{x})$$</p><p>ResNet 则引入一个残差映射：</p><p>$$\mathcal{F}(\mathbf{x}) = \mathcal{H}(\mathbf{x}) - \mathbf{x}$$</p><p>于是，原始映射可以重写为：</p><p>$$\mathbf{y} = \mathcal{F}(\mathbf{x}) + \mathbf{x}$$</p><p>这被称为<strong>残差学习框架</strong>。</p><h3 id=22-为什么残差更容易学习>2.2 为什么残差更容易学习？<a hidden class=anchor aria-hidden=true href=#22-为什么残差更容易学习>#</a></h3><p>现在问题来了：为什么学习 $\mathcal{F}(\mathbf{x})$ 比学习 $\mathcal{H}(\mathbf{x})$ 更容易？</p><p>考虑退化问题的极端情况：如果最优映射就是恒等映射（即 $\mathcal{H}(\mathbf{x}) = \mathbf{x}$），那么：</p><ul><li>传统网络需要学习 $\mathcal{H}(\mathbf{x}) = \mathbf{x}$</li><li>残差网络只需要学习 $\mathcal{F}(\mathbf{x}) = \mathbf{0}$</li></ul><p><strong>将参数推向零比学习恒等映射要容易得多</strong>。在所有可能的参数配置中，零是一个特殊的、容易达到的点。通过 L2 正则化或权重衰减，优化器实际上被鼓励向零靠近。</p><p>更一般地，如果最优映射接近恒等映射，残差网络只需要学习一个"小"的扰动，而传统网络需要学习完整的映射。</p><h3 id=23-跳跃连接的实现>2.3 跳跃连接的实现<a hidden class=anchor aria-hidden=true href=#23-跳跃连接的实现>#</a></h3><p>残差学习的实现通过一个极其简单的结构——<strong>跳跃连接</strong>（skip connection）或<strong>快捷连接</strong>（shortcut connection）：</p><p><img alt=残差块结构 loading=lazy src=/images/plots/resnet-block.png></p><p>如上图所示，输入 $\mathbf{x}$ 经过几个卷积层（以及 BN、ReLU）产生 $\mathcal{F}(\mathbf{x})$，然后与原始输入 $\mathbf{x}$ 相加，再通过激活函数。</p><p>数学上，一个基本的残差块（Residual Block）可以表示为：</p><p>$$\mathbf{y} = \mathcal{F}(\mathbf{x}, {W_i}) + \mathbf{x}$$</p><p>其中 $\mathcal{F}$ 表示要学习的残差映射。对于图中的两层残差块：</p><p>$$\mathcal{F}(\mathbf{x}) = W_2 \cdot \sigma(W_1 \cdot \mathbf{x})$$</p><p>注意这里的 $\sigma$ 表示 ReLU，而 $W_1$ 和 $W_2$ 是卷积层的权重。</p><h3 id=24-维度匹配问题>2.4 维度匹配问题<a hidden class=anchor aria-hidden=true href=#24-维度匹配问题>#</a></h3><p>在实际实现中，还有一个细节需要考虑：当残差路径改变特征图尺寸（如通过步长为 2 的卷积下采样）或通道数时，直接相加 $\mathcal{F}(\mathbf{x}) + \mathbf{x}$ 可能会有维度不匹配的问题。</p><p>ResNet 提供了两种解决方案：</p><p><strong>方案 A：零填充</strong>（Zero-padding）</p><p>通过零填充增加通道数，不使用额外参数：</p><p>$$\mathbf{y} = \mathcal{F}(\mathbf{x}) + [\mathbf{x}, \mathbf{0}]$$</p><p><strong>方案 B：投影 shortcut</strong>（Projection shortcut）</p><p>使用 $1 \times 1$ 卷积进行投影：</p><p>$$\mathbf{y} = \mathcal{F}(\mathbf{x}) + W_s \cdot \mathbf{x}$$</p><p>其中 $W_s$ 是 $1 \times 1$ 卷积的权重矩阵。这种方法引入少量额外参数，但性能稍好。</p><h2 id=第三章残差网络的数学分析>第三章：残差网络的数学分析<a hidden class=anchor aria-hidden=true href=#第三章残差网络的数学分析>#</a></h2><h3 id=31-前向传播的动力学>3.1 前向传播的动力学<a hidden class=anchor aria-hidden=true href=#31-前向传播的动力学>#</a></h3><p>让我们更深入地分析残差连接对前向传播的影响。考虑一个由 $L$ 个残差块组成的网络：</p><p>$$\mathbf{x}_{l+1} = \mathbf{x}_l + \mathcal{F}(\mathbf{x}_l, W_l)$$</p><p>通过递归展开，第 $L$ 层的输出可以表示为：</p><p>$$\mathbf{x}_L = \mathbf{x}<em>l + \sum</em>{i=l}^{L-1} \mathcal{F}(\mathbf{x}_i, W_i)$$</p><p>这个公式揭示了一个重要性质：<strong>任何一层的特征都可以表示为之前任意一层特征加上一个残差之和</strong>。这与传统网络形成鲜明对比——在传统网络中，特征是一系列非线性变换的复合。</p><h3 id=32-反向传播的梯度流动>3.2 反向传播的梯度流动<a hidden class=anchor aria-hidden=true href=#32-反向传播的梯度流动>#</a></h3><p>残差连接对梯度反向传播的影响更为关键。考虑损失函数 $\mathcal{L}$ 对第 $l$ 层输入的梯度：</p><p>$$\frac{\partial \mathcal{L}}{\partial \mathbf{x}_l} = \frac{\partial \mathcal{L}}{\partial \mathbf{x}_L} \cdot \frac{\partial \mathbf{x}_L}{\partial \mathbf{x}_l}$$</p><p>由于 $\mathbf{x}_L = \mathbf{x}<em>l + \sum</em>{i=l}^{L-1} \mathcal{F}(\mathbf{x}_i, W_i)$，我们有：</p><p>$$\frac{\partial \mathbf{x}_L}{\partial \mathbf{x}_l} = I + \frac{\partial}{\partial \mathbf{x}<em>l} \sum</em>{i=l}^{L-1} \mathcal{F}(\mathbf{x}_i, W_i)$$</p><p>因此：</p><p>$$\frac{\partial \mathcal{L}}{\partial \mathbf{x}_l} = \frac{\partial \mathcal{L}}{\partial \mathbf{x}_L} + \frac{\partial \mathcal{L}}{\partial \mathbf{x}_L} \cdot \frac{\partial}{\partial \mathbf{x}<em>l} \sum</em>{i=l}^{L-1} \mathcal{F}(\mathbf{x}_i, W_i)$$</p><p>这个分解显示了残差连接的关键作用：<strong>梯度可以直接从深层流向浅层，而不经过中间层的变换</strong>。第一项 $\frac{\partial \mathcal{L}}{\partial \mathbf{x}_L}$ 是梯度的"高速公路"，第二项则包含通过残差路径的梯度。</p><p><img alt=梯度流动 loading=lazy src=/images/plots/resnet-gradient.png></p><p>上图展示了传统网络与残差网络的梯度流动对比。在传统网络中，梯度需要经过每一层的链式法则乘法，容易导致梯度消失；而在残差网络中，梯度可以通过跳跃连接直接传播。</p><h3 id=33-层响应分析>3.3 层响应分析<a hidden class=anchor aria-hidden=true href=#33-层响应分析>#</a></h3><p>论文中还进行了有趣的层响应分析，即测量每层输出相对于输入的变化程度。结果表明：</p><ol><li>残差网络通常具有比传统网络更小的层响应</li><li>随着网络加深，残差函数变得更小</li></ol><p>这证实了残差学习的假设：网络确实倾向于学习更小的扰动，而非完全的映射。</p><h2 id=第四章resnet-架构详解>第四章：ResNet 架构详解<a hidden class=anchor aria-hidden=true href=#第四章resnet-架构详解>#</a></h2><h3 id=41-基本构建块>4.1 基本构建块<a hidden class=anchor aria-hidden=true href=#41-基本构建块>#</a></h3><p>ResNet 使用两种基本构建块：</p><p><strong>Basic Block</strong>（用于 ResNet-18/34）：</p><p>包含两个 $3 \times 3$ 卷积层：</p><p>$$\mathbf{y} = \sigma(W_2 \cdot \sigma(W_1 \cdot \mathbf{x} + b_1) + b_2) + \mathbf{x}$$</p><p><strong>Bottleneck Block</strong>（用于 ResNet-50/101/152）：</p><p>包含三个卷积层（$1 \times 1$、$3 \times 3$、$1 \times 1$）：</p><p>$$\mathbf{y} = W_3 \cdot \sigma(W_2 \cdot \sigma(W_1 \cdot \mathbf{x})) + \mathbf{x}$$</p><p>其中 $W_1$ 和 $W_3$ 是 $1 \times 1$ 卷积，分别用于降维和升维。这种设计减少了计算量，同时保持了表达能力。</p><h3 id=42-网络架构概览>4.2 网络架构概览<a hidden class=anchor aria-hidden=true href=#42-网络架构概览>#</a></h3><p>以下是不同深度 ResNet 的架构配置：</p><table><thead><tr><th>层名称</th><th>输出尺寸</th><th>ResNet-18</th><th>ResNet-34</th><th>ResNet-50</th><th>ResNet-101</th><th>ResNet-152</th></tr></thead><tbody><tr><td>conv1</td><td>$112 \times 112$</td><td>$7 \times 7$, 64, stride 2</td><td>同上</td><td>同上</td><td>同上</td><td>同上</td></tr><tr><td>pool</td><td>$56 \times 56$</td><td>$3 \times 3$ max pool, stride 2</td><td>同上</td><td>同上</td><td>同上</td><td>同上</td></tr><tr><td>conv2$_\text{x}$</td><td>$56 \times 56$</td><td>$\begin{bmatrix} 3 \times 3, 64 \ 3 \times 3, 64 \end{bmatrix} \times 2$</td><td>$\times 3$</td><td>$\begin{bmatrix} 1 \times 1, 64 \ 3 \times 3, 64 \ 1 \times 1, 256 \end{bmatrix} \times 3$</td><td>$\times 3$</td><td>$\times 3$</td></tr><tr><td>conv3$_\text{x}$</td><td>$28 \times 28$</td><td>$\begin{bmatrix} 3 \times 3, 128 \ 3 \times 3, 128 \end{bmatrix} \times 2$</td><td>$\times 4$</td><td>$\begin{bmatrix} 1 \times 1, 128 \ 3 \times 3, 128 \ 1 \times 1, 512 \end{bmatrix} \times 4$</td><td>$\times 4$</td><td>$\times 8$</td></tr><tr><td>conv4$_\text{x}$</td><td>$14 \times 14$</td><td>$\begin{bmatrix} 3 \times 3, 256 \ 3 \times 3, 256 \end{bmatrix} \times 2$</td><td>$\times 6$</td><td>$\begin{bmatrix} 1 \times 1, 256 \ 3 \times 3, 256 \ 1 \times 1, 1024 \end{bmatrix} \times 6$</td><td>$\times 23$</td><td>$\times 36$</td></tr><tr><td>conv5$_\text{x}$</td><td>$7 \times 7$</td><td>$\begin{bmatrix} 3 \times 3, 512 \ 3 \times 3, 512 \end{bmatrix} \times 2$</td><td>$\times 3$</td><td>$\begin{bmatrix} 1 \times 1, 512 \ 3 \times 3, 512 \ 1 \times 1, 2048 \end{bmatrix} \times 3$</td><td>$\times 3$</td><td>$\times 3$</td></tr><tr><td>全局平均池化</td><td>$1 \times 1$</td><td>全局平均池化</td><td>同上</td><td>同上</td><td>同上</td><td>同上</td></tr><tr><td>全连接层</td><td>1000</td><td>1000-d fc, softmax</td><td>同上</td><td>同上</td><td>同上</td><td>同上</td></tr></tbody></table><h3 id=43-架构设计的关键决策>4.3 架构设计的关键决策<a hidden class=anchor aria-hidden=true href=#43-架构设计的关键决策>#</a></h3><p><strong>1. 步长设计</strong></p><p>每个阶段的第一个残差块使用步长为 2 的卷积进行下采样，将空间维度减半，通道数加倍。</p><p><strong>2. 批归一化位置</strong></p><p>原始 ResNet 在每个卷积层后、激活函数前使用批归一化。后续改进（Identity Mappings in Deep Residual Networks）建议将 BN 和 ReLU 移到残差路径内部，形成"预激活"结构。</p><p><strong>3. 初始卷积层</strong></p><p>使用 $7 \times 7$ 的大卷积核和步长 2 快速降低空间维度，提取低级特征。</p><h2 id=第五章实验与结果分析>第五章：实验与结果分析<a hidden class=anchor aria-hidden=true href=#第五章实验与结果分析>#</a></h2><h3 id=51-imagenet-分类结果>5.1 ImageNet 分类结果<a hidden class=anchor aria-hidden=true href=#51-imagenet-分类结果>#</a></h3><p>ResNet 在 ImageNet 2012 分类数据集上取得了突破性成果：</p><p><img alt="ImageNet 结果" loading=lazy src=/images/plots/resnet-imagenet-results.png></p><p>从图中可以看到：</p><ul><li>ResNet-34（使用投影 shortcut）的错误率比 34 层普通网络低约 3.5%</li><li>ResNet-152 的错误率比 VGG-16/19 低约 3.2%</li><li>更深层的 ResNet-152（60.2M 参数）比 VGG-16（138M 参数）参数量更少但性能更好</li></ul><h3 id=52-退化问题的解决验证>5.2 退化问题的解决验证<a hidden class=anchor aria-hidden=true href=#52-退化问题的解决验证>#</a></h3><p>为了验证残差学习确实解决了退化问题，论文对比了 18 层和 34 层网络：</p><ul><li><strong>普通网络</strong>：34 层比 18 层训练误差更高（退化问题）</li><li><strong>ResNet</strong>：34 层比 18 层训练误差更低，验证误差也更好</li></ul><p>这直接证明了残差连接的有效性。</p><h3 id=53-不同-shortcut-策略的比较>5.3 不同 Shortcut 策略的比较<a hidden class=anchor aria-hidden=true href=#53-不同-shortcut-策略的比较>#</a></h3><p>论文比较了三种 shortcut 策略：</p><p><strong>A）零填充</strong>：增加维度时使用零填充，无额外参数
<strong>B）投影 shortcut</strong>：增加维度时使用 $1 \times 1$ 卷积
**C）所有 shortcut 都使用投影</p><p>结果：B 略优于 A，C 略优于 B，但差距不大。这说明投影 shortcut 并非关键，恒等 shortcut 才是性能提升的主要来源。</p><h3 id=54-超过-1000-层的网络>5.4 超过 1000 层的网络<a hidden class=anchor aria-hidden=true href=#54-超过-1000-层的网络>#</a></h3><p>论文还尝试了超过 1000 层的极深网络（1202 层）：</p><ul><li>训练误差仍然可以降低</li><li>但由于参数量过大（19.4M），出现了过拟合</li><li>使用 maxout 或 dropout 等正则化技术可能进一步改善</li></ul><h2 id=第六章残差网络的影响与拓展>第六章：残差网络的影响与拓展<a hidden class=anchor aria-hidden=true href=#第六章残差网络的影响与拓展>#</a></h2><h3 id=61-对其他视觉任务的迁移>6.1 对其他视觉任务的迁移<a hidden class=anchor aria-hidden=true href=#61-对其他视觉任务的迁移>#</a></h3><p>ResNet 的成功迅速扩展到其他计算机视觉任务：</p><p><strong>目标检测</strong>：Faster R-CNN、Mask R-CNN 等使用 ResNet 作为骨干网络</p><p><strong>语义分割</strong>：FCN、U-Net、DeepLab 等采用 ResNet 提取特征</p><p><strong>人体姿态估计</strong>：Hourglass、SimpleBaseline 等基于残差思想</p><h3 id=62-残差思想的变体>6.2 残差思想的变体<a hidden class=anchor aria-hidden=true href=#62-残差思想的变体>#</a></h3><p>ResNet 启发了大量后续研究：</p><p><strong>DenseNet</strong>：不仅与输入相加，还与之前所有层进行通道拼接</p><p>$$\mathbf{x}_l = H_l([\mathbf{x}_0, \mathbf{x}<em>1, \ldots, \mathbf{x}</em>{l-1}])$$</p><p><strong>ResNeXt</strong>：引入"基数"（cardinality）维度，使用分组卷积：</p><p>$$\mathbf{y} = \mathbf{x} + \sum_{i=1}^{C} T_i(\mathbf{x})$$</p><p><strong>SENet</strong>：在残差块中加入通道注意力机制</p><p><strong>EfficientNet</strong>：结合残差连接和复合缩放策略</p><h3 id=63-resnet-的理论解释>6.3 ResNet 的理论解释<a hidden class=anchor aria-hidden=true href=#63-resnet-的理论解释>#</a></h3><p>后续研究从理论上解释了 ResNet 的成功：</p><p><strong>动态网络视角</strong>：残差网络可以看作是一种集成学习，每一层决定是否使用残差路径</p><p><strong>常微分方程（ODE）视角</strong>：残差块的迭代公式与 Euler 离散化相似：</p><p>$$\mathbf{x}_{t+1} = \mathbf{x}_t + f(\mathbf{x}_t, t)$$</p><p>这启发了 Neural ODE，将残差网络推广到连续深度。</p><p><strong>信息流视角</strong>：残差连接创造了信息高速公路，改善了梯度流和特征复用</p><h2 id=第七章深入理解残差学习>第七章：深入理解残差学习<a hidden class=anchor aria-hidden=true href=#第七章深入理解残差学习>#</a></h2><h3 id=71-集成学习的视角>7.1 集成学习的视角<a hidden class=anchor aria-hidden=true href=#71-集成学习的视角>#</a></h3><p>2016 年，一项有趣的研究揭示了 ResNet 的另一种解释：<strong>一个 ResNet 实际上是一个指数级大小的隐式集成模型</strong>。</p><p>考虑一个 3 块残差网络，通过递归展开：</p><p>$$\mathbf{x}_3 = \mathbf{x}_0 + \mathcal{F}_1(\mathbf{x}_0) + \mathcal{F}_2(\mathbf{x}_1) + \mathcal{F}_3(\mathbf{x}_2)$$</p><p>如果每个残差块可以选择"使用"或"不使用"，那么 $n$ 个残差块可以产生 $2^n$ 条不同的路径。这解释了为什么删除 ResNet 中的某些层对性能影响很小——网络有其他路径可以补偿。</p><h3 id=72-动态深度的适应性>7.2 动态深度的适应性<a hidden class=anchor aria-hidden=true href=#72-动态深度的适应性>#</a></h3><p>残差网络的另一个有趣特性是<strong>动态深度</strong>。在测试时，网络可以根据输入的复杂度选择"使用"多少层。简单样本可能只需要前几层，复杂样本则会利用深层特征。</p><p>这与 Dropout 有相似之处——都是某种形式的模型平均，但 ResNet 的结构化路径选择更加高效。</p><h3 id=73-与-highway-networks-的关系>7.3 与 Highway Networks 的关系<a hidden class=anchor aria-hidden=true href=#73-与-highway-networks-的关系>#</a></h3><p>在 ResNet 之前，Highway Networks 也提出了类似的门控机制：</p><p>$$\mathbf{y} = T(\mathbf{x}) \cdot \mathcal{F}(\mathbf{x}) + (1 - T(\mathbf{x})) \cdot \mathbf{x}$$</p><p>其中 $T(\mathbf{x})$ 是一个门控函数（通常用 sigmoid）。ResNet 可以看作 Highway Network 的特例，其中 $T(\mathbf{x}) = 0.5$（固定不变）。</p><p>这种简化带来了两个好处：</p><ol><li>参数量减半（不需要门控参数）</li><li>恒等连接始终畅通，梯度流动更直接</li></ol><h2 id=结语>结语<a hidden class=anchor aria-hidden=true href=#结语>#</a></h2><p>ResNet 的提出是深度学习发展史上的一个里程碑。它通过一个简单而优雅的跳跃连接，解决了深层网络的退化问题，使得训练数百层甚至上千层的网络成为可能。</p><p>回顾这篇论文的核心贡献：</p><ol><li><strong>问题识别</strong>：明确指出深层网络的退化问题，并区分于梯度消失</li><li><strong>核心思想</strong>：提出残差学习框架，让网络学习残差而非直接映射</li><li><strong>简洁实现</strong>：通过恒等 shortcut 实现，几乎不增加额外计算</li><li><strong>实验验证</strong>：在 ImageNet 等数据集上验证了超深网络的有效性</li></ol><p>ResNet 的成功告诉我们：有时候，解决问题的最佳方式不是设计更复杂的模块，而是重新思考问题的本质。学习"差异"比学习"全部"更容易，这个简单却深刻的洞见，至今仍在影响着深度学习的发展。</p><p>从 2015 年至今，ResNet 已经成为计算机视觉领域的标准组件。无论是图像分类、目标检测、语义分割还是其他视觉任务，残差连接都是不可或缺的元素。它证明了好的架构设计可以跨越时间和任务，产生持久的影响力。</p><h2 id=参考文献>参考文献<a hidden class=anchor aria-hidden=true href=#参考文献>#</a></h2><ol><li><p>He, K., Zhang, X., Ren, S., & Sun, J. (2016). &ldquo;Deep Residual Learning for Image Recognition.&rdquo; <em>Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</em>, 770-778.</p></li><li><p>He, K., Zhang, X., Ren, S., & Sun, J. (2016). &ldquo;Identity Mappings in Deep Residual Networks.&rdquo; <em>European Conference on Computer Vision (ECCV)</em>, 630-645.</p></li><li><p>Veit, A., Wilber, M. J., & Belongie, S. (2016). &ldquo;Residual Networks Behave Like Ensembles of Relatively Shallow Networks.&rdquo; <em>Advances in Neural Information Processing Systems (NeurIPS)</em>, 29.</p></li><li><p>Srivastava, R. K., Greff, K., & Schmidhuber, J. (2015). &ldquo;Highway Networks.&rdquo; <em>arXiv preprint arXiv:1505.00387</em>.</p></li><li><p>Huang, G., Liu, Z., Van Der Maaten, L., & Weinberger, K. Q. (2017). &ldquo;Densely Connected Convolutional Networks.&rdquo; <em>Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</em>, 4700-4708.</p></li><li><p>Chen, R. T., Rubanova, Y., Bettencourt, J., & Duvenaud, D. (2018). &ldquo;Neural Ordinary Differential Equations.&rdquo; <em>Advances in Neural Information Processing Systems (NeurIPS)</em>, 31.</p></li></ol></div><footer class=post-footer><ul class=post-tags><li><a href=https://s-ai-unix.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/>深度学习</a></li><li><a href=https://s-ai-unix.github.io/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/>神经网络</a></li><li><a href=https://s-ai-unix.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/>机器学习</a></li><li><a href=https://s-ai-unix.github.io/tags/%E7%BB%BC%E8%BF%B0/>综述</a></li></ul><nav class=paginav><a class=prev href=https://s-ai-unix.github.io/posts/2026-01-30-ai-%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB%E7%B3%BB%E5%88%97vision-transformer-%E8%A7%86%E8%A7%89transformer/><span class=title>« Prev</span><br><span>AI 论文解读系列：Vision Transformer 视觉Transformer</span>
</a><a class=next href=https://s-ai-unix.github.io/posts/2026-01-29-fenchel-schur-theorems/><span class=title>Next »</span><br><span>从弯曲到一致性：微分几何中的芬切尔定理与舒尔定理</span></a></nav><ul class=share-buttons><li><a target=_blank rel="noopener noreferrer" aria-label="share AI 论文解读系列：ResNet 深度残差学习 on x" href="https://x.com/intent/tweet/?text=AI%20%e8%ae%ba%e6%96%87%e8%a7%a3%e8%af%bb%e7%b3%bb%e5%88%97%ef%bc%9aResNet%20%e6%b7%b1%e5%ba%a6%e6%ae%8b%e5%b7%ae%e5%ad%a6%e4%b9%a0&amp;url=https%3a%2f%2fs-ai-unix.github.io%2fposts%2f2026-01-30-ai-%25E8%25AE%25BA%25E6%2596%2587%25E8%25A7%25A3%25E8%25AF%25BB%25E7%25B3%25BB%25E5%2588%2597%25E4%25B9%258Bresnet-%25E6%25B7%25B1%25E5%25BA%25A6%25E6%25AE%258B%25E5%25B7%25AE%25E5%25AD%25A6%25E4%25B9%25A0%2f&amp;hashtags=%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0%2c%e7%a5%9e%e7%bb%8f%e7%bd%91%e7%bb%9c%2c%e6%9c%ba%e5%99%a8%e5%ad%a6%e4%b9%a0%2c%e7%bb%bc%e8%bf%b0"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446C483.971.0 512 28.03 512 62.554zM269.951 190.75 182.567 75.216H56L207.216 272.95 63.9 436.783h61.366L235.9 310.383l96.667 126.4H456L298.367 228.367l134-153.151H371.033zM127.633 110h36.468l219.38 290.065H349.5z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share AI 论文解读系列：ResNet 深度残差学习 on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fs-ai-unix.github.io%2fposts%2f2026-01-30-ai-%25E8%25AE%25BA%25E6%2596%2587%25E8%25A7%25A3%25E8%25AF%25BB%25E7%25B3%25BB%25E5%2588%2597%25E4%25B9%258Bresnet-%25E6%25B7%25B1%25E5%25BA%25A6%25E6%25AE%258B%25E5%25B7%25AE%25E5%25AD%25A6%25E4%25B9%25A0%2f&amp;title=AI%20%e8%ae%ba%e6%96%87%e8%a7%a3%e8%af%bb%e7%b3%bb%e5%88%97%ef%bc%9aResNet%20%e6%b7%b1%e5%ba%a6%e6%ae%8b%e5%b7%ae%e5%ad%a6%e4%b9%a0&amp;summary=AI%20%e8%ae%ba%e6%96%87%e8%a7%a3%e8%af%bb%e7%b3%bb%e5%88%97%ef%bc%9aResNet%20%e6%b7%b1%e5%ba%a6%e6%ae%8b%e5%b7%ae%e5%ad%a6%e4%b9%a0&amp;source=https%3a%2f%2fs-ai-unix.github.io%2fposts%2f2026-01-30-ai-%25E8%25AE%25BA%25E6%2596%2587%25E8%25A7%25A3%25E8%25AF%25BB%25E7%25B3%25BB%25E5%2588%2597%25E4%25B9%258Bresnet-%25E6%25B7%25B1%25E5%25BA%25A6%25E6%25AE%258B%25E5%25B7%25AE%25E5%25AD%25A6%25E4%25B9%25A0%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share AI 论文解读系列：ResNet 深度残差学习 on reddit" href="https://reddit.com/submit?url=https%3a%2f%2fs-ai-unix.github.io%2fposts%2f2026-01-30-ai-%25E8%25AE%25BA%25E6%2596%2587%25E8%25A7%25A3%25E8%25AF%25BB%25E7%25B3%25BB%25E5%2588%2597%25E4%25B9%258Bresnet-%25E6%25B7%25B1%25E5%25BA%25A6%25E6%25AE%258B%25E5%25B7%25AE%25E5%25AD%25A6%25E4%25B9%25A0%2f&title=AI%20%e8%ae%ba%e6%96%87%e8%a7%a3%e8%af%bb%e7%b3%bb%e5%88%97%ef%bc%9aResNet%20%e6%b7%b1%e5%ba%a6%e6%ae%8b%e5%b7%ae%e5%ad%a6%e4%b9%a0"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share AI 论文解读系列：ResNet 深度残差学习 on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fs-ai-unix.github.io%2fposts%2f2026-01-30-ai-%25E8%25AE%25BA%25E6%2596%2587%25E8%25A7%25A3%25E8%25AF%25BB%25E7%25B3%25BB%25E5%2588%2597%25E4%25B9%258Bresnet-%25E6%25B7%25B1%25E5%25BA%25A6%25E6%25AE%258B%25E5%25B7%25AE%25E5%25AD%25A6%25E4%25B9%25A0%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a></li></ul></footer><script src=https://giscus.app/client.js data-repo=s-ai-unix/blog data-repo-id=R_kgDOQ3Njaw data-category=General data-category-id=DIC_kwDOQ3Nja84C0yve data-mapping=pathname data-strict=0 data-reactions-enabled=1 data-emit-metadata=0 data-input-position=bottom data-theme=preferred_color_scheme data-lang=zh-CN data-loading=lazy crossorigin=anonymous async></script></article></main><footer class=footer><span>&copy; 2026 <a href=https://s-ai-unix.github.io/>s-ai-unix's Blog</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
<a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script>(function(){"use strict";function e(){var e=document.querySelectorAll("p, li, td, div, span, h1, h2, h3, h4, h5, h6, ol, ul");e.forEach(function(e){if(e.classList.contains("classical-quote-container")||e.classList.contains("quote-text")||e.closest(".classical-quote-container"))return;var t,n=e.innerHTML,s=!1;for(n.indexOf("<em>")!==-1&&(t=n.replace(/\$([^$]*?)<em>([^<]+?)<\/em>([^$]*?)\$/g,function(e,t,n,s){return/^[\d.,]+$/.test((t+n+s).replace(/[.,]/g,""))?e:"$"+t+"_"+n+s+"$"}),t=t.replace(/\$\$([^$]*?)<em>([^<]+?)<\/em>([^$]*?)\$\$/g,function(e,t,n,s){return"$$"+t+"_"+n+s+"$$"}),t!==n&&(n=t,s=!0)),n.indexOf("</em>")!==-1&&(t=n.replace(/\$([^$]*?)<\/em>([^$]*?)\$/g,function(e,t,n){return"$"+t+"_{"+n+"$"}),t=t.replace(/\$\$([^$]*?)<\/em>([^$]*?)\$\$/g,function(e,t,n){return"$$"+t+"_{"+n+"$$"}),t!==n&&(n=t,s=!0)),n.indexOf("<em>$")!==-1&&(t=n.replace(/<em>\$/g,"$"),t!==n&&(n=t,s=!0)),n.indexOf("</em>$")!==-1&&(t=n.replace(/<\/em>\$/g,"$"),t!==n&&(n=t,s=!0));n.indexOf("<em>")!==-1&&n.indexOf("</em>")!==-1;){if(t=n.replace(/\$([^$]*?)<em>([^<]+?)<\/em>([^$]*?)\$/g,function(e,t,n,s){return/^[\d.,]+$/.test((t+n+s).replace(/[.,]/g,""))?e:"$"+t+"_"+n+s+"$"}),t=t.replace(/\$\$([^$]*?)<em>([^<]+?)<\/em>([^$]*?)\$\$/g,function(e,t,n,s){return"$$"+t+"_"+n+s+"$$"}),t===n)break;n=t,s=!0}n.indexOf("_{")!==-1&&(t=n.replace(/_{/g,"_{"),t!==n&&(n=t,s=!0)),n.indexOf("}_")!==-1&&(t=n.replace(/}_/g,"}"),t!==n&&(n=t,s=!0)),n.includes("</em>{")&&(t=n.replace(/\\mathbf\{(W|x|y|z)\}<\/em>\{\\mathrm\{([a-z]+)\}\}/g,"\\mathbf{$1}_{\\mathrm{$2}}"),t=t.replace(/([LHf])<\/em>\{\\mathrm\{([a-z]+)\}\}/g,"$1_{\\mathrm{$2}}"),t=t.replace(/\\nabla ([LHf])<\/em>\{\\mathrm\{([a-z]+)\}\}/g,`\\nabla $1_{\\mathrm{$2}}`),t=t.replace(/([A-Z])<\/em>\{\\mathrm\{([a-z]+)\}\}/g,"$1_{\\mathrm{$2}}"),t!==n&&(n=t,s=!0)),n.includes("<em>{\\mathrm{")&&(t=n.replace(/\\mathbf\{(W|x|y|z)\}<em>\{\\mathrm\{([a-z]+)\}\}/g,"\\mathbf{$1}_{\\mathrm{$2}}"),t=t.replace(/([LHf])<em>\{\\mathrm\{([a-z]+)\}\}/g,"$1_{\\mathrm{$2}}"),t=t.replace(/\\nabla ([LHf])<em>\{\\mathrm\{([a-z]+)\}\}/g,`\\nabla $1_{\\mathrm{$2}}`),t=t.replace(/([A-Z])<em>\{\\mathrm\{([a-z]+)\}\}/g,"$1_{\\mathrm{$2}}"),t!==n&&(n=t,s=!0)),(n.includes("</em>")||n.includes("<em>"))&&(t=n.replace(/(\$[^$]*?)<em>([^$]*?)<\/em>/g,"$1_{$2}"),t=t.replace(/(\$\$[^$]*?)<em>([^$]*?)<\/em>/g,"$1_{$2}"),t=t.replace(/(\$[^$]*?)<em>/g,"$1"),t=t.replace(/<em>([^$]*?\$)/g,"$1"),t=t.replace(/(\$[^$]*?)<\/em>/g,"$1"),t=t.replace(/<\/em>([^$]*?\$)/g,"$1"),t!==n&&(n=t,s=!0)),n.indexOf("\\\\")!==-1&&(t=n.replace(/(\$\{1,2\})([^$]*?)(\$\{1,2\})/g,function(e,t,n,s){for(;n.indexOf("\\\\")!==-1;)n=n.replace(/\\\\/g,"\\");return t+n+s}),t!==n&&(n=t,s=!0)),s&&(e.innerHTML=n)})}window.MathJax={tex:{inlineMath:[["$","$"]],displayMath:[["$$","$$"]],processEscapes:!0,processEnvironments:!0,tags:"ams",packages:{"[+]":["noerrors","noundefined","boldsymbol"]},macros:{oiint:"\\mathop{∯}",oiiint:"\\mathop{∰}"}},options:{skipHtmlTags:["script","noscript","style","textarea","pre","code"]},startup:{pageReady:function(){return e(),MathJax.startup.defaultPageReady().then(function(){console.log("MathJax formulas rendered successfully")})}}}})()</script><script src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script><link rel=stylesheet href=/css/mermaid-custom.css><script src=/js/mermaid-converter.js></script><script type=module>
  import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs';

  
  setTimeout(() => {
    mermaid.initialize({
      startOnLoad: true,
      theme: 'base',
      themeVariables: {
        primaryColor: '#e3f2fd',
        primaryTextColor: '#1565c0',
        primaryBorderColor: '#2196f3',
        lineColor: '#42a5f5',
        secondaryColor: '#f3e5f5',
        tertiaryColor: '#fff9c4',
        background: '#ffffff',
        mainBkg: '#ffffff',
        nodeBorder: '#2196f3',
        clusterBkg: '#ffffff',
        clusterBorder: '#e0e0e0',
        titleColor: '#1565c0',
        edgeLabelBackground: '#fafafa',
      },
      securityLevel: 'loose',
    });
  }, 100);
</script><script src=/js/toc.js></script><script>let menu=document.getElementById("menu");if(menu){const e=localStorage.getItem("menu-scroll-position");e&&(menu.scrollLeft=parseInt(e,10)),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}}document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{const e=document.querySelector("html");e.dataset.theme==="dark"?(e.dataset.theme="light",localStorage.setItem("pref-theme","light")):(e.dataset.theme="dark",localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script><script>(function(){"use strict";function e(){var e=document.querySelectorAll("p, li, td, div, span, h1, h2, h3, h4, h5, h6, ol, ul");e.forEach(function(e){if(e.classList.contains("classical-quote-container")||e.classList.contains("quote-text")||e.closest(".classical-quote-container"))return;var t,n=e.innerHTML,s=!1;for(n.indexOf("<em>")!==-1&&(t=n.replace(/\$([^$]*?)<em>([^<]+?)<\/em>([^$]*?)\$/g,function(e,t,n,s){return/^[\d.,]+$/.test((t+n+s).replace(/[.,]/g,""))?e:"$"+t+"_"+n+s+"$"}),t=t.replace(/\$\$([^$]*?)<em>([^<]+?)<\/em>([^$]*?)\$\$/g,function(e,t,n,s){return"$$"+t+"_"+n+s+"$$"}),t!==n&&(n=t,s=!0)),n.indexOf("</em>")!==-1&&(t=n.replace(/\$([^$]*?)<\/em>([^$]*?)\$/g,function(e,t,n){return"$"+t+"_{"+n+"$"}),t=t.replace(/\$\$([^$]*?)<\/em>([^$]*?)\$\$/g,function(e,t,n){return"$$"+t+"_{"+n+"$$"}),t!==n&&(n=t,s=!0)),n.indexOf("<em>$")!==-1&&(t=n.replace(/<em>\$/g,"$"),t!==n&&(n=t,s=!0)),n.indexOf("</em>$")!==-1&&(t=n.replace(/<\/em>\$/g,"$"),t!==n&&(n=t,s=!0));n.indexOf("<em>")!==-1&&n.indexOf("</em>")!==-1;){if(t=n.replace(/\$([^$]*?)<em>([^<]+?)<\/em>([^$]*?)\$/g,function(e,t,n,s){return/^[\d.,]+$/.test((t+n+s).replace(/[.,]/g,""))?e:"$"+t+"_"+n+s+"$"}),t=t.replace(/\$\$([^$]*?)<em>([^<]+?)<\/em>([^$]*?)\$\$/g,function(e,t,n,s){return"$$"+t+"_"+n+s+"$$"}),t===n)break;n=t,s=!0}n.indexOf("_{")!==-1&&(t=n.replace(/_{/g,"_{"),t!==n&&(n=t,s=!0)),n.indexOf("}_")!==-1&&(t=n.replace(/}_/g,"}"),t!==n&&(n=t,s=!0)),n.includes("</em>{")&&(t=n.replace(/\\mathbf\{(W|x|y|z)\}<\/em>\{\\mathrm\{([a-z]+)\}\}/g,"\\mathbf{$1}_{\\mathrm{$2}}"),t=t.replace(/([LHf])<\/em>\{\\mathrm\{([a-z]+)\}\}/g,"$1_{\\mathrm{$2}}"),t=t.replace(/\\nabla ([LHf])<\/em>\{\\mathrm\{([a-z]+)\}\}/g,`\\nabla $1_{\\mathrm{$2}}`),t=t.replace(/([A-Z])<\/em>\{\\mathrm\{([a-z]+)\}\}/g,"$1_{\\mathrm{$2}}"),t!==n&&(n=t,s=!0)),n.includes("<em>{\\mathrm{")&&(t=n.replace(/\\mathbf\{(W|x|y|z)\}<em>\{\\mathrm\{([a-z]+)\}\}/g,"\\mathbf{$1}_{\\mathrm{$2}}"),t=t.replace(/([LHf])<em>\{\\mathrm\{([a-z]+)\}\}/g,"$1_{\\mathrm{$2}}"),t=t.replace(/\\nabla ([LHf])<em>\{\\mathrm\{([a-z]+)\}\}/g,`\\nabla $1_{\\mathrm{$2}}`),t=t.replace(/([A-Z])<em>\{\\mathrm\{([a-z]+)\}\}/g,"$1_{\\mathrm{$2}}"),t!==n&&(n=t,s=!0)),(n.includes("</em>")||n.includes("<em>"))&&(t=n.replace(/(\$[^$]*?)<em>([^$]*?)<\/em>/g,"$1_{$2}"),t=t.replace(/(\$\$[^$]*?)<em>([^$]*?)<\/em>/g,"$1_{$2}"),t=t.replace(/(\$[^$]*?)<em>/g,"$1"),t=t.replace(/<em>([^$]*?\$)/g,"$1"),t=t.replace(/(\$[^$]*?)<\/em>/g,"$1"),t=t.replace(/<\/em>([^$]*?\$)/g,"$1"),t!==n&&(n=t,s=!0)),n.indexOf("\\\\")!==-1&&(t=n.replace(/(\$\{1,2\})([^$]*?)(\$\{1,2\})/g,function(e,t,n,s){for(;n.indexOf("\\\\")!==-1;)n=n.replace(/\\\\/g,"\\");return t+n+s}),t!==n&&(n=t,s=!0)),s&&(e.innerHTML=n)})}window.MathJax={tex:{inlineMath:[["$","$"]],displayMath:[["$$","$$"]],processEscapes:!0,processEnvironments:!0,tags:"ams",packages:{"[+]":["noerrors","noundefined","boldsymbol"]},macros:{oiint:"\\mathop{∯}",oiiint:"\\mathop{∰}"}},options:{skipHtmlTags:["script","noscript","style","textarea","pre","code"]},startup:{pageReady:function(){return e(),MathJax.startup.defaultPageReady().then(function(){console.log("MathJax formulas rendered successfully")})}}}})()</script><script src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script><link rel=stylesheet href=/css/mermaid-custom.css><script src=/js/mermaid-converter.js></script><script type=module>
  import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs';

  
  setTimeout(() => {
    mermaid.initialize({
      startOnLoad: true,
      theme: 'base',
      themeVariables: {
        primaryColor: '#e3f2fd',
        primaryTextColor: '#1565c0',
        primaryBorderColor: '#2196f3',
        lineColor: '#42a5f5',
        secondaryColor: '#f3e5f5',
        tertiaryColor: '#fff9c4',
        background: '#ffffff',
        mainBkg: '#ffffff',
        nodeBorder: '#2196f3',
        clusterBkg: '#ffffff',
        clusterBorder: '#e0e0e0',
        titleColor: '#1565c0',
        edgeLabelBackground: '#fafafa',
      },
      securityLevel: 'loose',
    });
  }, 100);
</script><script src=/js/toc.js></script></body></html>
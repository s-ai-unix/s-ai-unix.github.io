#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
åå¥æ•°æ®è·å–ã€éªŒè¯å’Œåˆ†ç‰‡å­˜å‚¨è„šæœ¬
ä» GitHub æ•°æ®æºè·å–åå¥ï¼Œå»é‡ã€éªŒè¯ï¼Œå¹¶åˆ†ç‰‡å­˜å‚¨

æ•°æ®æºï¼š
- ä¸­æ–‡å¤è¯—è¯ï¼šhttps://github.com/chinese-poetry/chinese-poetry (336,000+é¦–)
- å›½é™…åå¥ APIï¼šhttps://api.quotable.io (RESTful API)
- å›½é™…åå¥ CSVï¼šhttps://github.com/ShivaliGoel/Quotes-500K (500,000æ¡)
"""

import json
import requests
import os
import hashlib
import time
from typing import List, Dict, Set
from pathlib import Path
import csv
import random


class QuotesManager:
    """åå¥ç®¡ç†å™¨ï¼šè´Ÿè´£è·å–ã€éªŒè¯ã€å»é‡å’Œåˆ†ç‰‡å­˜å‚¨"""

    def __init__(self, output_dir: str = "./static/quotes", shard_size: int = 500):
        """
        åˆå§‹åŒ–åå¥ç®¡ç†å™¨

        Args:
            output_dir: è¾“å‡ºç›®å½•
            shard_size: æ¯ä¸ªåˆ†ç‰‡çš„åå¥æ•°é‡
        """
        self.output_dir = Path(output_dir)
        self.shard_size = shard_size
        self.all_quotes: List[Dict] = []
        self.seen_hashes: Set[str] = set()
        self.seen_content_authors: Set[str] = set()

        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        self.output_dir.mkdir(parents=True, exist_ok=True)

    def normalize_text(self, text: str) -> str:
        """è§„èŒƒåŒ–æ–‡æœ¬ï¼šå»é™¤é¦–å°¾ç©ºæ ¼ã€å¤šä½™ç©ºæ ¼"""
        return text.strip()

    def generate_quote_hash(self, quote: Dict) -> str:
        """ç”Ÿæˆåå¥çš„å”¯ä¸€å“ˆå¸Œå€¼"""
        content = self.normalize_text(quote.get("quote", quote.get("content", "")))
        author = self.normalize_text(quote.get("author", ""))
        hash_input = f"{content}|{author}"
        return hashlib.md5(hash_input.encode('utf-8')).hexdigest()

    def is_duplicate(self, quote: Dict) -> bool:
        """æ£€æŸ¥æ˜¯å¦é‡å¤"""
        content = self.normalize_text(quote.get("quote", quote.get("content", "")))
        author = self.normalize_text(quote.get("author", ""))

        # æ–¹æ³•1: å†…å®¹+ä½œè€…ç»„åˆæ£€æŸ¥
        content_author = f"{content}|{author}"
        if content_author in self.seen_content_authors:
            return True

        # æ–¹æ³•2: å“ˆå¸Œå€¼æ£€æŸ¥
        quote_hash = self.generate_quote_hash(quote)
        if quote_hash in self.seen_hashes:
            return True

        return False

    def normalize_quote_format(self, quote: Dict) -> Dict:
        """ç»Ÿä¸€åå¥æ ¼å¼"""
        # æ ‡å‡†åŒ–å­—æ®µå
        normalized = {
            "quote": self.normalize_text(
                quote.get("quote") or quote.get("content") or ""
            ),
            "author": self.normalize_text(
                quote.get("author") or quote.get("authorSlug") or ""
            ),
            "source": self.normalize_text(
                quote.get("source") or quote.get("origin") or quote.get("title") or ""
            ),
            "dynasty": self.normalize_text(
                quote.get("dynasty") or quote.get("category") or ""
            ),
            "tags": quote.get("tags", [])
        }

        # å¦‚æœæœ‰å…¶ä»–å­—æ®µä¹Ÿä¿ç•™
        for key, value in quote.items():
            if key not in normalized and not isinstance(value, (list, dict)):
                normalized[key] = value

        return normalized

    def validate_quote(self, quote: Dict) -> bool:
        """éªŒè¯åå¥æ˜¯å¦æœ‰æ•ˆ"""
        if not quote:
            return False

        content = self.normalize_text(quote.get("quote", quote.get("content", "")))

        # åŸºæœ¬éªŒè¯
        if len(content) < 5:  # å¤ªçŸ­
            return False

        if len(content) > 500:  # å¤ªé•¿
            return False

        # æ£€æŸ¥ä¹±ç ï¼ˆç®€å•å¯å‘å¼ï¼‰
        try:
            content.encode('utf-8').decode('utf-8')
        except UnicodeError:
            return False

        # æ£€æŸ¥æ˜¯å¦æœ‰è¿‡å¤šç‰¹æ®Šå­—ç¬¦
        special_chars = sum(1 for c in content if not c.isalnum() and not c.isspace() and not ord(c) > 127)
        if special_chars / len(content) > 0.5:  # è¶…è¿‡50%æ˜¯ç‰¹æ®Šå­—ç¬¦
            return False

        return True

    def add_quote(self, quote: Dict) -> bool:
        """
        æ·»åŠ åå¥åˆ°é›†åˆ

        Returns:
            bool: æ˜¯å¦æˆåŠŸæ·»åŠ ï¼ˆfalseè¡¨ç¤ºé‡å¤æˆ–æ— æ•ˆï¼‰
        """
        # è§„èŒƒåŒ–æ ¼å¼
        normalized = self.normalize_quote_format(quote)

        # éªŒè¯
        if not self.validate_quote(normalized):
            return False

        # å»é‡
        if self.is_duplicate(normalized):
            return False

        # æ·»åŠ åˆ°é›†åˆ
        content = normalized["quote"]
        author = normalized["author"]

        self.seen_hashes.add(self.generate_quote_hash(normalized))
        self.seen_content_authors.add(f"{content}|{author}")
        self.all_quotes.append(normalized)

        return True

    def fetch_from_chinese_poetry_github(self, limit: int = 2000) -> int:
        """
        ä» Chinese Poetry GitHub è·å–æ•°æ®

        ä½¿ç”¨ Raw GitHub URL ç›´æ¥è·å– JSON æ•°æ®
        """
        print("ğŸ“š ä» Chinese Poetry GitHub è·å–æ•°æ®...")
        added_count = 0

        # ä½¿ç”¨ jackeyGao çš„ forkï¼Œæ•°æ®æ ¼å¼æ›´è§„èŒƒ
        base_url = "https://raw.githubusercontent.com/jackeyGao/chinese-poetry/master/json/"

        # å”è¯—å’Œå®‹è¯æ•°æ®æ–‡ä»¶
        collections = [
            "poet.tang.0.json",
            "poet.tang.1.json",
            "poet.tang.2.json",
            "poet.song.0.json",
            "ci.song.980.json",
            "ci.south.json",
        ]

        for collection in collections:
            if added_count >= limit:
                break

            try:
                url = f"{base_url}{collection}"
                print(f"  æ­£åœ¨è·å–: {collection}")
                response = requests.get(url, timeout=15)

                if response.status_code == 200:
                    data = response.json()

                    if isinstance(data, list):
                        for poem in data:
                            if added_count >= limit:
                                break

                            # ä»è¯—è¯ä¸­æå–åå¥ï¼ˆå–å‰ä¸¤å¥ï¼‰
                            paragraphs = poem.get("paragraphs", [])

                            if paragraphs and len(paragraphs) >= 1:
                                # æå–å‰1-2å¥ä½œä¸ºåå¥
                                quote_text = paragraphs[0]
                                if len(paragraphs) > 1 and len(paragraphs[0]) < 10:
                                    quote_text = "\n".join(paragraphs[:2])

                                # å¦‚æœå¤ªé•¿ï¼Œåªå–ç¬¬ä¸€å¥
                                if len(quote_text) > 50:
                                    quote_text = paragraphs[0]

                                quote = {
                                    "quote": quote_text,
                                    "author": poem.get("author", ""),
                                    "source": f"ã€Š{poem.get('title', '')}ã€‹",
                                    "dynasty": ""
                                }

                                if self.add_quote(quote):
                                    added_count += 1
                                    if added_count % 100 == 0:
                                        print(f"    å·²æ·»åŠ  {added_count} æ¡")

                    time.sleep(0.5)

            except Exception as e:
                print(f"    âš ï¸  è·å–å¤±è´¥: {e}")
                continue

        print(f"âœ… ä» Chinese Poetry æ·»åŠ äº† {added_count} æ¡åå¥")
        return added_count

    def fetch_from_quotable_api(self, limit: int = 1000) -> int:
        """ä» Quotable API è·å–å›½é™…åå¥"""
        print("ğŸŒ ä» Quotable API è·å–å›½é™…åå¥...")
        added_count = 0

        base_url = "https://api.quotable.io/quotes"
        params = {"limit": 20, "page": 1}

        import urllib3
        urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

        while added_count < limit:
            try:
                response = requests.get(base_url, params=params, timeout=10, verify=False)
                response.raise_for_status()
                data = response.json()

                quotes = data.get("results", [])

                if not quotes:
                    break

                for item in quotes:
                    if added_count >= limit:
                        break

                    quote = {
                        "quote": item.get("content", ""),
                        "author": item.get("author", ""),
                        "source": item.get("tags", [""])[0] if item.get("tags") else "",
                        "dynasty": "",
                        "tags": item.get("tags", [])
                    }

                    if self.add_quote(quote):
                        added_count += 1
                        if added_count % 100 == 0:
                            print(f"    å·²æ·»åŠ  {added_count} æ¡")

                params["page"] += 1
                time.sleep(0.2)

            except Exception as e:
                print(f"    âš ï¸  è·å–å¤±è´¥: {e}")
                break

        print(f"âœ… ä» Quotable API æ·»åŠ äº† {added_count} æ¡åå¥")
        return added_count

    def fetch_from_gushici_api(self, limit: int = 500) -> int:
        """ä» Gushici API è·å–å¤è¯—è¯åå¥"""
        print("ğŸ‹ ä» Gushici API è·å–å¤è¯—è¯åå¥...")
        added_count = 0

        api_url = "https://v1.jinrishici.com/all.json"

        for i in range(limit):
            try:
                response = requests.get(api_url, timeout=10)
                response.raise_for_status()
                data = response.json()

                quote = {
                    "quote": data.get("content", ""),
                    "author": data.get("author", ""),
                    "source": f"ã€Š{data.get('origin', '')}ã€‹",
                    "dynasty": "",
                    "category": data.get("category", "")
                }

                if self.add_quote(quote):
                    added_count += 1
                    if added_count % 100 == 0:
                        print(f"    å·²æ·»åŠ  {added_count} æ¡")

                time.sleep(0.2)  # ç¤¼è²Œæ€§å»¶è¿Ÿ

            except Exception as e:
                print(f"    âš ï¸  è·å–å¤±è´¥: {e}")
                break

        print(f"âœ… ä» Gushici API æ·»åŠ äº† {added_count} æ¡åå¥")
        return added_count

    def load_existing_quotes(self) -> int:
        """åŠ è½½ç°æœ‰çš„åå¥æ•°æ®"""
        existing_file = self.output_dir / "quotes.json"

        if not existing_file.exists():
            return 0

        print(f"ğŸ“– åŠ è½½ç°æœ‰åå¥: {existing_file}")

        try:
            with open(existing_file, 'r', encoding='utf-8') as f:
                existing_quotes = json.load(f)

            for quote in existing_quotes:
                normalized = self.normalize_quote_format(quote)
                if self.validate_quote(normalized):
                    self.seen_hashes.add(self.generate_quote_hash(normalized))
                    content = normalized["quote"]
                    author = normalized["author"]
                    self.seen_content_authors.add(f"{content}|{author}")

            print(f"âœ… å·²åŠ è½½ {len(self.seen_hashes)} æ¡ç°æœ‰åå¥")
            return len(self.seen_hashes)

        except Exception as e:
            print(f"âš ï¸  åŠ è½½å¤±è´¥: {e}")
            return 0

    def shuffle_quotes(self):
        """éšæœºæ‰“ä¹±åå¥é¡ºåº"""
        print("ğŸ”€ éšæœºæ‰“ä¹±åå¥é¡ºåº...")
        random.shuffle(self.all_quotes)

    def save_shards(self) -> List[str]:
        """
        åˆ†ç‰‡å­˜å‚¨åå¥

        Returns:
            List[str]: ç”Ÿæˆçš„åˆ†ç‰‡æ–‡ä»¶ååˆ—è¡¨
        """
        print(f"ğŸ’¾ å¼€å§‹åˆ†ç‰‡å­˜å‚¨ï¼ˆæ¯ç‰‡ {self.shard_size} æ¡ï¼‰...")

        shard_files = []
        total_quotes = len(self.all_quotes)
        num_shards = (total_quotes + self.shard_size - 1) // self.shard_size

        for i in range(num_shards):
            start_idx = i * self.shard_size
            end_idx = min((i + 1) * self.shard_size, total_quotes)
            shard_quotes = self.all_quotes[start_idx:end_idx]

            shard_filename = f"quotes_{i + 1}.json"
            shard_path = self.output_dir / shard_filename

            with open(shard_path, 'w', encoding='utf-8') as f:
                json.dump(shard_quotes, f, ensure_ascii=False, indent=2)

            shard_files.append(shard_filename)
            print(f"  âœ… {shard_filename}: {len(shard_quotes)} æ¡")

        return shard_files

    def save_index(self, shard_files: List[str], total_quotes: int):
        """ä¿å­˜åˆ†ç‰‡ç´¢å¼•æ–‡ä»¶"""
        index = {
            "version": "1.0",
            "total_quotes": total_quotes,
            "shard_size": self.shard_size,
            "total_shards": len(shard_files),
            "shards": shard_files,
            "created_at": time.strftime("%Y-%m-%d %H:%M:%S")
        }

        index_path = self.output_dir / "quotes_index.json"
        with open(index_path, 'w', encoding='utf-8') as f:
            json.dump(index, f, ensure_ascii=False, indent=2)

        print(f"âœ… ç´¢å¼•æ–‡ä»¶å·²ä¿å­˜: {index_path}")

    def generate_all(self, target_count: int = 5000) -> Dict:
        """
        ç”Ÿæˆå®Œæ•´çš„åå¥æ•°æ®é›†

        Args:
            target_count: ç›®æ ‡åå¥æ•°é‡

        Returns:
            Dict: ç”Ÿæˆç»Ÿè®¡ä¿¡æ¯
        """
        print("=" * 60)
        print("ğŸš€ å¼€å§‹ç”Ÿæˆåå¥æ•°æ®é›†")
        print("=" * 60)

        stats = {
            "chinese_poetry": 0,
            "quotable_api": 0,
            "gushici_api": 0,
            "existing": 0,
            "total": 0
        }

        # 1. åŠ è½½ç°æœ‰åå¥
        stats["existing"] = self.load_existing_quotes()

        # 2. ä»å„ä¸ªæ•°æ®æºè·å–åå¥
        remaining = target_count - stats["existing"]

        if remaining > 0:
            # æŒ‰æ¯”ä¾‹åˆ†é…
            chinese_quota = int(remaining * 0.6)  # 60% ä¸­æ–‡
            international_quota = remaining - chinese_quota  # 40% å›½é™…

            stats["chinese_poetry"] = self.fetch_from_chinese_poetry_github(min(chinese_quota, 2000))
            stats["gushici_api"] = self.fetch_from_gushici_api(min(chinese_quota - stats["chinese_poetry"], 500))

            stats["quotable_api"] = self.fetch_from_quotable_api(international_quota)

        # 3. éšæœºæ‰“ä¹±
        self.shuffle_quotes()

        # 4. åˆ†ç‰‡å­˜å‚¨
        shard_files = self.save_shards()

        # 5. ä¿å­˜ç´¢å¼•
        stats["total"] = len(self.all_quotes)
        self.save_index(shard_files, stats["total"])

        # 6. ç»Ÿè®¡ä¿¡æ¯
        print("\n" + "=" * 60)
        print("ğŸ“Š ç”Ÿæˆå®Œæˆï¼ç»Ÿè®¡ä¿¡æ¯ï¼š")
        print("=" * 60)
        print(f"  ç°æœ‰åå¥: {stats['existing']} æ¡")
        print(f"  Chinese Poetry: {stats['chinese_poetry']} æ¡")
        print(f"  Gushici API: {stats['gushici_api']} æ¡")
        print(f"  Quotable API: {stats['quotable_api']} æ¡")
        print(f"  " + "-" * 50)
        print(f"  æ€»è®¡: {stats['total']} æ¡")
        print(f"  åˆ†ç‰‡æ•°: {len(shard_files)} ä¸ªæ–‡ä»¶")
        print(f"  æ¯ç‰‡å¤§å°: {self.shard_size} æ¡")
        print("=" * 60)

        return stats


def main():
    """ä¸»å‡½æ•°"""
    # é…ç½®
    OUTPUT_DIR = "./static/quotes"
    SHARD_SIZE = 500
    TARGET_COUNT = 5000

    # åˆ›å»ºç®¡ç†å™¨
    manager = QuotesManager(
        output_dir=OUTPUT_DIR,
        shard_size=SHARD_SIZE
    )

    # ç”Ÿæˆæ•°æ®é›†
    stats = manager.generate_all(target_count=TARGET_COUNT)

    print("\nâœ¨ å®Œæˆï¼å¯ä»¥å¼€å§‹ä½¿ç”¨äº†ã€‚")


if __name__ == "__main__":
    main()

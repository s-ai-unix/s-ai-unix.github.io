<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/"><channel><title>PCA on s-ai-unix's Blog</title><link>https://s-ai-unix.github.io/tags/pca/</link><description>Recent content in PCA on s-ai-unix's Blog</description><generator>Hugo -- 0.154.5</generator><language>zh-cn</language><lastBuildDate>Sun, 25 Jan 2026 18:00:00 +0800</lastBuildDate><atom:link href="https://s-ai-unix.github.io/tags/pca/index.xml" rel="self" type="application/rss+xml"/><item><title>谱定理：线性代数的优雅与机器学习的基石</title><link>https://s-ai-unix.github.io/posts/2026-01-25-spectral-theorem/</link><pubDate>Sun, 25 Jan 2026 18:00:00 +0800</pubDate><guid>https://s-ai-unix.github.io/posts/2026-01-25-spectral-theorem/</guid><description>从对称矩阵到深度学习：系统性介绍谱定理的核心理论及其在机器学习中的应用，包括正交对角化、SVD、PCA、谱聚类和图神经网络</description></item><item><title>PCA 主成分分析：从数据降维的优雅艺术</title><link>https://s-ai-unix.github.io/posts/2026-01-24-pca-comprehensive-guide/</link><pubDate>Sat, 24 Jan 2026 12:00:00 +0800</pubDate><guid>https://s-ai-unix.github.io/posts/2026-01-24-pca-comprehensive-guide/</guid><description>深入探讨机器学习中的核心降维算法 PCA，从直观理解到数学推导，从两种等价的视角（最大化方差、最小化重构误差）揭示其本质，包含完整的证明和实际应用。</description></item></channel></rss>
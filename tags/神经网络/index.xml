<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/"><channel><title>神经网络 on s-ai-unix's Blog</title><link>https://s-ai-unix.github.io/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/</link><description>Recent content in 神经网络 on s-ai-unix's Blog</description><generator>Hugo -- 0.154.5</generator><language>zh-cn</language><lastBuildDate>Sat, 24 Jan 2026 18:30:00 +0800</lastBuildDate><atom:link href="https://s-ai-unix.github.io/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/index.xml" rel="self" type="application/rss+xml"/><item><title>变分自编码器：从概率建模到深度生成的优雅桥梁</title><link>https://s-ai-unix.github.io/posts/2026-01-24-variational-autoencoder/</link><pubDate>Sat, 24 Jan 2026 18:30:00 +0800</pubDate><guid>https://s-ai-unix.github.io/posts/2026-01-24-variational-autoencoder/</guid><description>深入解析变分自编码器（VAE）的数学原理与推导，从变分推断到 ELBO 优化，从重参数化到生成应用，完整呈现 VAE 的理论框架与实践价值</description></item><item><title>生成对抗网络：从混沌中创造秩序的博弈论</title><link>https://s-ai-unix.github.io/posts/2026-01-24-gan-comprehensive-guide/</link><pubDate>Sat, 24 Jan 2026 11:45:00 +0800</pubDate><guid>https://s-ai-unix.github.io/posts/2026-01-24-gan-comprehensive-guide/</guid><description>深入探讨生成对抗网络（GAN）的数学原理、训练挑战与应用前景</description></item><item><title>Transformer：重塑AI世界的架构革命</title><link>https://s-ai-unix.github.io/posts/2026-01-21-transformer/</link><pubDate>Wed, 21 Jan 2026 10:00:00 +0800</pubDate><guid>https://s-ai-unix.github.io/posts/2026-01-21-transformer/</guid><description>深入解读 Transformer 架构的核心原理，从自注意力机制到多头注意力，探索这个重塑 AI 世界的重要架构</description></item><item><title>感知机的完整发展历程：从线性分类到深度学习的基石</title><link>https://s-ai-unix.github.io/posts/2026-01-21-perceptron-development-history/</link><pubDate>Wed, 21 Jan 2026 08:00:00 +0800</pubDate><guid>https://s-ai-unix.github.io/posts/2026-01-21-perceptron-development-history/</guid><description>系统综述感知机的发展历程，从早期的线性分类器到现代深度学习的基础，注重背景和演变过程的介绍，通俗易懂。</description></item><item><title>神经网络算法演进：从感知机到 Transformer 的七十年征程</title><link>https://s-ai-unix.github.io/posts/2026-01-15-neural-network-evolution/</link><pubDate>Thu, 15 Jan 2026 23:55:00 +0800</pubDate><guid>https://s-ai-unix.github.io/posts/2026-01-15-neural-network-evolution/</guid><description>回顾神经网络七十年发展历程，从感知机到 Transformer，详解核心算法的数学原理</description></item><item><title>大语言模型：为什么AI能这么快、这么聪明地回答问题</title><link>https://s-ai-unix.github.io/posts/2026-01-14-llm-principle-for-students/</link><pubDate>Wed, 14 Jan 2026 08:50:00 +0800</pubDate><guid>https://s-ai-unix.github.io/posts/2026-01-14-llm-principle-for-students/</guid><description>从预测下一个词的简单想法出发，解释大语言模型的工作原理，面向初中生和高中生的通俗易懂指南。</description></item><item><title>梯度、梯度下降与反向传播：从最优化到深度学习的数学引擎</title><link>https://s-ai-unix.github.io/posts/2026-01-14-gradient-descent-backpropagation-overview/</link><pubDate>Wed, 14 Jan 2026 08:34:44 +0800</pubDate><guid>https://s-ai-unix.github.io/posts/2026-01-14-gradient-descent-backpropagation-overview/</guid><description>系统介绍梯度、梯度下降、反向传播算法，以及梯度的其他应用，完整推导历史背景与应用场景，并详细对比梯度、散度、旋度三个核心概念。</description></item><item><title>基于神经网络的深度学习算法：从感知机到Transformer的完整指南</title><link>https://s-ai-unix.github.io/posts/2026-01-14-deep-learning-algorithms-comprehensive-guide/</link><pubDate>Wed, 14 Jan 2026 08:30:00 +0800</pubDate><guid>https://s-ai-unix.github.io/posts/2026-01-14-deep-learning-algorithms-comprehensive-guide/</guid><description>本文全面回顾深度学习算法的发展历程、数学原理、架构演进及未来前景，涵盖从基础神经网络到Transformer的完整演进路径。</description></item></channel></rss>
<!doctype html><html lang=en dir=auto data-theme=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>机器学习 | s-ai-unix's Blog</title><meta name=keywords content><meta name=description content="s-ai-unix 的个人技术博客，分享数学、AI、产品设计、数据科学、智能汽车(设计、研发、质量、合规)、历史等领域的知识和思考"><meta name=author content="s-ai-unix"><link rel=canonical href=https://s-ai-unix.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/><link crossorigin=anonymous href=/assets/css/stylesheet.0833aff7e1cf567ecfb9755701ee95a80535f671e2e1a0a770c9bc20a0a7b5bb.css integrity="sha256-CDOv9+HPVn7PuXVXAe6VqAU19nHi4aCncMm8IKCntbs=" rel="preload stylesheet" as=style><link rel=icon href=https://s-ai-unix.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://s-ai-unix.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://s-ai-unix.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://s-ai-unix.github.io/apple-touch-icon.png><link rel=mask-icon href=https://s-ai-unix.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate type=application/rss+xml href=https://s-ai-unix.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/index.xml title=rss><link rel=alternate hreflang=en href=https://s-ai-unix.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51);color-scheme:dark}.list{background:var(--theme)}.toc{background:var(--entry)}}@media(prefers-color-scheme:light){.list::-webkit-scrollbar-thumb{border-color:var(--code-bg)}}</style></noscript><script>localStorage.getItem("pref-theme")==="dark"?document.querySelector("html").dataset.theme="dark":localStorage.getItem("pref-theme")==="light"?document.querySelector("html").dataset.theme="light":window.matchMedia("(prefers-color-scheme: dark)").matches?document.querySelector("html").dataset.theme="dark":document.querySelector("html").dataset.theme="light"</script><meta property="og:url" content="https://s-ai-unix.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"><meta property="og:site_name" content="s-ai-unix's Blog"><meta property="og:title" content="机器学习"><meta property="og:description" content="s-ai-unix 的个人技术博客，分享数学、AI、产品设计、数据科学、智能汽车(设计、研发、质量、合规)、历史等领域的知识和思考"><meta property="og:locale" content="zh-cn"><meta property="og:type" content="website"><meta name=twitter:card content="summary"><meta name=twitter:title content="机器学习"><meta name=twitter:description content="s-ai-unix 的个人技术博客，分享数学、AI、产品设计、数据科学、智能汽车(设计、研发、质量、合规)、历史等领域的知识和思考"><link rel=stylesheet href=https://s-ai-unix.github.io/css/classical-quote.css></head><body class=list id=top><header class=header><nav class=nav><div class=logo><a href=https://s-ai-unix.github.io/ accesskey=h title="s-ai-unix's Blog (Alt + H)">s-ai-unix's Blog</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://s-ai-unix.github.io/ title="🏠 首页"><span>🏠 首页</span></a></li><li><a href=https://s-ai-unix.github.io/posts/ title="📚 文章"><span>📚 文章</span></a></li><li><a href=https://s-ai-unix.github.io/archives/ title="📁 归档"><span>📁 归档</span></a></li><li><a href=https://s-ai-unix.github.io/tags/ title="🏷️ 标签"><span>🏷️ 标签</span></a></li><li><a href=https://s-ai-unix.github.io/search/ title="🔍 搜索 (Alt + /)" accesskey=/><span>🔍 搜索</span></a></li><li><a href=https://s-ai-unix.github.io/about/ title="👤 关于"><span>👤 关于</span></a></li></ul></nav></header><main class=main><header class=page-header><div class=breadcrumbs><a href=https://s-ai-unix.github.io/>Home</a>&nbsp;»&nbsp;<a href=https://s-ai-unix.github.io/tags/>Tags</a></div><h1>机器学习</h1></header><article class="post-entry tag-entry"><figure class=entry-cover><img loading=lazy src=https://s-ai-unix.github.io/images/covers/iso-8800-ai-safety.jpg alt=AI安全网络示意图></figure><header class=entry-header><h2 class=entry-hint-parent>ISO/PAS 8800:2024 道路车辆人工智能安全工程——从确定性到概率性的范式转移</h2></header><div class=entry-content><p>引言：确定性基石的动摇与重构 本文仅代表本人以及所使用的AI工具的观点， 不代表任何公司或者机构实体的意见！
在汽车工业百年的发展历程中，安全工程的基石始终建立在确定性逻辑之上。传统的 ISO 26262 功能安全标准，其核心哲学是"防错"——通过严格的流程控制和硬件冗余，防止电子电气系统发生非预期的故障。这种思想在数学上对应着清晰的布尔代数：系统要么正常（$x = 1$），要么失效（$x = 0$），边界分明。
然而，随着人工智能（AI），特别是深度学习技术在自动驾驶感知、预测及决策模块中的深度渗透，这一确定性基石遭遇了前所未有的冲击。AI 系统的行为不再完全由代码行数决定，而是由数据分布、模型架构及训练过程中的随机性共同涌现而成。以神经网络为例，其输出可以表示为：
$$ y = f(x; \theta) = \sigma_L(W_L \cdot \sigma_{L-1}(W_{L-1} \cdot \ldots \cdot \sigma_1(W_1 \cdot x + b_1) \ldots) + b_L) $$
其中 $\theta = {W_1, b_1, \ldots, W_L, b_L}$ 是通过训练过程优化的参数。这种"黑盒"特性与概率性输出，使得传统的安全保障体系面临巨大的逻辑真空。
ISO/PAS 8800:2024《道路车辆——安全与人工智能》 的发布，标志着汽车安全工程正式进入了"数据定义安全“的新纪元。这不仅仅是一份新的技术规范，它是对现有安全方法论的一次系统性重构：它不再试图将 AI 强行塞入确定性的框架，而是承认 AI 的不确定性，并提供了一套全新的数学与工程语言来量化、管理和控制这种不确定性。
本文将从数学原理出发，系统性地解读 ISO 8800 的核心概念，并通过实战案例，展示如何在不确定的 AI 世界中构建可信的安全系统。
第一章：标准定位——三大安全支柱的逻辑互补 1.1 安全体系的演进：从单点防御到立体防护 理解 ISO 8800 的首要任务，是厘清其在现有安全标准体系中的生态位。现代汽车安全体系正演变为由 ISO 26262、ISO 21448 和 ISO 8800 共同支撑的三维架构。这三大标准并非简单的并列关系，而是形成了一个严密的逻辑闭环：
...</p></div><footer class=entry-footer><span title='2026-01-20 21:10:00 +0800 CST'>January 20, 2026</span>&nbsp;·&nbsp;<span>9 min</span>&nbsp;·&nbsp;<span>1710 words</span>&nbsp;·&nbsp;<span>s-ai-unix</span></footer><a class=entry-link aria-label="post link to ISO/PAS 8800:2024 道路车辆人工智能安全工程——从确定性到概率性的范式转移" href=https://s-ai-unix.github.io/posts/2026-01-20-iso-8800-comprehensive-guide/></a></article><article class="post-entry tag-entry"><figure class=entry-cover><img loading=lazy src=https://s-ai-unix.github.io/images/covers/neural-network-evolution.jpg alt=抽象神经网络连接图></figure><header class=entry-header><h2 class=entry-hint-parent>神经网络算法演进：从感知机到 Transformer 的七十年征程</h2></header><div class=entry-content><p>引言：智慧的萌芽 想象一下 1957 年的夏天，康奈尔大学的弗兰克·罗森布拉特（Frank Rosenblatt）在实验室里调试着一台早期的电子计算机。他正在实现一个大胆的想法——能否用数学模型模拟人类的大脑神经元？
这个想法在当时看起来近乎荒谬。人类大脑由数百亿个神经元组成，神经元之间通过突触连接，形成了一个令人眩晕的复杂网络。但罗森布拉特相信，如果我们能理解单个神经元的基本工作原理，就能一步步构建出能够学习的智能系统。
那时的学术界对机器学习充满怀疑。“机器怎么可能思考？"——这是当时的主流声音。但罗森布拉特和他的同道们坚持了下来，用数学公式编织着最初的神经之梦。
今天，当我们面对能够写出论文、创作艺术、驾驶汽车的深度学习系统时，很容易忘记这一切都始于一个简单的线性分类器。让我们放慢脚步，回顾这七十年的征程，感受数学的力量与思想的演进。
一、感知机：神经网络的起点（1957） 时间：1957 年 - 弗兰克·罗森布拉特 (Frank Rosenblatt)
历史的起点 1957 年，弗兰克·罗森布拉特在康奈尔航空实验室发明了感知机（Perceptron）。这是第一个能够学习的神经网络模型，被誉为"机器学习的开端”。
1962 年的《纽约客》杂志甚至专门报道了这个发明，称它为"会思考的机器"。那时的媒体兴奋中充满了对人工智能未来的无限遐想。
数学形式 单个神经元的工作原理 一个感知机神经元接收 $d$ 维输入 $\mathbf{x} = (x_1, x_2, \ldots, x_d)^T$，每个输入对应一个权重 $w_i$，还有一个偏置 $b$。
神经元的输出是输入的加权和，然后通过激活函数：
$$ y = f(z) = f\left(\sum_{i=1}^{d} w_i x_i + b\right) = f(w^T x + b) $$
其中 $z = \mathbf{w}^T \mathbf{x} + b$ 是净输入（net input）。
激活函数 在最初的感知机中，激活函数是符号函数（sign function）：
$$ f(z) = \begin{cases} 1 & \text{if } z \geq 0 \ -1 & \text{if } z &lt; 0 \end{cases} $$
...</p></div><footer class=entry-footer><span title='2026-01-15 23:55:00 +0800 CST'>January 15, 2026</span>&nbsp;·&nbsp;<span>8 min</span>&nbsp;·&nbsp;<span>1578 words</span>&nbsp;·&nbsp;<span>s-ai-unix</span></footer><a class=entry-link aria-label="post link to 神经网络算法演进：从感知机到 Transformer 的七十年征程" href=https://s-ai-unix.github.io/posts/2026-01-15-neural-network-evolution/></a></article><article class="post-entry tag-entry"><figure class=entry-cover><img loading=lazy src=https://s-ai-unix.github.io/images/covers/ml-algorithms-legacy.jpg alt=抽象几何图案></figure><header class=entry-header><h2 class=entry-hint-parent>深度学习前夜：十大传统机器学习算法的历史与数学之美</h2></header><div class=entry-content><p>引言：黄金时代 想象一下 2006 年的秋天，深度学习尚未兴起。那时的机器学习领域正经历着一场静悄悄的革命。统计学习方法、核方法、集成学习层出不穷，数学家们用优雅的公式编织着智能的梦想。
那时，人们相信：只要数据足够、特征工程足够细致，我们就能教机器做任何事。这种信念催生了一批经典算法——它们或许不如今天的深度神经网络那样炫目，但每一款都凝聚着数学家的智慧，每一步推导都闪耀着逻辑的光辉。
今天，我们回顾这段黄金时代，讲述十个改变了世界的传统机器学习算法的故事。但这次，让我们放慢脚步，亲手推导每一步，感受数学的力量。
一、线性回归：回归分析的鼻祖 时间：1795 年 - 阿德里安-马里·勒让德 (Adrien-Marie Legendre)
历史的偶然 1795 年，法国天文学家勒让德正在为一个问题头疼：如何用最简单的方法拟合行星轨道数据？他需要找到一条直线，让所有数据点到这条直线的距离平方和最小。
这就是最小二乘法的诞生。
推导过程 让我们从最简单的情况开始。假设我们有 $n$ 个数据点 $(x_1, y_1), (x_2, y_2), \ldots, (x_n, y_n)$，想要找到一条直线 $y = w_0 + w_1 x$ 来拟合这些数据。
第一步：定义误差
对于每个数据点 $(x_i, y_i)$，我们的预测值是 $\hat{y}_i = w_0 + w_1 x_i$，误差就是观测值和预测值的差：
$$ e_i = y_i - \hat{y}_i = y_i - (w_0 + w_1 x_i) $$
第二步：定义损失函数
为什么是平方误差？勒让德选择平方误差有几个好处：
非负：平方后总是非负 可导：处处光滑，便于优化 凸函数：只有一个最小值 损失函数定义为：
$$ L(w_0, w_1) = \sum_{i=1}^{n} e_i^2 = \sum_{i=1}^{n} [y_i - (w_0 + w_1 x_i)]^2 $$
...</p></div><footer class=entry-footer><span title='2026-01-15 22:30:00 +0800 CST'>January 15, 2026</span>&nbsp;·&nbsp;<span>17 min</span>&nbsp;·&nbsp;<span>3481 words</span>&nbsp;·&nbsp;<span>s-ai-unix</span></footer><a class=entry-link aria-label="post link to 深度学习前夜：十大传统机器学习算法的历史与数学之美" href=https://s-ai-unix.github.io/posts/2026-01-15-traditional-ml-algorithms/></a></article><article class="post-entry tag-entry"><figure class=entry-cover><img loading=lazy src=https://s-ai-unix.github.io/images/covers/unsplash-taylor.jpg alt=抽象几何曲线></figure><header class=entry-header><h2 class=entry-hint-parent>泰勒公式：用简单近似复杂的艺术</h2></header><div class=entry-content><p>引言：从曲线到直线 想象你站在一座山上，想知道脚下的山坡有多陡。你不需要知道整个山脉的形状，只需要知道你所在位置的局部斜率。这是微积分最基本的思想——用局部信息推断全局行为。
更进一步，如果山坡弯曲了怎么办？这时不仅需要知道斜率，还需要知道弯曲的程度。这就是泰勒公式的核心思想：用最简单的函数（多项式）来近似复杂的函数，而近似的质量取决于我们使用多少局部信息（导数）。
泰勒公式被誉为"数学家最有力的工具之一"。它不仅连接了离散与连续、局部与整体，更在数值计算、物理建模和现代人工智能中扮演着不可替代的角色。今天，让我们深入探索这个既古老又常新的数学宝藏。
一、历史回顾：从牛顿到泰勒 泰勒公式的思想可以追溯到牛顿和莱布尼茨创立微积分的时期。牛顿在他的《流数术》中已经隐含了将函数展开为无穷级数的想法。
布鲁克·泰勒（Brook Taylor，1685-1731）在1715年发表了他的开创性论文《增量法及其逆运算》，首次系统地阐述了用多项式级数逼近函数的方法。有趣的是，泰勒本人并没有意识到他发现的公式的全部潜力，余项的研究（拉格朗日余项、柯西余项等）是后来由拉格朗日等数学家完善的。
麦克劳林（Colin Maclaurin）发现了泰勒公式在零点展开的特例，即麦克劳林级数。这个形式在实际计算中更为常用，因为计算起来更加方便。
二、一元函数的泰勒公式 基本形式 假设函数 $f(x)$ 在点 $a$ 处足够光滑（即具有各阶导数），那么我们可以构造一个多项式 $P_n(x)$ 来近似 $f(x)$：
$$ P_n(x) = f(a) + f’(a)(x-a) + \frac{f’’(a)}{2!}(x-a)^2 + \cdots + \frac{f^{(n)}(a)}{n!}(x-a)^n $$
泰勒公式告诉我们：
$$ f(x) = P_n(x) + R_n(x) $$
其中 $R_n(x)$ 是余项，表示近似误差。
余项的几种形式 理解余项对于掌握泰勒公式至关重要，因为它告诉我们近似在什么范围内可靠。
拉格朗日余项：
$$ R_n(x) = \frac{f^{(n+1)}(\xi)}{(n+1)!}(x-a)^{n+1} $$
其中 $\xi$ 是 $a$ 和 $x$ 之间的某个值。
积分余项：
$$ R_n(x) = \frac{1}{n!} \int_a^x f^{(n+1)}(t)(x-t)^n , dt $$
直观理解 让我们通过一个简单的例子来理解泰勒公式。考虑 $f(x) = e^x$ 在 $a = 0$ 处的泰勒展开（即麦克劳林级数）：
...</p></div><footer class=entry-footer><span title='2026-01-14 22:10:00 +0800 CST'>January 14, 2026</span>&nbsp;·&nbsp;<span>6 min</span>&nbsp;·&nbsp;<span>1110 words</span>&nbsp;·&nbsp;<span>s-ai-unix</span></footer><a class=entry-link aria-label="post link to 泰勒公式：用简单近似复杂的艺术" href=https://s-ai-unix.github.io/posts/2026-01-14-taylor-series/></a></article><article class="post-entry tag-entry"><figure class=entry-cover><img loading=lazy src=https://s-ai-unix.github.io/images/covers/photo-1620712943543-bcc4688e7485.jpg alt=神经网络连接></figure><header class=entry-header><h2 class=entry-hint-parent>基于神经网络的深度学习算法：从感知机到Transformer的完整指南</h2></header><div class=entry-content><p>引言：从生物启发到智能革命 1943年，Warren McCulloch和Walter Pitts提出了第一个神经元数学模型。他们用一个简单的数学公式模拟了生物神经元的工作方式：接收输入、加权求和、激活输出。这个看似简单的想法，却孕育了后来改变世界的人工智能技术。
1958年，Frank Rosenblatt发明了感知机（Perceptron），这是第一个可以学习的神经网络。但1969年，Minsky和Papert在《Perceptrons》一书中证明了单层感知机无法解决异或（XOR）问题，这个致命缺陷导致了神经网络研究的第一次寒冬。
1986年，David Rumelhart、Geoffrey Hinton和Ronald Williams重新发现了反向传播算法，解决了多层网络的训练问题。神经网络迎来了短暂的春天。
但在90年代到2000年代初，支持向量机（SVM）等传统机器学习算法统治了学术界。神经网络因为数据量不足、计算能力有限、缺乏有效的训练技巧，再次陷入沉寂。
2012年，ImageNet竞赛上，Hinton的学生Alex Krizhevsky使用深度卷积神经网络AlexNet，以压倒性优势击败了传统方法，分类错误率从26%降低到15.3%。这一年，深度学习时代正式开启。
从此，深度学习以惊人的速度发展：2014年的VGG、GoogLeNet，2015年的ResNet解决深度退化问题，2017年的Transformer彻底改变自然语言处理，2022年的ChatGPT让全世界见识到大模型的力量。
本文将从数学原理出发，系统讲解深度学习的核心算法：从基础神经网络到卷积神经网络（CNN），从循环神经网络（RNN）到Transformer，最后探讨未来发展趋势。
第一章：神经网络的数学基础 1.1 单神经元：感知机的数学模型 1.1.1 前向传播 感知机是最基础的神经网络单元，模拟生物神经元的工作原理。给定输入向量 $x \in \mathbb{R}^d$，权重向量 $w \in \mathbb{R}^d$，偏置 $b \in \mathbb{R}$：
$$z = w^Tx + b = \sum_{i=1}^d w_i x_i + b$$
激活函数 $\sigma(z)$ 决定神经元的输出：
$$a = \sigma(z)$$
1.1.2 常用激活函数 Sigmoid函数： $$\sigma(z) = \frac{1}{1 + e^{-z}}$$
导数： $$\sigma’(z) = \sigma(z)(1 - \sigma(z))$$
性质：
输出范围：$(0, 1)$ S型曲线，可微 缺点：梯度消失（$| \sigma’(z) | \leq 0.25$），输出不以零为中心 Tanh函数： $$\tanh(z) = \frac{e^z - e^{-z}}{e^z + e^{-z}}$$
...</p></div><footer class=entry-footer><span title='2026-01-14 08:30:00 +0800 CST'>January 14, 2026</span>&nbsp;·&nbsp;<span>11 min</span>&nbsp;·&nbsp;<span>2188 words</span>&nbsp;·&nbsp;<span>s-ai-unix</span></footer><a class=entry-link aria-label="post link to 基于神经网络的深度学习算法：从感知机到Transformer的完整指南" href=https://s-ai-unix.github.io/posts/2026-01-14-deep-learning-algorithms-comprehensive-guide/></a></article><article class="post-entry tag-entry"><figure class=entry-cover><img loading=lazy src=https://s-ai-unix.github.io/images/covers/rl-network.jpg alt=神经网络连接示意图></figure><header class=entry-header><h2 class=entry-hint-parent>强化学习：从试错到智能的数学之旅</h2></header><div class=entry-content><p>引言：试错的智慧 想象一下，你第一次玩《超级马里奥》这款游戏。屏幕上的小人在管道和蘑菇之间跳跃，你必须不断尝试：有时候跳得太早撞到了蘑菇，有时候跳得太晚掉进了坑里。但随着尝试次数的增多，你逐渐掌握了时机——你知道什么时候该加速，什么时候该按跳跃键。
这种通过试错来学习的过程，就是强化学习（Reinforcement Learning, RL）的核心思想。不同于监督学习从标注好的数据中学习，强化学习通过与环境的交互来获取反馈，并逐渐优化自己的行为策略。
从数学的角度看，强化学习可以被视为一个优化问题：智能体（Agent）需要在环境中选择动作（Action），以最大化累积奖励（Reward）。这个过程可以用概率论和微积分的语言来精确描述。
本文将带你踏上这段数学之旅，从马尔可夫决策过程（MDP）的基础框架出发，逐步推导经典的Q-learning、Policy Gradient和Actor-Critic算法，最后探讨强化学习的应用场景和未来前景。
第一章：强化学习的基本框架 1.1 核心概念 在正式进入数学推导之前，让我们先建立一个直观的图像。想象一只老鼠在迷宫中寻找奶酪：
智能体（Agent）：这只老鼠 环境（Environment）：迷宫 状态（State）：老鼠在迷宫中的位置 动作（Action）：老鼠可以向前后左右移动 奖励（Reward）：找到奶酪+10分，撞墙-1分，每走一步-0.1分（鼓励快速找到） 智能体的目标是学习一个策略（Policy），即在不同状态下选择最优的动作，以最大化长期累积奖励。
1.2 数学表示 现在让我们用数学语言来描述这个框架。一个强化学习问题通常由以下元组表示：
$$ (S, A, P, R, \gamma) $$
其中：
$S$：状态空间（State Space） $A$：动作空间（Action Space） $P$：状态转移概率（Transition Probability） $R$：奖励函数（Reward Function） $\gamma$：折扣因子（Discount Factor），$\gamma \in [0,1]$ 状态转移概率 $P(s’|s,a)$ 表示在状态 $s$ 执行动作 $a$ 后，转移到状态 $s’$ 的概率：
$$ P(s’|s,a) = \mathbb{P}[S_{t+1} = s’ | S_t = s, A_t = a] $$
奖励函数 $R(s,a)$ 可以定义为：
$$ R(s,a) = \mathbb{E}[R_{t+1} | S_t = s, A_t = a] $$
...</p></div><footer class=entry-footer><span title='2026-01-14 08:30:00 +0800 CST'>January 14, 2026</span>&nbsp;·&nbsp;<span>7 min</span>&nbsp;·&nbsp;<span>1291 words</span>&nbsp;·&nbsp;<span>s-ai-unix</span></footer><a class=entry-link aria-label="post link to 强化学习：从试错到智能的数学之旅" href=https://s-ai-unix.github.io/posts/2026-01-14-reinforcement-learning-comprehensive-guide/></a></article><article class="post-entry tag-entry"><figure class=entry-cover><img loading=lazy src=https://s-ai-unix.github.io/images/covers/photo-1509228468518-180dd4864904.jpg alt=抽象几何图形></figure><header class=entry-header><h2 class=entry-hint-parent>传统机器学习与统计学习算法：从理论到实践的完整指南</h2></header><div class=entry-content><p>引言：从统计学到机器学习 1956年，达特茅斯会议上正式提出了"人工智能"这个词。但在那之前的一百年里，统计学家们已经在用数学工具从数据中提取规律。高斯在1809年就用最小二乘法解决了天文学中的观测数据拟合问题，这可以看作是最早的机器学习算法。
机器学习和统计学习，本质上是一回事：从数据中学习规律，并用这些规律做出预测。只是出发点略有不同——统计学家关注估计的可靠性和显著性检验，而计算机科学家更关心算法的计算效率和泛化能力。
当我们说"传统机器学习"时，指的是深度学习时代之前的那些经典算法。这些算法虽然不像神经网络那样"万能"，但在数据量有限、需要可解释性的场景下，依然发挥着不可替代的作用。
第一章：统计学习的理论基础 1.1 学习问题的数学框架 假设我们有一个数据集 $D = {(x_1, y_1), (x_2, y_2), \ldots, (x_n, y_n)}$，其中 $x_i \in \mathcal{X}$ 是输入（特征），$y_i \in \mathcal{Y}$ 是输出（标签）。我们的目标是找到一个函数 $f: \mathcal{X} \to \mathcal{Y}$，使得对于新的输入 $x$，$f(x)$ 能准确预测对应的 $y$。
但在统计学习的框架下，我们还需要引入概率论的概念。假设数据是按照某个未知的联合分布 $P(X,Y)$ 生成的，我们的目标是学习一个决策函数 $f$，使得期望风险最小化：
$$R(f) = \mathbb{E}_{(X,Y) \sim P}[L(Y, f(X))]$$
其中 $L$ 是损失函数。对于回归问题，常用平方损失；对于分类问题，常用0-1损失或交叉熵损失。
问题在于：我们不知道 $P(X,Y)$，无法直接计算 $R(f)$。我们只能用经验风险（Empirical Risk）来近似：
$$\hat{R}(f) = \frac{1}{n}\sum_{i=1}^n L(y_i, f(x_i))$$
这就是经验风险最小化（ERM）的基本思想。但直接最小化经验风险会导致过拟合（overfitting）。
1.2 偏差-方差权衡 这是统计学习中最重要的概念之一。模型的预测误差可以分解为三个部分：
$$\mathbb{E}[(y - \hat{f}(x))^2] = \text{Bias}[\hat{f}(x)]^2 + \text{Var}[\hat{f}(x)] + \sigma^2$$
其中：
$\text{Bias}[\hat{f}(x)] = \mathbb{E}[\hat{f}(x)] - f^*(x)$：模型预测的期望与真实值的差距 $\text{Var}[\hat{f}(x)] = \mathbb{E}[(\hat{f}(x) - \mathbb{E}[\hat{f}(x)])^2]$：模型预测的方差 $\sigma^2$：不可约误差（数据本身的噪声） 偏差反映了模型的"假设强度"。如果模型过于简单（比如用线性模型拟合高度非线性的数据），会产生高偏差，导致欠拟合。
...</p></div><footer class=entry-footer><span title='2026-01-14 08:18:25 +0800 CST'>January 14, 2026</span>&nbsp;·&nbsp;<span>11 min</span>&nbsp;·&nbsp;<span>2161 words</span>&nbsp;·&nbsp;<span>s-ai-unix</span></footer><a class=entry-link aria-label="post link to 传统机器学习与统计学习算法：从理论到实践的完整指南" href=https://s-ai-unix.github.io/posts/2026-01-14-traditional-ml-algorithms-comprehensive-guide/></a></article><article class="post-entry tag-entry"><figure class=entry-cover><img loading=lazy src=https://s-ai-unix.github.io/images/covers/1555255707-c07966088b7b.jpg alt=机器学习流程></figure><header class=entry-header><h2 class=entry-hint-parent>机器学习项目完整流程图与实践指南</h2></header><div class=entry-content><p>前言 下面的机器学习流程图是从某视频中看到的,虽然"会的不难",但里面的每一步都很艰辛。尤其是被很多人认为是脏活累活的"加载预处理数据集"这块,这个大家实践下来的基本共识是:这块就占了整个机器学习流程的60%到80%的工作量。
所以,不要心存美好幻想,觉得机器学习或者人工智能是多么高大上和美好的事情。
机器学习完整流程图 ┌─────────────────────────────────────────────────────────────┐ │ 机器学习项目完整流程 │ └─────────────────────────────────────────────────────────────┘ ↓ ┌─────────────────────────────────────────────────────────────┐ │ 1. 问题定义 │ │ - 明确业务目标 │ │ - 定义成功指标 │ │ - 确定项目范围 │ └─────────────────────────────────────────────────────────────┘ ↓ ┌─────────────────────────────────────────────────────────────┐ │ 2. 数据收集 │ │ - 确定数据源 │ │ - 收集训练数据 │ │ - 数据质量评估 │ └─────────────────────────────────────────────────────────────┘ ↓ ┌─────────────────────────────────────────────────────────────┐ │ 3. 数据探索(EDA) │ │ - 统计分析 │ │ - 可视化探索 │ │ - 发现模式和异常 │ └─────────────────────────────────────────────────────────────┘ ↓ ┌─────────────────────────────────────────────────────────────┐ │ 4. 数据预处理 │ │ - 数据清洗 │ │ - 缺失值处理 │ │ - 异常值处理 │ │ - 特征编码 │ └─────────────────────────────────────────────────────────────┘ ↓ ┌─────────────────────────────────────────────────────────────┐ │ 5. 特征工程 │ │ - 特征选择 │ │ - 特征变换 │ │ - 特征构造 │ │ - 降维处理 │ └─────────────────────────────────────────────────────────────┘ ↓ ┌─────────────────────────────────────────────────────────────┐ │ 6. 模型选择 │ │ - 选择算法 │ │ - 设计基线模型 │ │ - 确定评估指标 │ └─────────────────────────────────────────────────────────────┘ ↓ ┌─────────────────────────────────────────────────────────────┐ │ 7. 模型训练 │ │ - 数据集分割 │ │ - 交叉验证 │ │ - 超参数调优 │ └─────────────────────────────────────────────────────────────┘ ↓ ┌─────────────────────────────────────────────────────────────┐ │ 8. 模型评估 │ │ - 性能评估 │ │ - 错误分析 │ │ - 模型解释 │ └─────────────────────────────────────────────────────────────┘ ↓ ┌─────────────────────────────────────────────────────────────┐ │ 9. 模型优化 │ │ - 集成方法 │ │ - 模型融合 │ │ - 迭代改进 │ └─────────────────────────────────────────────────────────────┘ ↓ ┌─────────────────────────────────────────────────────────────┐ │ 10. 模型部署 │ │ - 模型序列化 │ │ - API设计 │ │ - 监控和维护 │ └─────────────────────────────────────────────────────────────┘ 详细步骤解析 第1步:问题定义 重要性:
...</p></div><footer class=entry-footer><span title='2019-07-07 07:32:15 +0800 CST'>July 7, 2019</span>&nbsp;·&nbsp;<span>5 min</span>&nbsp;·&nbsp;<span>928 words</span>&nbsp;·&nbsp;<span>s-ai-unix</span></footer><a class=entry-link aria-label="post link to 机器学习项目完整流程图与实践指南" href=https://s-ai-unix.github.io/posts/2019-07-07-machine-learning-workflow-guide/></a></article><article class="post-entry tag-entry"><figure class=entry-cover><img loading=lazy src=https://s-ai-unix.github.io/images/covers/1454165804606-c3d57bc86b40.jpg alt=职业发展路径></figure><header class=entry-header><h2 class=entry-hint-parent>工作回顾与职业发展思考</h2></header><div class=entry-content><p>引言 2019年年中开始,后面的工作内容应该有所调整。
自从16年6月底,从上海回到合肥,加入到华米科技,到现在整整3年了。
工作历程回顾 第一阶段(2016年中 - 2017年初) 基本一个人在做数据分析和报表。这段时间是快速成长的阶段:
独立负责数据分析工作 搭建数据报表体系 熟悉业务和数据结构 提升技术能力和业务理解 第二阶段(2017年初 - 2018年中) 带了一个新加入的同事A一起做数据分析和ETL等相关工作。开始从个人贡献者向团队协作者转变:
学习如何带领新人 分工协作,提高效率 ETL流程优化 建立更完善的数据分析体系 第三阶段(2018年中 - 2019年中) A去做上游的导数的事情,分析由我和新加入的B和C,两个妹子,一起来完成。同时,自己也从大数据工程师,升级成了高级大数据工程师:
团队规模扩大 工作内容更加聚焦 技术深度和广度都有提升 开始思考职业发展方向 职业转型的思考 到了19年年中, 为什么想从大数据分析,转到人工智能实验室团队去做更多的AI直接相关的事情呢?
我想主要还是想去探索数据价值发挥的一个新路径吧。毕竟,描述性的统计分析,这个我已经做了三年了。而描述性数据分析的价值有它的局限性。
而关于数据的更地道的挖掘和分析:
特征选取 建模 模型评估 这些都是自己的薄弱点,也是我所认为的一个合格的data scientist必须掌握的。更何况,自己在算法和机器学习这块,并非是没有基础。人生那么长,总不能一辈子做基础的描述性的统计分析/业务分析还有做报表吧。
过往的学习准备 下面列出一些以前学习过的课程和材料吧,算是对过往准备工作的一个总结。
理论基础 台大林轩田的课程 《机器学习基石》 《机器学习技巧》 对应的英文教材《Learning From Data》 这些课程打下了坚实的机器学习理论基础,特别是对机器学习的核心概念和算法有了深入理解。
吴恩达的课程 《机器学习》 《深度学习》 完成了coursera上的深度学习的几门课程 课后作业有点水,因为很多都可以通过上下文得到,但是不得不承认,是好的课后作业。
其他课程 周志华的西瓜书《机器学习》 李航的《统计学习方法》 《The Elements of Statistical Learning》(看了一点点) 数学基础 概率统计的相关知识 线性代数的相关知识 平时都有所复习 实践经验 工具使用 scikit-learn:常用的机器学习算法库 pandas:数据处理和分析 numpy:数值计算 项目经验 1. 逻辑回归和时间序列分析
...</p></div><footer class=entry-footer><span title='2019-07-04 12:04:30 +0800 CST'>July 4, 2019</span>&nbsp;·&nbsp;<span>1 min</span>&nbsp;·&nbsp;<span>141 words</span>&nbsp;·&nbsp;<span>s-ai-unix</span></footer><a class=entry-link aria-label="post link to 工作回顾与职业发展思考" href=https://s-ai-unix.github.io/posts/2019-07-04-work-reflections/></a></article><footer class=page-footer><nav class=pagination><a class=prev href=https://s-ai-unix.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/>«&nbsp;Prev&nbsp;</a></nav></footer></main><footer class=footer><span>&copy; 2026 <a href=https://s-ai-unix.github.io/>s-ai-unix's Blog</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
<a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script>(function(){"use strict";function e(){var e=document.querySelectorAll("p, li, td, div, span, h1, h2, h3, h4, h5, h6, ol, ul");e.forEach(function(e){if(e.classList.contains("classical-quote-container")||e.classList.contains("quote-text")||e.closest(".classical-quote-container"))return;var n,t=e.innerHTML,s=!1;for(t.indexOf("<em>")!==-1&&(n=t.replace(/\$([^$]*?)<em>([^<]+?)<\/em>([^$]*?)\$/g,function(e,t,n,s){return/^[\d.,]+$/.test((t+n+s).replace(/[.,]/g,""))?e:"$"+t+"_"+n+s+"$"}),n=n.replace(/\$\$([^$]*?)<em>([^<]+?)<\/em>([^$]*?)\$\$/g,function(e,t,n,s){return"$$"+t+"_"+n+s+"$$"}),n!==t&&(t=n,s=!0)),t.indexOf("</em>")!==-1&&(n=t.replace(/\$([^$]*?)<\/em>([^$]*?)\$/g,function(e,t,n){return"$"+t+"_{"+n+"$"}),n=n.replace(/\$\$([^$]*?)<\/em>([^$]*?)\$\$/g,function(e,t,n){return"$$"+t+"_{"+n+"$$"}),n!==t&&(t=n,s=!0)),t.indexOf("<em>$")!==-1&&(n=t.replace(/<em>\$/g,"$"),n!==t&&(t=n,s=!0)),t.indexOf("</em>$")!==-1&&(n=t.replace(/<\/em>\$/g,"$"),n!==t&&(t=n,s=!0));t.indexOf("<em>")!==-1&&t.indexOf("</em>")!==-1;){if(n=t.replace(/\$([^$]*?)<em>([^<]+?)<\/em>([^$]*?)\$/g,function(e,t,n,s){return/^[\d.,]+$/.test((t+n+s).replace(/[.,]/g,""))?e:"$"+t+"_"+n+s+"$"}),n=n.replace(/\$\$([^$]*?)<em>([^<]+?)<\/em>([^$]*?)\$\$/g,function(e,t,n,s){return"$$"+t+"_"+n+s+"$$"}),n===t)break;t=n,s=!0}t.indexOf("_{")!==-1&&(n=t.replace(/_{/g,"_{"),n!==t&&(t=n,s=!0)),t.indexOf("}_")!==-1&&(n=t.replace(/}_/g,"}"),n!==t&&(t=n,s=!0)),t.indexOf("\\\\")!==-1&&(n=t.replace(/(\$\{1,2\})([^$]*?)(\$\{1,2\})/g,function(e,t,n,s){for(;n.indexOf("\\\\")!==-1;)n=n.replace(/\\\\/g,"\\");return t+n+s}),n!==t&&(t=n,s=!0)),s&&(e.innerHTML=t)})}window.MathJax={tex:{inlineMath:[["$","$"]],displayMath:[["$$","$$"]],processEscapes:!0,processEnvironments:!0,tags:"ams",macros:{oiint:"\\mathop{∯}",oiiint:"\\mathop{∰}"}},options:{skipHtmlTags:["script","noscript","style","textarea","pre","code"]},startup:{pageReady:function(){return e(),MathJax.startup.defaultPageReady().then(function(){console.log("MathJax formulas rendered successfully")})}}}})()</script><script src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script><link rel=stylesheet href=/css/mermaid-custom.css><script src=/js/mermaid-converter.js></script><script type=module>
  import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs';

  
  setTimeout(() => {
    mermaid.initialize({
      startOnLoad: true,
      theme: 'base',
      themeVariables: {
        primaryColor: '#e3f2fd',
        primaryTextColor: '#1565c0',
        primaryBorderColor: '#2196f3',
        lineColor: '#42a5f5',
        secondaryColor: '#f3e5f5',
        tertiaryColor: '#fff9c4',
        background: '#ffffff',
        mainBkg: '#ffffff',
        nodeBorder: '#2196f3',
        clusterBkg: '#ffffff',
        clusterBorder: '#e0e0e0',
        titleColor: '#1565c0',
        edgeLabelBackground: '#fafafa',
      },
      securityLevel: 'loose',
    });
  }, 100);
</script><script src=/js/toc.js></script><script>let menu=document.getElementById("menu");if(menu){const e=localStorage.getItem("menu-scroll-position");e&&(menu.scrollLeft=parseInt(e,10)),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}}document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{const e=document.querySelector("html");e.dataset.theme==="dark"?(e.dataset.theme="light",localStorage.setItem("pref-theme","light")):(e.dataset.theme="dark",localStorage.setItem("pref-theme","dark"))})</script><script>(function(){"use strict";function e(){var e=document.querySelectorAll("p, li, td, div, span, h1, h2, h3, h4, h5, h6, ol, ul");e.forEach(function(e){if(e.classList.contains("classical-quote-container")||e.classList.contains("quote-text")||e.closest(".classical-quote-container"))return;var n,t=e.innerHTML,s=!1;for(t.indexOf("<em>")!==-1&&(n=t.replace(/\$([^$]*?)<em>([^<]+?)<\/em>([^$]*?)\$/g,function(e,t,n,s){return/^[\d.,]+$/.test((t+n+s).replace(/[.,]/g,""))?e:"$"+t+"_"+n+s+"$"}),n=n.replace(/\$\$([^$]*?)<em>([^<]+?)<\/em>([^$]*?)\$\$/g,function(e,t,n,s){return"$$"+t+"_"+n+s+"$$"}),n!==t&&(t=n,s=!0)),t.indexOf("</em>")!==-1&&(n=t.replace(/\$([^$]*?)<\/em>([^$]*?)\$/g,function(e,t,n){return"$"+t+"_{"+n+"$"}),n=n.replace(/\$\$([^$]*?)<\/em>([^$]*?)\$\$/g,function(e,t,n){return"$$"+t+"_{"+n+"$$"}),n!==t&&(t=n,s=!0)),t.indexOf("<em>$")!==-1&&(n=t.replace(/<em>\$/g,"$"),n!==t&&(t=n,s=!0)),t.indexOf("</em>$")!==-1&&(n=t.replace(/<\/em>\$/g,"$"),n!==t&&(t=n,s=!0));t.indexOf("<em>")!==-1&&t.indexOf("</em>")!==-1;){if(n=t.replace(/\$([^$]*?)<em>([^<]+?)<\/em>([^$]*?)\$/g,function(e,t,n,s){return/^[\d.,]+$/.test((t+n+s).replace(/[.,]/g,""))?e:"$"+t+"_"+n+s+"$"}),n=n.replace(/\$\$([^$]*?)<em>([^<]+?)<\/em>([^$]*?)\$\$/g,function(e,t,n,s){return"$$"+t+"_"+n+s+"$$"}),n===t)break;t=n,s=!0}t.indexOf("_{")!==-1&&(n=t.replace(/_{/g,"_{"),n!==t&&(t=n,s=!0)),t.indexOf("}_")!==-1&&(n=t.replace(/}_/g,"}"),n!==t&&(t=n,s=!0)),t.indexOf("\\\\")!==-1&&(n=t.replace(/(\$\{1,2\})([^$]*?)(\$\{1,2\})/g,function(e,t,n,s){for(;n.indexOf("\\\\")!==-1;)n=n.replace(/\\\\/g,"\\");return t+n+s}),n!==t&&(t=n,s=!0)),s&&(e.innerHTML=t)})}window.MathJax={tex:{inlineMath:[["$","$"]],displayMath:[["$$","$$"]],processEscapes:!0,processEnvironments:!0,tags:"ams",macros:{oiint:"\\mathop{∯}",oiiint:"\\mathop{∰}"}},options:{skipHtmlTags:["script","noscript","style","textarea","pre","code"]},startup:{pageReady:function(){return e(),MathJax.startup.defaultPageReady().then(function(){console.log("MathJax formulas rendered successfully")})}}}})()</script><script src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script><link rel=stylesheet href=/css/mermaid-custom.css><script src=/js/mermaid-converter.js></script><script type=module>
  import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs';

  
  setTimeout(() => {
    mermaid.initialize({
      startOnLoad: true,
      theme: 'base',
      themeVariables: {
        primaryColor: '#e3f2fd',
        primaryTextColor: '#1565c0',
        primaryBorderColor: '#2196f3',
        lineColor: '#42a5f5',
        secondaryColor: '#f3e5f5',
        tertiaryColor: '#fff9c4',
        background: '#ffffff',
        mainBkg: '#ffffff',
        nodeBorder: '#2196f3',
        clusterBkg: '#ffffff',
        clusterBorder: '#e0e0e0',
        titleColor: '#1565c0',
        edgeLabelBackground: '#fafafa',
      },
      securityLevel: 'loose',
    });
  }, 100);
</script><script src=/js/toc.js></script></body></html>